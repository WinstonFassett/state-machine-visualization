{"version":3,"sources":["../node_modules/.pnpm/mdast-util-to-string@3.2.0/node_modules/mdast-util-to-string/lib/index.js","../node_modules/.pnpm/micromark-util-chunked@1.1.0/node_modules/micromark-util-chunked/index.js","../node_modules/.pnpm/micromark-util-combine-extensions@1.1.0/node_modules/micromark-util-combine-extensions/index.js","../node_modules/.pnpm/micromark-util-character@1.2.0/node_modules/micromark-util-character/lib/unicode-punctuation-regex.js","../node_modules/.pnpm/micromark-util-character@1.2.0/node_modules/micromark-util-character/index.js","../node_modules/.pnpm/micromark-factory-space@1.1.0/node_modules/micromark-factory-space/index.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/initialize/content.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/initialize/document.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/blank-line.js","../node_modules/.pnpm/micromark-util-subtokenize@1.1.0/node_modules/micromark-util-subtokenize/index.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/content.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/initialize/flow.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/initialize/text.js","../node_modules/.pnpm/micromark-util-resolve-all@1.1.0/node_modules/micromark-util-resolve-all/index.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/create-tokenizer.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/thematic-break.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/list.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/block-quote.js","../node_modules/.pnpm/micromark-factory-destination@1.1.0/node_modules/micromark-factory-destination/index.js","../node_modules/.pnpm/micromark-factory-label@1.1.0/node_modules/micromark-factory-label/index.js","../node_modules/.pnpm/micromark-factory-title@1.1.0/node_modules/micromark-factory-title/index.js","../node_modules/.pnpm/micromark-factory-whitespace@1.1.0/node_modules/micromark-factory-whitespace/index.js","../node_modules/.pnpm/micromark-util-normalize-identifier@1.1.0/node_modules/micromark-util-normalize-identifier/index.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/definition.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/code-indented.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/setext-underline.js","../node_modules/.pnpm/micromark-util-html-tag-name@1.2.0/node_modules/micromark-util-html-tag-name/index.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/html-flow.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/code-fenced.js","../node_modules/.pnpm/character-entities@2.0.2/node_modules/character-entities/index.js","../node_modules/.pnpm/decode-named-character-reference@1.0.2/node_modules/decode-named-character-reference/index.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/character-reference.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/character-escape.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/line-ending.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/label-end.js","../node_modules/.pnpm/micromark-util-classify-character@1.1.0/node_modules/micromark-util-classify-character/index.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/attention.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/constructs.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/heading-atx.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/label-start-image.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/autolink.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/html-text.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/label-start-link.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/hard-break-escape.js","../node_modules/.pnpm/micromark-core-commonmark@1.1.0/node_modules/micromark-core-commonmark/lib/code-text.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/parse.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/preprocess.js","../node_modules/.pnpm/micromark-util-decode-numeric-character-reference@1.1.0/node_modules/micromark-util-decode-numeric-character-reference/index.js","../node_modules/.pnpm/micromark-util-decode-string@1.1.0/node_modules/micromark-util-decode-string/index.js","../node_modules/.pnpm/unist-util-stringify-position@3.0.3/node_modules/unist-util-stringify-position/lib/index.js","../node_modules/.pnpm/mdast-util-from-markdown@1.3.1/node_modules/mdast-util-from-markdown/lib/index.js","../node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/postprocess.js","../node_modules/.pnpm/mermaid@10.6.0/node_modules/mermaid/dist/createText-62fc7601.js"],"names":["emptyOptions","one","value","includeImageAlt","includeHtml","Boolean","lib_node","type","alt","lib_all","children","Array","isArray","values","result","index","length","join","splice","list","start","remove","items","end","parameters","chunkStart","from","unshift","slice","push","micromark_util_combine_extensions_hasOwnProperty","hasOwnProperty","syntaxExtension","all","extension","hook","left","call","undefined","right","code","micromark_util_combine_extensions_constructs","existing","before","add","asciiAlpha","regexCheck","asciiAlphanumeric","asciiAtext","asciiControl","asciiDigit","asciiHexDigit","asciiPunctuation","markdownLineEnding","markdownLineEndingOrSpace","markdownSpace","unicodePunctuation","unicodeWhitespace","regex","test","String","fromCharCode","factorySpace","effects","ok","max","limit","Number","POSITIVE_INFINITY","size","enter","prefix","consume","exit","content_content","tokenize","contentStart","attempt","this","parser","constructs","contentInitial","lineStart","previous","token","contentType","next","data","document_document","self","stack","childFlow","childToken","lineStartOffset","continued","item","containerState","continuation","documentContinue","checkNewContainers","_closeFlow","closeFlow","indexBeforeExits","events","point","indexBeforeFlow","exitContainers","Object","assign","documentContinued","currentConstruct","concrete","flowStart","interrupt","_gfmTableDynamicInterruptHack","check","containerConstruct","thereIsANewContainer","thereIsNoNewContainer","lazy","now","line","offset","containerContinue","flow","_tokenizer","flowContinue","writeToChild","eof","stream","sliceStream","defineSkip","write","seen","entry","nok","document","disable","null","includes","blankLine","after","partial","subtokenize","jumps","event","lineIndex","otherIndex","otherEvent","subevents","more","_isInFirstContentOfListItem","subcontent","_container","eventIndex","context","startPosition","startPositions","tokenizer","childEvents","gaps","current","adjust","breaks","_gfmTasklistFirstContentOfListItem","pop","lib_content_content","chunkInside","contentEnd","continuationConstruct","contentContinue","resolve","prefixed","tail","sliceSerialize","initial","flowInitial","afterConstruct","resolver","resolveAll","createResolver","text_string","initializeFactory","text_text","field","text","notText","atBreak","resolveAllLineSuffixes","extraResolver","chunks","tabs","bufferIndex","chunk","charCodeAt","column","_index","_bufferIndex","called","createTokenizer","initialize","columnStart","resolveAllConstructs","consumed","accountForPotentialSkip","fields","constructFactory","construct","info","addResult","onsuccessfulcheck","expandTabs","atTab","serializeChunks","chunkIndex","go","main","expectedCode","state","startIndex","startBufferIndex","endIndex","endBufferIndex","view","head","shift","sliceChunks","_","restore","onreturn","returnState","bogusState","listOfConstructs","constructIndex","handleListOfConstructs","map","def","handleMapOfConstructs","handleConstruct","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","store","name","create","resolveTo","thematic_break_thematicBreak","marker","sequence","list_list","initialSize","kind","atMarker","inside","onBlank","listItemPrefixWhitespaceConstruct","endOfPrefix","otherPrefix","initialBlankLine","furtherBlankLines","notInCurrentItem","indentConstruct","block_quote_blockQuote","open","contBefore","factoryDestination","literalType","literalMarkerType","rawType","stringType","balance","enclosedBefore","raw","enclosed","enclosedEscape","rawEscape","factoryLabel","markerType","labelInside","labelEscape","factoryTitle","begin","escape","factoryWhitespace","normalizeIdentifier","replace","toLowerCase","toUpperCase","definition_definition","identifier","labelAfter","markerAfter","destinationBefore","destinationAfter","definition_titleBefore","afterWhitespace","defined","beforeMarker","titleAfter","titleAfterOptionalWhitespace","codeIndented","afterPrefix","code_indented_furtherStart","furtherStart","setextUnderline","paragraph","content","definition","heading","htmlBlockNames","htmlRawNames","htmlFlow","closingTag","buffer","markerB","declarationOpen","tagCloseStart","continuationDeclarationInside","tagName","commentOpenInside","cdataOpenInside","slash","basicSelfClosing","completeClosingTagAfter","completeAttributeNameBefore","completeEnd","completeAttributeName","completeAttributeNameAfter","completeAttributeValueBefore","completeAttributeValueQuoted","completeAttributeValueUnquoted","completeAttributeValueQuotedAfter","completeAfter","continuationCommentInside","continuationRawTagOpen","continuationClose","continuationCdataInside","continuationStart","blankLineBefore","continuationAfter","nonLazyContinuationStart","continuationStartNonLazy","continuationBefore","continuationRawEndTag","nonLazyContinuation","codeFenced","closeStart","beforeSequenceClose","sequenceClose","sizeOpen","sequenceCloseAfter","initialPrefix","sequenceOpen","beforeSequenceOpen","infoBefore","atNonLazyBreak","metaBefore","meta","contentBefore","beforeContentChunk","contentChunk","characterEntities","AElig","AMP","Aacute","Abreve","Acirc","Acy","Afr","Agrave","Alpha","Amacr","And","Aogon","Aopf","ApplyFunction","Aring","Ascr","Assign","Atilde","Auml","Backslash","Barv","Barwed","Bcy","Because","Bernoullis","Beta","Bfr","Bopf","Breve","Bscr","Bumpeq","CHcy","COPY","Cacute","Cap","CapitalDifferentialD","Cayleys","Ccaron","Ccedil","Ccirc","Cconint","Cdot","Cedilla","CenterDot","Cfr","Chi","CircleDot","CircleMinus","CirclePlus","CircleTimes","ClockwiseContourIntegral","CloseCurlyDoubleQuote","CloseCurlyQuote","Colon","Colone","Congruent","Conint","ContourIntegral","Copf","Coproduct","CounterClockwiseContourIntegral","Cross","Cscr","Cup","CupCap","DD","DDotrahd","DJcy","DScy","DZcy","Dagger","Darr","Dashv","Dcaron","Dcy","Del","Delta","Dfr","DiacriticalAcute","DiacriticalDot","DiacriticalDoubleAcute","DiacriticalGrave","DiacriticalTilde","Diamond","DifferentialD","Dopf","Dot","DotDot","DotEqual","DoubleContourIntegral","DoubleDot","DoubleDownArrow","DoubleLeftArrow","DoubleLeftRightArrow","DoubleLeftTee","DoubleLongLeftArrow","DoubleLongLeftRightArrow","DoubleLongRightArrow","DoubleRightArrow","DoubleRightTee","DoubleUpArrow","DoubleUpDownArrow","DoubleVerticalBar","DownArrow","DownArrowBar","DownArrowUpArrow","DownBreve","DownLeftRightVector","DownLeftTeeVector","DownLeftVector","DownLeftVectorBar","DownRightTeeVector","DownRightVector","DownRightVectorBar","DownTee","DownTeeArrow","Downarrow","Dscr","Dstrok","ENG","ETH","Eacute","Ecaron","Ecirc","Ecy","Edot","Efr","Egrave","Element","Emacr","EmptySmallSquare","EmptyVerySmallSquare","Eogon","Eopf","Epsilon","Equal","EqualTilde","Equilibrium","Escr","Esim","Eta","Euml","Exists","ExponentialE","Fcy","Ffr","FilledSmallSquare","FilledVerySmallSquare","Fopf","ForAll","Fouriertrf","Fscr","GJcy","GT","Gamma","Gammad","Gbreve","Gcedil","Gcirc","Gcy","Gdot","Gfr","Gg","Gopf","GreaterEqual","GreaterEqualLess","GreaterFullEqual","GreaterGreater","GreaterLess","GreaterSlantEqual","GreaterTilde","Gscr","Gt","HARDcy","Hacek","Hat","Hcirc","Hfr","HilbertSpace","Hopf","HorizontalLine","Hscr","Hstrok","HumpDownHump","HumpEqual","IEcy","IJlig","IOcy","Iacute","Icirc","Icy","Idot","Ifr","Igrave","Im","Imacr","ImaginaryI","Implies","Int","Integral","Intersection","InvisibleComma","InvisibleTimes","Iogon","Iopf","Iota","Iscr","Itilde","Iukcy","Iuml","Jcirc","Jcy","Jfr","Jopf","Jscr","Jsercy","Jukcy","KHcy","KJcy","Kappa","Kcedil","Kcy","Kfr","Kopf","Kscr","LJcy","LT","Lacute","Lambda","Lang","Laplacetrf","Larr","Lcaron","Lcedil","Lcy","LeftAngleBracket","LeftArrow","LeftArrowBar","LeftArrowRightArrow","LeftCeiling","LeftDoubleBracket","LeftDownTeeVector","LeftDownVector","LeftDownVectorBar","LeftFloor","LeftRightArrow","LeftRightVector","LeftTee","LeftTeeArrow","LeftTeeVector","LeftTriangle","LeftTriangleBar","LeftTriangleEqual","LeftUpDownVector","LeftUpTeeVector","LeftUpVector","LeftUpVectorBar","LeftVector","LeftVectorBar","Leftarrow","Leftrightarrow","LessEqualGreater","LessFullEqual","LessGreater","LessLess","LessSlantEqual","LessTilde","Lfr","Ll","Lleftarrow","Lmidot","LongLeftArrow","LongLeftRightArrow","LongRightArrow","Longleftarrow","Longleftrightarrow","Longrightarrow","Lopf","LowerLeftArrow","LowerRightArrow","Lscr","Lsh","Lstrok","Lt","Map","Mcy","MediumSpace","Mellintrf","Mfr","MinusPlus","Mopf","Mscr","Mu","NJcy","Nacute","Ncaron","Ncedil","Ncy","NegativeMediumSpace","NegativeThickSpace","NegativeThinSpace","NegativeVeryThinSpace","NestedGreaterGreater","NestedLessLess","NewLine","Nfr","NoBreak","NonBreakingSpace","Nopf","Not","NotCongruent","NotCupCap","NotDoubleVerticalBar","NotElement","NotEqual","NotEqualTilde","NotExists","NotGreater","NotGreaterEqual","NotGreaterFullEqual","NotGreaterGreater","NotGreaterLess","NotGreaterSlantEqual","NotGreaterTilde","NotHumpDownHump","NotHumpEqual","NotLeftTriangle","NotLeftTriangleBar","NotLeftTriangleEqual","NotLess","NotLessEqual","NotLessGreater","NotLessLess","NotLessSlantEqual","NotLessTilde","NotNestedGreaterGreater","NotNestedLessLess","NotPrecedes","NotPrecedesEqual","NotPrecedesSlantEqual","NotReverseElement","NotRightTriangle","NotRightTriangleBar","NotRightTriangleEqual","NotSquareSubset","NotSquareSubsetEqual","NotSquareSuperset","NotSquareSupersetEqual","NotSubset","NotSubsetEqual","NotSucceeds","NotSucceedsEqual","NotSucceedsSlantEqual","NotSucceedsTilde","NotSuperset","NotSupersetEqual","NotTilde","NotTildeEqual","NotTildeFullEqual","NotTildeTilde","NotVerticalBar","Nscr","Ntilde","Nu","OElig","Oacute","Ocirc","Ocy","Odblac","Ofr","Ograve","Omacr","Omega","Omicron","Oopf","OpenCurlyDoubleQuote","OpenCurlyQuote","Or","Oscr","Oslash","Otilde","Otimes","Ouml","OverBar","OverBrace","OverBracket","OverParenthesis","PartialD","Pcy","Pfr","Phi","Pi","PlusMinus","Poincareplane","Popf","Pr","Precedes","PrecedesEqual","PrecedesSlantEqual","PrecedesTilde","Prime","Product","Proportion","Proportional","Pscr","Psi","QUOT","Qfr","Qopf","Qscr","RBarr","REG","Racute","Rang","Rarr","Rarrtl","Rcaron","Rcedil","Rcy","Re","ReverseElement","ReverseEquilibrium","ReverseUpEquilibrium","Rfr","Rho","RightAngleBracket","RightArrow","RightArrowBar","RightArrowLeftArrow","RightCeiling","RightDoubleBracket","RightDownTeeVector","RightDownVector","RightDownVectorBar","RightFloor","RightTee","RightTeeArrow","RightTeeVector","RightTriangle","RightTriangleBar","RightTriangleEqual","RightUpDownVector","RightUpTeeVector","RightUpVector","RightUpVectorBar","RightVector","RightVectorBar","Rightarrow","Ropf","RoundImplies","Rrightarrow","Rscr","Rsh","RuleDelayed","SHCHcy","SHcy","SOFTcy","Sacute","Sc","Scaron","Scedil","Scirc","Scy","Sfr","ShortDownArrow","ShortLeftArrow","ShortRightArrow","ShortUpArrow","Sigma","SmallCircle","Sopf","Sqrt","Square","SquareIntersection","SquareSubset","SquareSubsetEqual","SquareSuperset","SquareSupersetEqual","SquareUnion","Sscr","Star","Sub","Subset","SubsetEqual","Succeeds","SucceedsEqual","SucceedsSlantEqual","SucceedsTilde","SuchThat","Sum","Sup","Superset","SupersetEqual","Supset","THORN","TRADE","TSHcy","TScy","Tab","Tau","Tcaron","Tcedil","Tcy","Tfr","Therefore","Theta","ThickSpace","ThinSpace","Tilde","TildeEqual","TildeFullEqual","TildeTilde","Topf","TripleDot","Tscr","Tstrok","Uacute","Uarr","Uarrocir","Ubrcy","Ubreve","Ucirc","Ucy","Udblac","Ufr","Ugrave","Umacr","UnderBar","UnderBrace","UnderBracket","UnderParenthesis","Union","UnionPlus","Uogon","Uopf","UpArrow","UpArrowBar","UpArrowDownArrow","UpDownArrow","UpEquilibrium","UpTee","UpTeeArrow","Uparrow","Updownarrow","UpperLeftArrow","UpperRightArrow","Upsi","Upsilon","Uring","Uscr","Utilde","Uuml","VDash","Vbar","Vcy","Vdash","Vdashl","Vee","Verbar","Vert","VerticalBar","VerticalLine","VerticalSeparator","VerticalTilde","VeryThinSpace","Vfr","Vopf","Vscr","Vvdash","Wcirc","Wedge","Wfr","Wopf","Wscr","Xfr","Xi","Xopf","Xscr","YAcy","YIcy","YUcy","Yacute","Ycirc","Ycy","Yfr","Yopf","Yscr","Yuml","ZHcy","Zacute","Zcaron","Zcy","Zdot","ZeroWidthSpace","Zeta","Zfr","Zopf","Zscr","aacute","abreve","ac","acE","acd","acirc","acute","acy","aelig","af","afr","agrave","alefsym","aleph","alpha","amacr","amalg","amp","and","andand","andd","andslope","andv","ang","ange","angle","angmsd","angmsdaa","angmsdab","angmsdac","angmsdad","angmsdae","angmsdaf","angmsdag","angmsdah","angrt","angrtvb","angrtvbd","angsph","angst","angzarr","aogon","aopf","ap","apE","apacir","ape","apid","apos","approx","approxeq","aring","ascr","ast","asymp","asympeq","atilde","auml","awconint","awint","bNot","backcong","backepsilon","backprime","backsim","backsimeq","barvee","barwed","barwedge","bbrk","bbrktbrk","bcong","bcy","bdquo","becaus","because","bemptyv","bepsi","bernou","beta","beth","between","bfr","bigcap","bigcirc","bigcup","bigodot","bigoplus","bigotimes","bigsqcup","bigstar","bigtriangledown","bigtriangleup","biguplus","bigvee","bigwedge","bkarow","blacklozenge","blacksquare","blacktriangle","blacktriangledown","blacktriangleleft","blacktriangleright","blank","blk12","blk14","blk34","block","bne","bnequiv","bnot","bopf","bot","bottom","bowtie","boxDL","boxDR","boxDl","boxDr","boxH","boxHD","boxHU","boxHd","boxHu","boxUL","boxUR","boxUl","boxUr","boxV","boxVH","boxVL","boxVR","boxVh","boxVl","boxVr","boxbox","boxdL","boxdR","boxdl","boxdr","boxh","boxhD","boxhU","boxhd","boxhu","boxminus","boxplus","boxtimes","boxuL","boxuR","boxul","boxur","boxv","boxvH","boxvL","boxvR","boxvh","boxvl","boxvr","bprime","breve","brvbar","bscr","bsemi","bsim","bsime","bsol","bsolb","bsolhsub","bull","bullet","bump","bumpE","bumpe","bumpeq","cacute","cap","capand","capbrcup","capcap","capcup","capdot","caps","caret","caron","ccaps","ccaron","ccedil","ccirc","ccups","ccupssm","cdot","cedil","cemptyv","cent","centerdot","cfr","chcy","checkmark","chi","cir","cirE","circ","circeq","circlearrowleft","circlearrowright","circledR","circledS","circledast","circledcirc","circleddash","cire","cirfnint","cirmid","cirscir","clubs","clubsuit","colon","colone","coloneq","comma","commat","comp","compfn","complement","complexes","cong","congdot","conint","copf","coprod","copy","copysr","crarr","cross","cscr","csub","csube","csup","csupe","ctdot","cudarrl","cudarrr","cuepr","cuesc","cularr","cularrp","cup","cupbrcap","cupcap","cupcup","cupdot","cupor","cups","curarr","curarrm","curlyeqprec","curlyeqsucc","curlyvee","curlywedge","curren","curvearrowleft","curvearrowright","cuvee","cuwed","cwconint","cwint","cylcty","dArr","dHar","dagger","daleth","darr","dash","dashv","dbkarow","dblac","dcaron","dcy","dd","ddagger","ddarr","ddotseq","deg","delta","demptyv","dfisht","dfr","dharl","dharr","diam","diamond","diamondsuit","diams","die","digamma","disin","div","divide","divideontimes","divonx","djcy","dlcorn","dlcrop","dollar","dopf","dot","doteq","doteqdot","dotminus","dotplus","dotsquare","doublebarwedge","downarrow","downdownarrows","downharpoonleft","downharpoonright","drbkarow","drcorn","drcrop","dscr","dscy","dsol","dstrok","dtdot","dtri","dtrif","duarr","duhar","dwangle","dzcy","dzigrarr","eDDot","eDot","eacute","easter","ecaron","ecir","ecirc","ecolon","ecy","edot","ee","efDot","efr","eg","egrave","egs","egsdot","el","elinters","ell","els","elsdot","emacr","empty","emptyset","emptyv","emsp13","emsp14","emsp","eng","ensp","eogon","eopf","epar","eparsl","eplus","epsi","epsilon","epsiv","eqcirc","eqcolon","eqsim","eqslantgtr","eqslantless","equals","equest","equiv","equivDD","eqvparsl","erDot","erarr","escr","esdot","esim","eta","eth","euml","euro","excl","exist","expectation","exponentiale","fallingdotseq","fcy","female","ffilig","fflig","ffllig","ffr","filig","fjlig","flat","fllig","fltns","fnof","fopf","forall","fork","forkv","fpartint","frac12","frac13","frac14","frac15","frac16","frac18","frac23","frac25","frac34","frac35","frac38","frac45","frac56","frac58","frac78","frasl","frown","fscr","gE","gEl","gacute","gamma","gammad","gap","gbreve","gcirc","gcy","gdot","ge","gel","geq","geqq","geqslant","ges","gescc","gesdot","gesdoto","gesdotol","gesl","gesles","gfr","gg","ggg","gimel","gjcy","gl","glE","gla","glj","gnE","gnap","gnapprox","gne","gneq","gneqq","gnsim","gopf","grave","gscr","gsim","gsime","gsiml","gt","gtcc","gtcir","gtdot","gtlPar","gtquest","gtrapprox","gtrarr","gtrdot","gtreqless","gtreqqless","gtrless","gtrsim","gvertneqq","gvnE","hArr","hairsp","half","hamilt","hardcy","harr","harrcir","harrw","hbar","hcirc","hearts","heartsuit","hellip","hercon","hfr","hksearow","hkswarow","hoarr","homtht","hookleftarrow","hookrightarrow","hopf","horbar","hscr","hslash","hstrok","hybull","hyphen","iacute","ic","icirc","icy","iecy","iexcl","iff","ifr","igrave","ii","iiiint","iiint","iinfin","iiota","ijlig","imacr","image","imagline","imagpart","imath","imof","imped","in","incare","infin","infintie","inodot","int","intcal","integers","intercal","intlarhk","intprod","iocy","iogon","iopf","iota","iprod","iquest","iscr","isin","isinE","isindot","isins","isinsv","isinv","it","itilde","iukcy","iuml","jcirc","jcy","jfr","jmath","jopf","jscr","jsercy","jukcy","kappa","kappav","kcedil","kcy","kfr","kgreen","khcy","kjcy","kopf","kscr","lAarr","lArr","lAtail","lBarr","lE","lEg","lHar","lacute","laemptyv","lagran","lambda","lang","langd","langle","lap","laquo","larr","larrb","larrbfs","larrfs","larrhk","larrlp","larrpl","larrsim","larrtl","lat","latail","late","lates","lbarr","lbbrk","lbrace","lbrack","lbrke","lbrksld","lbrkslu","lcaron","lcedil","lceil","lcub","lcy","ldca","ldquo","ldquor","ldrdhar","ldrushar","ldsh","le","leftarrow","leftarrowtail","leftharpoondown","leftharpoonup","leftleftarrows","leftrightarrow","leftrightarrows","leftrightharpoons","leftrightsquigarrow","leftthreetimes","leg","leq","leqq","leqslant","les","lescc","lesdot","lesdoto","lesdotor","lesg","lesges","lessapprox","lessdot","lesseqgtr","lesseqqgtr","lessgtr","lesssim","lfisht","lfloor","lfr","lg","lgE","lhard","lharu","lharul","lhblk","ljcy","ll","llarr","llcorner","llhard","lltri","lmidot","lmoust","lmoustache","lnE","lnap","lnapprox","lne","lneq","lneqq","lnsim","loang","loarr","lobrk","longleftarrow","longleftrightarrow","longmapsto","longrightarrow","looparrowleft","looparrowright","lopar","lopf","loplus","lotimes","lowast","lowbar","loz","lozenge","lozf","lpar","lparlt","lrarr","lrcorner","lrhar","lrhard","lrm","lrtri","lsaquo","lscr","lsh","lsim","lsime","lsimg","lsqb","lsquo","lsquor","lstrok","lt","ltcc","ltcir","ltdot","lthree","ltimes","ltlarr","ltquest","ltrPar","ltri","ltrie","ltrif","lurdshar","luruhar","lvertneqq","lvnE","mDDot","macr","male","malt","maltese","mapsto","mapstodown","mapstoleft","mapstoup","mcomma","mcy","mdash","measuredangle","mfr","mho","micro","mid","midast","midcir","middot","minus","minusb","minusd","minusdu","mlcp","mldr","mnplus","models","mopf","mp","mscr","mstpos","mu","multimap","mumap","nGg","nGt","nGtv","nLeftarrow","nLeftrightarrow","nLl","nLt","nLtv","nRightarrow","nVDash","nVdash","nabla","nacute","nang","nap","napE","napid","napos","napprox","natur","natural","naturals","nbsp","nbump","nbumpe","ncap","ncaron","ncedil","ncong","ncongdot","ncup","ncy","ndash","ne","neArr","nearhk","nearr","nearrow","nedot","nequiv","nesear","nesim","nexist","nexists","nfr","ngE","nge","ngeq","ngeqq","ngeqslant","nges","ngsim","ngt","ngtr","nhArr","nharr","nhpar","ni","nis","nisd","niv","njcy","nlArr","nlE","nlarr","nldr","nle","nleftarrow","nleftrightarrow","nleq","nleqq","nleqslant","nles","nless","nlsim","nlt","nltri","nltrie","nmid","nopf","not","notin","notinE","notindot","notinva","notinvb","notinvc","notni","notniva","notnivb","notnivc","npar","nparallel","nparsl","npart","npolint","npr","nprcue","npre","nprec","npreceq","nrArr","nrarr","nrarrc","nrarrw","nrightarrow","nrtri","nrtrie","nsc","nsccue","nsce","nscr","nshortmid","nshortparallel","nsim","nsime","nsimeq","nsmid","nspar","nsqsube","nsqsupe","nsub","nsubE","nsube","nsubset","nsubseteq","nsubseteqq","nsucc","nsucceq","nsup","nsupE","nsupe","nsupset","nsupseteq","nsupseteqq","ntgl","ntilde","ntlg","ntriangleleft","ntrianglelefteq","ntriangleright","ntrianglerighteq","nu","num","numero","numsp","nvDash","nvHarr","nvap","nvdash","nvge","nvgt","nvinfin","nvlArr","nvle","nvlt","nvltrie","nvrArr","nvrtrie","nvsim","nwArr","nwarhk","nwarr","nwarrow","nwnear","oS","oacute","oast","ocir","ocirc","ocy","odash","odblac","odiv","odot","odsold","oelig","ofcir","ofr","ogon","ograve","ogt","ohbar","ohm","oint","olarr","olcir","olcross","oline","olt","omacr","omega","omicron","omid","ominus","oopf","opar","operp","oplus","or","orarr","ord","order","orderof","ordf","ordm","origof","oror","orslope","orv","oscr","oslash","osol","otilde","otimes","otimesas","ouml","ovbar","par","para","parallel","parsim","parsl","part","pcy","percnt","period","permil","perp","pertenk","pfr","phi","phiv","phmmat","phone","pi","pitchfork","piv","planck","planckh","plankv","plus","plusacir","plusb","pluscir","plusdo","plusdu","pluse","plusmn","plussim","plustwo","pm","pointint","popf","pound","pr","prE","prap","prcue","pre","prec","precapprox","preccurlyeq","preceq","precnapprox","precneqq","precnsim","precsim","prime","primes","prnE","prnap","prnsim","prod","profalar","profline","profsurf","prop","propto","prsim","prurel","pscr","psi","puncsp","qfr","qint","qopf","qprime","qscr","quaternions","quatint","quest","questeq","quot","rAarr","rArr","rAtail","rBarr","rHar","race","racute","radic","raemptyv","rang","rangd","range","rangle","raquo","rarr","rarrap","rarrb","rarrbfs","rarrc","rarrfs","rarrhk","rarrlp","rarrpl","rarrsim","rarrtl","rarrw","ratail","ratio","rationals","rbarr","rbbrk","rbrace","rbrack","rbrke","rbrksld","rbrkslu","rcaron","rcedil","rceil","rcub","rcy","rdca","rdldhar","rdquo","rdquor","rdsh","real","realine","realpart","reals","rect","reg","rfisht","rfloor","rfr","rhard","rharu","rharul","rho","rhov","rightarrow","rightarrowtail","rightharpoondown","rightharpoonup","rightleftarrows","rightleftharpoons","rightrightarrows","rightsquigarrow","rightthreetimes","ring","risingdotseq","rlarr","rlhar","rlm","rmoust","rmoustache","rnmid","roang","roarr","robrk","ropar","ropf","roplus","rotimes","rpar","rpargt","rppolint","rrarr","rsaquo","rscr","rsh","rsqb","rsquo","rsquor","rthree","rtimes","rtri","rtrie","rtrif","rtriltri","ruluhar","rx","sacute","sbquo","sc","scE","scap","scaron","sccue","sce","scedil","scirc","scnE","scnap","scnsim","scpolint","scsim","scy","sdot","sdotb","sdote","seArr","searhk","searr","searrow","sect","semi","seswar","setminus","setmn","sext","sfr","sfrown","sharp","shchcy","shcy","shortmid","shortparallel","shy","sigma","sigmaf","sigmav","sim","simdot","sime","simeq","simg","simgE","siml","simlE","simne","simplus","simrarr","slarr","smallsetminus","smashp","smeparsl","smid","smile","smt","smte","smtes","softcy","sol","solb","solbar","sopf","spades","spadesuit","spar","sqcap","sqcaps","sqcup","sqcups","sqsub","sqsube","sqsubset","sqsubseteq","sqsup","sqsupe","sqsupset","sqsupseteq","squ","square","squarf","squf","srarr","sscr","ssetmn","ssmile","sstarf","star","starf","straightepsilon","straightphi","strns","sub","subE","subdot","sube","subedot","submult","subnE","subne","subplus","subrarr","subset","subseteq","subseteqq","subsetneq","subsetneqq","subsim","subsub","subsup","succ","succapprox","succcurlyeq","succeq","succnapprox","succneqq","succnsim","succsim","sum","sung","sup1","sup2","sup3","sup","supE","supdot","supdsub","supe","supedot","suphsol","suphsub","suplarr","supmult","supnE","supne","supplus","supset","supseteq","supseteqq","supsetneq","supsetneqq","supsim","supsub","supsup","swArr","swarhk","swarr","swarrow","swnwar","szlig","target","tau","tbrk","tcaron","tcedil","tcy","tdot","telrec","tfr","there4","therefore","theta","thetasym","thetav","thickapprox","thicksim","thinsp","thkap","thksim","thorn","tilde","times","timesb","timesbar","timesd","tint","toea","top","topbot","topcir","topf","topfork","tosa","tprime","trade","triangle","triangledown","triangleleft","trianglelefteq","triangleq","triangleright","trianglerighteq","tridot","trie","triminus","triplus","trisb","tritime","trpezium","tscr","tscy","tshcy","tstrok","twixt","twoheadleftarrow","twoheadrightarrow","uArr","uHar","uacute","uarr","ubrcy","ubreve","ucirc","ucy","udarr","udblac","udhar","ufisht","ufr","ugrave","uharl","uharr","uhblk","ulcorn","ulcorner","ulcrop","ultri","umacr","uml","uogon","uopf","uparrow","updownarrow","upharpoonleft","upharpoonright","uplus","upsi","upsih","upsilon","upuparrows","urcorn","urcorner","urcrop","uring","urtri","uscr","utdot","utilde","utri","utrif","uuarr","uuml","uwangle","vArr","vBar","vBarv","vDash","vangrt","varepsilon","varkappa","varnothing","varphi","varpi","varpropto","varr","varrho","varsigma","varsubsetneq","varsubsetneqq","varsupsetneq","varsupsetneqq","vartheta","vartriangleleft","vartriangleright","vcy","vdash","vee","veebar","veeeq","vellip","verbar","vert","vfr","vltri","vnsub","vnsup","vopf","vprop","vrtri","vscr","vsubnE","vsubne","vsupnE","vsupne","vzigzag","wcirc","wedbar","wedge","wedgeq","weierp","wfr","wopf","wp","wr","wreath","wscr","xcap","xcirc","xcup","xdtri","xfr","xhArr","xharr","xi","xlArr","xlarr","xmap","xnis","xodot","xopf","xoplus","xotime","xrArr","xrarr","xscr","xsqcup","xuplus","xutri","xvee","xwedge","yacute","yacy","ycirc","ycy","yen","yfr","yicy","yopf","yscr","yucy","yuml","zacute","zcaron","zcy","zdot","zeetrf","zeta","zfr","zhcy","zigrarr","zopf","zscr","zwj","zwnj","own","decodeNamedCharacterReference","characterReference","numeric","characterEscape","lineEnding","labelEnd","labelStart","_balanced","_inactive","labelEndNok","resourceConstruct","labelEndOk","referenceFullConstruct","referenceNotFull","referenceCollapsedConstruct","close","media","group","label","insideSpan","resourceBefore","resourceOpen","resourceEnd","resourceDestinationAfter","resourceDestinationMissing","resourceBetween","resourceTitleAfter","referenceFullAfter","referenceFullMissing","referenceCollapsedOpen","classifyCharacter","attention","attentionMarkers","_open","_close","openingSequence","closingSequence","use","nextEvents","movePoint","constructs_document","42","43","45","48","49","50","51","52","53","54","55","56","57","62","91","[object Object]","32","constructs_flow","35","sequenceFurther","60","61","95","96","126","constructs_string","38","92","constructs_text","33","schemeOrEmailAtext","emailAtext","schemeInsideOrEmailAtext","urlInside","emailAtSignOrDot","emailLabel","emailValue","instruction","tagOpen","declaration","commentEnd","comment","commentClose","lineEndingBefore","cdata","cdataClose","cdataEnd","instructionClose","tagClose","tagCloseBetween","tagOpenBetween","tagOpenAttributeName","tagOpenAttributeNameAfter","tagOpenAttributeValueBefore","tagOpenAttributeValueQuoted","tagOpenAttributeValueUnquoted","tagOpenAttributeValueQuotedAfter","lineEndingAfter","lineEndingAfterPrefix","93","tailExitIndex","headEnterIndex","constructs_attentionMarkers","parse","options","extensions","combineExtensions","constructs_namespaceObject","string","search","decodeNumericCharacterReference","base","parseInt","characterEscapeOrReference","decode","$0","$1","$2","hex","stringifyPosition","position","lib_point","lib_index","pos","lib_own","fromMarkdown","encoding","config","transforms","canContainEols","autolink","opener","link","autolinkProtocol","onenterdata","autolinkEmail","atxHeading","blockQuote","codeFlow","codeFencedFenceInfo","codeFencedFenceMeta","codeText","codeTextData","codeFlowValue","title","url","definitionDestinationString","definitionLabelString","definitionTitleString","emphasis","hardBreakEscape","hardBreak","hardBreakTrailing","html","htmlFlowData","htmlText","htmlTextData","listItem","spread","_spread","checked","listItemValue","getData","ancestor","setData","listOrdered","listUnordered","reference","referenceString","resourceDestinationString","resourceTitleString","setextHeading","strong","thematicBreak","closer","atxHeadingSequence","node","depth","onexitdata","characterEscapeValue","characterReferenceMarkerHexadecimal","onexitcharacterreferencemarker","characterReferenceMarkerNumeric","characterReferenceValue","mdast_util_from_markdown_lib_point","resume","codeFencedFence","onexithardbreak","referenceType","fragment","labelText","resource","setextHeadingLineSequence","setextHeadingText","configure","combined","mdastExtensions","tree","tokenStack","listStack","prepareList","handler","defaultOnError","firstBlankLineIndex","containerBalance","listSpread","tailIndex","tailEvent","key","errorHandler","parent","onExitError","Error","settings","lib_toString","ordered","compiler","postprocess","atCarriageReturn","match","endPosition","toString","lastIndex","exec","Math","ceil","preprocess","d","markdownToLines","markdown","preprocessedMarkdown","withoutMultipleNewlines","esm","preprocessMarkdown","lines","currentLine","forEach","treeNode","contentNode","processNode","parentType","arguments","split","textLine","word","splitWordToFitWidth","checkFit","splitWordToFitWidthRecursion","usedChars","remainingChars","nextChar","rest","newWord","Intl","Segmenter","segment","s","splitLineToFitWidth","some","_ref","splitLineToFitWidthRecursion","words","_words$shift","newLine","joiner","nextWord","lineWithNextWord","createTspan","textElement","lineHeight","append","attr","computeWidthOfText","parentNode","testElement","testSpan","updateTextContentAndStyles","textLength","getComputedTextLength","computeDimensionOfText","_a","textDimension","getBoundingClientRect","tspan","wrappedLine","innerTspan","__webpack_require__","__webpack_exports__","createText","style","isTitle","classes","useHtmlLabels","isNode","width","addSvgBackground","mermaid_8af3addd","output","concat","markdownToHTML","element","addBackground","fo","labelClass","dom","styleFn","labelStyle","bbox","height","addHtmlSpan","g","structuredText","labelGroup","bkg","insert","checkWidth","line2","linesUnderWidth","preparedLine","getBBox","padding","createFormattedText"],"mappings":"ueAYA,MAAAA,EAAA,GAkCA,SAAAC,EAAAC,EAAAC,EAAAC,GACA,GA+CA,SAAaF,GACb,OAAAG,QAAAH,GAAA,kBAAAA,GAhDMI,CAAIJ,GAAA,CACV,aAAAA,EACA,eAAAA,EAAAK,MAAAH,EAAAF,QAAA,GAEA,GAAAC,GAAA,QAAAD,KAAAM,IACA,OAAAN,EAAAM,IAEA,gBAAAN,EACA,OAAaO,EAAGP,EAAAQ,SAAAP,EAAAC,GAGhB,OAAAO,MAAAC,QAAAV,GACWO,EAAGP,EAAAC,EAAAC,GAEd,GAeA,SAASK,EAAGI,EAAAV,EAAAC,GAEZ,MAAAU,EAAA,GACA,IAAAC,GAAA,EACA,OAAAA,EAAAF,EAAAG,QACAF,EAAAC,GAAAd,EAAAY,EAAAE,GAAAZ,EAAAC,GAEA,OAAAU,EAAAG,KAAA,IC7DO,SAAAC,EAAAC,EAAAC,EAAAC,EAAAC,GACP,MAAAC,EAAAJ,EAAAH,OACA,IAEAQ,EAFAC,EAAA,EAaA,GAPAL,EADAA,EAAA,GACAA,EAAAG,EAAA,EAAAA,EAAAH,EAEAA,EAAAG,IAAAH,EAEAC,IAAA,EAAAA,EAAA,EAGAC,EAAAN,OAAA,KACAQ,EAAAb,MAAAe,KAAAJ,IACAK,QAAAP,EAAAC,GAEAF,EAAAD,UAAAM,QAMA,IAHAH,GAAAF,EAAAD,OAAAE,EAAAC,GAGAI,EAAAH,EAAAN,SACAQ,EAAAF,EAAAM,MAAAH,IAAA,MACAE,QAAAP,EAAA,GAEAD,EAAAD,UAAAM,GACAC,GAAA,IACAL,GAAA,IAqBO,SAAAS,EAAAV,EAAAG,GACP,OAAAH,EAAAH,OAAA,GACAE,EAAAC,IAAAH,OAAA,EAAAM,GACAH,GAEAG,ECvEA,MAAMQ,EAAc,GAAKC,eA6BzB,SAAAC,EAAAC,EAAAC,GAEA,IAAAC,EACA,IAAAA,KAAAD,EAAA,CACA,MAEAE,GAFkBN,EAAcO,KAAAJ,EAAAE,GAAAF,EAAAE,QAAAG,KAEhCL,EAAAE,GAAA,IAEAI,EAAAL,EAAAC,GAEA,IAAAK,EACA,GAAAD,EACA,IAAAC,KAAAD,EAAA,CACaT,EAAcO,KAAAD,EAAAI,KAAAJ,EAAAI,GAAA,IAC3B,MAAAtC,EAAAqC,EAAAC,GACQC,EAERL,EAAAI,GAAA7B,MAAAC,QAAAV,OAAA,CAAAA,GAAA,MAcA,SAASuC,EAAUC,EAAAvB,GACnB,IAAAJ,GAAA,EAEA,MAAA4B,EAAA,GACA,OAAA5B,EAAAI,EAAAH,SAGA,UAAAG,EAAAJ,GAAA6B,IAAAF,EAAAC,GAAAd,KAAAV,EAAAJ,IAEEG,EAAMwB,EAAA,IAAAC,GCnED,MCaAE,EAAAC,EAAA,YAcAC,EAAAD,EAAA,cAuBAE,EAAAF,EAAA,uBAaA,SAAAG,EAAAT,GACP,OAGA,OAAAA,MAAA,UAAAA,GAeO,MAAAU,EAAAJ,EAAA,MAoBAK,EAAAL,EAAA,cAeAM,EAAAN,EAAA,kBAiBA,SAAAO,EAAAb,GACP,cAAAA,MAAA,EAYO,SAAAc,EAAAd,GACP,cAAAA,MAAA,QAAAA,GAkBO,SAAAe,EAAAf,GACP,WAAAA,IAAA,IAAAA,GAAA,KAAAA,EAwBO,MAAAgB,EAAAV,ED/LA,wwCCqNAW,EAAAX,EAAA,MAQP,SAAAA,EAAAY,GACA,OAUA,SAAAlB,GACA,cAAAA,GAAAkB,EAAAC,KAAAC,OAAAC,aAAArB,KCzMO,SAAAsB,EAAAC,EAAAC,EAAAzD,EAAA0D,GACP,MAAAC,EAAAD,IAAA,EAAAE,OAAAC,kBACA,IAAAC,EAAA,EACA,OAGA,SAAA7B,GACA,GAAQe,EAAaf,GAErB,OADAuB,EAAAO,MAAA/D,GACAgE,EAAA/B,GAEA,OAAAwB,EAAAxB,IAIA,SAAA+B,EAAA/B,GACA,OAAQe,EAAaf,IAAA6B,IAAAH,GACrBH,EAAAS,QAAAhC,GACA+B,IAEAR,EAAAU,KAAAlE,GACAyD,EAAAxB,KCpDO,MAAMkC,EAAO,CACpBC,SAOA,SAAAZ,GACA,MAAAa,EAAAb,EAAAc,QAAAC,KAAAC,OAAAC,WAAAC,eAMA,SAAAzC,GACA,UAAAA,EAEA,YADAuB,EAAAS,QAAAhC,GAMA,OAHAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACWX,EAAYC,EAAAa,EAAA,eAIvB,SAAApC,GAEA,OADAuB,EAAAO,MAAA,aACAY,EAAA1C,KAlBA,IAAA2C,EACA,OAAAP,EAqBA,SAAAM,EAAA1C,GACA,MAAA4C,EAAArB,EAAAO,MAAA,aACAe,YAAA,OACAF,aAMA,OAJAA,IACAA,EAAAG,KAAAF,GAEAD,EAAAC,EACAG,EAAA/C,GAIA,SAAA+C,EAAA/C,GACA,cAAAA,GACAuB,EAAAU,KAAA,aACAV,EAAAU,KAAA,kBACAV,EAAAS,QAAAhC,IAGQa,EAAkBb,IAC1BuB,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,aACAS,IAIAnB,EAAAS,QAAAhC,GACA+C,MCpDO,MAAMC,EAAQ,CACrBb,SAYA,SAAAZ,GACA,MAAA0B,EAAAX,KAEAY,EAAA,GACA,IAEAC,EAEAC,EAEAC,EANAC,EAAA,EAOA,OAAA1E,EAGA,SAAAA,EAAAoB,GAWA,GAAAsD,EAAAJ,EAAA1E,OAAA,CACA,MAAA+E,EAAAL,EAAAI,GAEA,OADAL,EAAAO,eAAAD,EAAA,GACAhC,EAAAc,QAAAkB,EAAA,GAAAE,aAAAC,EAAAC,EAAApC,CAAAvB,GAIA,OAAA2D,EAAA3D,GAIA,SAAA0D,EAAA1D,GAMA,GALAsD,IAKAL,EAAAO,eAAAI,WAAA,CACAX,EAAAO,eAAAI,gBAAA9D,EACAqD,GACAU,IAKA,MAAAC,EAAAb,EAAAc,OAAAvF,OACA,IAEAwF,EAFAC,EAAAH,EAKA,KAAAG,KACA,YAAAhB,EAAAc,OAAAE,GAAA,kBAAAhB,EAAAc,OAAAE,GAAA,GAAAlG,KAAA,CACAiG,EAAAf,EAAAc,OAAAE,GAAA,GAAAlF,IACA,MAGAmF,EAAAZ,GAGA,IAAA/E,EAAAuF,EACA,KAAAvF,EAAA0E,EAAAc,OAAAvF,QACAyE,EAAAc,OAAAxF,GAAA,GAAAQ,IAAAoF,OAAAC,OAAA,GAAoDJ,GACpDzF,IAQA,OAJMG,EAAMuE,EAAAc,OAAAE,EAAA,IAAAhB,EAAAc,OAAA3E,MAAA0E,IAGZb,EAAAc,OAAAvF,OAAAD,EACAoF,EAAA3D,GAEA,OAAApB,EAAAoB,GAIA,SAAA2D,EAAA3D,GAMA,GAAAsD,IAAAJ,EAAA1E,OAAA,CAIA,IAAA2E,EACA,OAAAkB,EAAArE,GAMA,GAAAmD,EAAAmB,kBAAAnB,EAAAmB,iBAAAC,SACA,OAAAC,EAAAxE,GAQAiD,EAAAwB,UAAA5G,QAAAsF,EAAAmB,mBAAAnB,EAAAuB,+BAKA,OADAzB,EAAAO,eAAA,GACAjC,EAAAoD,MAAAC,EAAAC,EAAAC,EAAAvD,CAAAvB,GAIA,SAAA6E,EAAA7E,GAGA,OAFAmD,GAAAU,IACAK,EAAAZ,GACAe,EAAArE,GAIA,SAAA8E,EAAA9E,GAGA,OAFAiD,EAAAV,OAAAwC,KAAA9B,EAAA+B,MAAAC,MAAA3B,IAAAJ,EAAA1E,OACA6E,EAAAJ,EAAA+B,MAAAE,OACAV,EAAAxE,GAIA,SAAAqE,EAAArE,GAGA,OADAiD,EAAAO,eAAA,GACAjC,EAAAc,QAAAuC,EAAAO,EAAAX,EAAAjD,CAAAvB,GAIA,SAAAmF,EAAAnF,GAIA,OAHAsD,IACAJ,EAAA7D,KAAA,CAAA4D,EAAAqB,iBAAArB,EAAAO,iBAEAa,EAAArE,GAIA,SAAAwE,EAAAxE,GACA,cAAAA,GACAmD,GAAAU,IACAK,EAAA,QACA3C,EAAAS,QAAAhC,KAGAmD,KAAAF,EAAAV,OAAA6C,KAAAnC,EAAA+B,OACAzD,EAAAO,MAAA,aACAe,YAAA,OACAF,SAAAS,EACAiC,WAAAlC,IAEAmC,EAAAtF,IAIA,SAAAsF,EAAAtF,GACA,cAAAA,GACAuF,EAAAhE,EAAAU,KAAA,iBACAiC,EAAA,QACA3C,EAAAS,QAAAhC,IAGQa,EAAkBb,IAC1BuB,EAAAS,QAAAhC,GACAuF,EAAAhE,EAAAU,KAAA,cAEAqB,EAAA,EACAL,EAAAwB,eAAA3E,EACAlB,IAEA2C,EAAAS,QAAAhC,GACAsF,GAQA,SAAAC,EAAA3C,EAAA4C,GACA,MAAAC,EAAAxC,EAAAyC,YAAA9C,GAyCA,GAxCA4C,GAAAC,EAAApG,KAAA,MACAuD,EAAAD,SAAAS,EACAA,MAAAN,KAAAF,GACAQ,EAAAR,EACAO,EAAAwC,WAAA/C,EAAAhE,OACAuE,EAAAyC,MAAAH,GAmCAxC,EAAAV,OAAAwC,KAAAnC,EAAAhE,MAAAqG,MAAA,CACA,IAAA1G,EAAA4E,EAAAY,OAAAvF,OACA,KAAAD,KACA,GAEA4E,EAAAY,OAAAxF,GAAA,GAAAK,MAAAsG,OAAA7B,KAEAF,EAAAY,OAAAxF,GAAA,GAAAQ,KAEAoE,EAAAY,OAAAxF,GAAA,GAAAQ,IAAAmG,OAAA7B,GAGA,OAMA,MAAAS,EAAAb,EAAAc,OAAAvF,OACA,IAEAqH,EAEA7B,EAJAC,EAAAH,EAOA,KAAAG,KACA,YAAAhB,EAAAc,OAAAE,GAAA,kBAAAhB,EAAAc,OAAAE,GAAA,GAAAlG,KAAA,CACA,GAAA8H,EAAA,CACA7B,EAAAf,EAAAc,OAAAE,GAAA,GAAAlF,IACA,MAEA8G,GAAA,EAOA,IAJA3B,EAAAZ,GAGA/E,EAAAuF,EACAvF,EAAA0E,EAAAc,OAAAvF,QACAyE,EAAAc,OAAAxF,GAAA,GAAAQ,IAAAoF,OAAAC,OAAA,GAAoDJ,GACpDzF,IAIMG,EAAMuE,EAAAc,OAAAE,EAAA,IAAAhB,EAAAc,OAAA3E,MAAA0E,IAGZb,EAAAc,OAAAvF,OAAAD,GAQA,SAAA2F,EAAArC,GACA,IAAAtD,EAAA2E,EAAA1E,OAGA,KAAAD,KAAAsD,GAAA,CACA,MAAAiE,EAAA5C,EAAA3E,GACA0E,EAAAO,eAAAsC,EAAA,GACAA,EAAA,GAAA7D,KAAApC,KAAAoD,EAAA1B,GAEA2B,EAAA1E,OAAAqD,EAEA,SAAAgC,IACAV,EAAAyC,MAAA,QACAxC,OAAAtD,EACAqD,OAAArD,EACAmD,EAAAO,eAAAI,gBAAA9D,KApTA8E,EAAA,CACAzC,SA2TA,SAAAZ,EAAAC,EAAAuE,GAGA,OAASzE,EAAYC,IAAAc,QAAAC,KAAAC,OAAAC,WAAAwD,SAAAxE,EAAAuE,GAAA,aAAAzD,KAAAC,OAAAC,WAAAyD,QAAAC,KAAAC,SAAA,qBAAArG,EAAA,KC9Ud,MAAAsG,EAAA,CACPjE,SAQA,SAAAZ,EAAAC,EAAAuE,GACA,OAgBA,SAAA/F,GACA,OAAWe,EAAaf,GAASsB,EAAYC,EAAA8E,EAAA,aAAZ/E,CAAYtB,GAAAqG,EAAArG,IAiB7C,SAAAqG,EAAArG,GACA,cAAAA,GAA4Ba,EAAkBb,GAAAwB,EAAAxB,GAAA+F,EAAA/F,KA3C9CsG,SAAA,GCGO,SAAAC,EAAAxC,GAEP,MAAAyC,EAAA,GACA,IAEAC,EAEAC,EAEAC,EAEAC,EAEA5H,EAEA6H,EAEAC,EAdAvI,GAAA,EAeA,OAAAA,EAAAwF,EAAAvF,QAAA,CACA,KAAAD,KAAAiI,GACAjI,EAAAiI,EAAAjI,GAMA,GAJAkI,EAAA1C,EAAAxF,GAIAA,GAAA,cAAAkI,EAAA,GAAA1I,MAAA,mBAAAgG,EAAAxF,EAAA,MAAAR,QAEA4I,EAAA,IADAE,EAAAJ,EAAA,GAAApB,WAAAtB,QAEAvF,QAAA,oBAAAqI,EAAAF,GAAA,GAAA5I,OACA4I,GAAA,GAEAA,EAAAE,EAAArI,QAAA,YAAAqI,EAAAF,GAAA,GAAA5I,MACA,OAAA4I,EAAAE,EAAArI,QACA,YAAAqI,EAAAF,GAAA,GAAA5I,MAGA,cAAA8I,EAAAF,GAAA,GAAA5I,OACA8I,EAAAF,GAAA,GAAAI,6BAAA,EACAJ,KAOA,aAAAF,EAAA,GACAA,EAAA,GAAA5D,cACAsB,OAAAC,OAAAoC,EAAAQ,EAAAjD,EAAAxF,IACAA,EAAAiI,EAAAjI,GACAuI,GAAA,QAIA,GAAAL,EAAA,GAAAQ,WAAA,CAGA,IAFAN,EAAApI,EACAmI,OAAA5G,EACA6G,MAEA,gBADAC,EAAA7C,EAAA4C,IACA,GAAA5I,MAAA,oBAAA6I,EAAA,GAAA7I,OACA,UAAA6I,EAAA,KACAF,IACA3C,EAAA2C,GAAA,GAAA3I,KAAA,mBAEA6I,EAAA,GAAA7I,KAAA,aACA2I,EAAAC,GAMAD,IAEAD,EAAA,GAAA1H,IAAAoF,OAAAC,OAAA,GAAuCL,EAAA2C,GAAA,GAAA9H,QAGvCI,EAAA+E,EAAA3E,MAAAsH,EAAAnI,IACAY,QAAAsH,GACQ/H,EAAMqF,EAAA2C,EAAAnI,EAAAmI,EAAA,EAAA1H,KAId,OAAA8H,EAUA,SAAAE,EAAAjD,EAAAmD,GACA,MAAAtE,EAAAmB,EAAAmD,GAAA,GACAC,EAAApD,EAAAmD,GAAA,GACA,IAAAE,EAAAF,EAAA,EAEA,MAAAG,EAAA,GACAC,EAAA1E,EAAAyC,YAAA8B,EAAA5E,OAAAK,EAAAC,aAAAD,EAAAhE,OACA2I,EAAAD,EAAAvD,OAEAyC,EAAA,GAEAgB,EAAA,GAEA,IAAA/B,EAEA9C,EACApE,GAAA,EAEAkJ,EAAA7E,EACA8E,EAAA,EACA9I,EAAA,EACA,MAAA+I,EAAA,CAAA/I,GAIA,KAAA6I,GAAA,CAEA,KAAA1D,IAAAqD,GAAA,KAAAK,IAGAJ,EAAAhI,KAAA+H,GACAK,EAAApC,aACAI,EAAA0B,EAAAzB,YAAA+B,GACAA,EAAA3E,MACA2C,EAAApG,KAAA,MAEAsD,GACA2E,EAAA3B,WAAA8B,EAAA7I,OAEA6I,EAAAV,8BACAO,EAAAM,oCAAA,GAEAN,EAAA1B,MAAAH,GACAgC,EAAAV,8BACAO,EAAAM,wCAAA9H,IAKA6C,EAAA8E,EACAA,IAAA3E,KAMA,IADA2E,EAAA7E,IACArE,EAAAgJ,EAAA/I,QAGA,SAAA+I,EAAAhJ,GAAA,cAAAgJ,EAAAhJ,EAAA,OAAAgJ,EAAAhJ,GAAA,GAAAR,OAAAwJ,EAAAhJ,EAAA,MAAAR,MAAAwJ,EAAAhJ,GAAA,GAAAK,MAAAqG,OAAAsC,EAAAhJ,GAAA,GAAAQ,IAAAkG,OACArG,EAAAL,EAAA,EACAoJ,EAAAtI,KAAAT,GAEA6I,EAAApC,gBAAAvF,EACA2H,EAAA9E,cAAA7C,EACA2H,IAAA3E,MAqBA,IAhBAwE,EAAAvD,OAAA,GAKA0D,GAEAA,EAAApC,gBAAAvF,EACA2H,EAAA9E,cAAA7C,GAEA6H,EAAAE,MAKAtJ,EAAAoJ,EAAAnJ,OACAD,KAAA,CACA,MAAAa,EAAAmI,EAAAnI,MAAAuI,EAAApJ,GAAAoJ,EAAApJ,EAAA,IACAK,EAAAyI,EAAAQ,MACArB,EAAArH,QAAA,CAAAP,IAAAQ,EAAAZ,OAAA,IACIE,EAAMqF,EAAAnF,EAAA,EAAAQ,GAGV,IADAb,GAAA,IACAA,EAAAiI,EAAAhI,QACAgJ,EAAAE,EAAAlB,EAAAjI,GAAA,IAAAmJ,EAAAlB,EAAAjI,GAAA,GACAmJ,GAAAlB,EAAAjI,GAAA,GAAAiI,EAAAjI,GAAA,KAEA,OAAAiJ,EC5LO,MAAMM,EAAO,CACpB3F,SAyBA,SAAAZ,EAAAC,GAEA,IAAAmB,EACA,OAYA,SAAA3C,GAKA,OAJAuB,EAAAO,MAAA,WACAa,EAAApB,EAAAO,MAAA,gBACAe,YAAA,YAEAkF,EAAA/H,IAaA,SAAA+H,EAAA/H,GACA,cAAAA,EACAgI,EAAAhI,GAKQa,EAAkBb,GAC1BuB,EAAAoD,MAAAsD,EAAAC,EAAAF,EAAAzG,CAAAvB,IAIAuB,EAAAS,QAAAhC,GACA+H,GAQA,SAAAC,EAAAhI,GAGA,OAFAuB,EAAAU,KAAA,gBACAV,EAAAU,KAAA,WACAT,EAAAxB,GAQA,SAAAkI,EAAAlI,GAQA,OAPAuB,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,gBACAU,EAAAG,KAAAvB,EAAAO,MAAA,gBACAe,YAAA,UACAF,aAEAA,IAAAG,KACAiF,IAjGAI,QAeA,SAAApE,GAEA,OADEwC,EAAWxC,GACbA,IAbAkE,EAAA,CACA9F,SAoGA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAOA,SAAAtC,GAKA,OAJAuB,EAAAU,KAAA,gBACAV,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACWX,EAAYC,EAAA6G,EAAA,eAQvB,SAAAA,EAAApI,GACA,UAAAA,GAAyBa,EAAkBb,GAC3C,OAAA+F,EAAA/F,GAKA,MAAAqI,EAAApF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,GACA,OAAAyE,EAAAV,OAAAC,WAAAyD,QAAAC,KAAAC,SAAA,iBAAAkC,GAAA,eAAAA,EAAA,GAAAtK,MAAAsK,EAAA,GAAAC,eAAAD,EAAA,OAAA7J,QAAA,EACAgD,EAAAxB,GAEAuB,EAAAkD,UAAAxB,EAAAV,OAAAC,WAAA4C,KAAAW,EAAAvE,EAAAD,CAAAvB,KApIAsG,SAAA,GCbO,MAAAlB,EAAA,CACPjD,SAOA,SAAAZ,GACA,MAAA0B,EAAAX,KACAiG,EAAAhH,EAAAc,QAEE+D,EAMF,SAAApG,GACA,UAAAA,EAEA,YADAuB,EAAAS,QAAAhC,GAOA,OAJAuB,EAAAO,MAAA,mBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,mBACAgB,EAAAqB,sBAAAxE,EACAyI,GAbAhH,EAAAc,QAAAC,KAAAC,OAAAC,WAAAgG,YAAAC,EAAsEnH,EAAYC,IAAAc,QAAAC,KAAAC,OAAAC,WAAA4C,KAAAqD,EAAAlH,EAAAc,QAAuFyF,EAAOW,IAAA,gBAChL,OAAAF,EAgBA,SAAAE,EAAAzI,GACA,UAAAA,EAQA,OAJAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACAgB,EAAAqB,sBAAAxE,EACAyI,EAPAhH,EAAAS,QAAAhC,MCnCO,MAAA0I,EAAA,CACPC,WAAAC,KAEaC,EAAMC,EAAA,UACNC,EAAID,EAAA,QAMjB,SAAAA,EAAAE,GACA,OACA7G,SAQA,SAAAZ,GACA,MAAA0B,EAAAX,KACAE,EAAAF,KAAAC,OAAAC,WAAAwG,GACAC,EAAA1H,EAAAc,QAAAG,EAAA5D,EAAAsK,GACA,OAAAtK,EAGA,SAAAA,EAAAoB,GACA,OAAAmJ,EAAAnJ,GAAAiJ,EAAAjJ,GAAAkJ,EAAAlJ,GAIA,SAAAkJ,EAAAlJ,GACA,UAAAA,EAMA,OAFAuB,EAAAO,MAAA,QACAP,EAAAS,QAAAhC,GACA+C,EALAxB,EAAAS,QAAAhC,GASA,SAAA+C,EAAA/C,GACA,OAAAmJ,EAAAnJ,IACAuB,EAAAU,KAAA,QACAgH,EAAAjJ,KAIAuB,EAAAS,QAAAhC,GACA+C,GAOA,SAAAoG,EAAAnJ,GACA,UAAAA,EACA,SAEA,MAAArB,EAAA6D,EAAAxC,GACA,IAAAzB,GAAA,EACA,GAAAI,EAGA,OAAAJ,EAAAI,EAAAH,QAAA,CACA,MAAA+E,EAAA5E,EAAAJ,GACA,IAAAgF,EAAAZ,UAAAY,EAAAZ,SAAA9C,KAAAoD,IAAAN,UACA,SAIA,WA7DAgG,WAAAC,EAAA,SAAAI,EAAAI,OAAAtJ,IAsEA,SAAA8I,EAAAS,GACA,OAGA,SAAAtF,EAAAoD,GACA,IAEArF,EAFAvD,GAAA,EAMA,OAAAA,GAAAwF,EAAAvF,aACAsB,IAAAgC,EACAiC,EAAAxF,IAAA,SAAAwF,EAAAxF,GAAA,GAAAR,OACA+D,EAAAvD,EACAA,KAEOwF,EAAAxF,IAAA,SAAAwF,EAAAxF,GAAA,GAAAR,OAEPQ,IAAAuD,EAAA,IACAiC,EAAAjC,GAAA,GAAA/C,IAAAgF,EAAAxF,EAAA,MAAAQ,IACAgF,EAAArF,OAAAoD,EAAA,EAAAvD,EAAAuD,EAAA,GACAvD,EAAAuD,EAAA,GAEAA,OAAAhC,GAGA,OAAAuJ,IAAAtF,EAAAoD,GAAApD,GAeA,SAAAqF,EAAArF,EAAAoD,GACA,IAAAD,EAAA,EAEA,OAAAA,GAAAnD,EAAAvF,QACA,IAAA0I,IAAAnD,EAAAvF,QAAA,eAAAuF,EAAAmD,GAAA,GAAAnJ,OAAA,SAAAgG,EAAAmD,EAAA,MAAAnJ,KAAA,CACA,MAAAgF,EAAAgB,EAAAmD,EAAA,MACAoC,EAAAnC,EAAAzB,YAAA3C,GACA,IAIAwG,EAJAhL,EAAA+K,EAAA9K,OACAgL,GAAA,EACA3H,EAAA,EAGA,KAAAtD,KAAA,CACA,MAAAkL,EAAAH,EAAA/K,GACA,qBAAAkL,EAAA,CAEA,IADAD,EAAAC,EAAAjL,OACA,KAAAiL,EAAAC,WAAAF,EAAA,IACA3H,IACA2H,IAEA,GAAAA,EAAA,MACAA,GAAA,OAGA,QAAAC,EACAF,GAAA,EACA1H,SACS,QAAA4H,EAEA,CAETlL,IACA,OAGA,GAAAsD,EAAA,CACA,MAAAe,EAAA,CACA7E,KAAAmJ,IAAAnD,EAAAvF,QAAA+K,GAAA1H,EAAA,mCACAjD,MAAA,CACAqG,KAAAlC,EAAAhE,IAAAkG,KACA0E,OAAA5G,EAAAhE,IAAA4K,OAAA9H,EACAqD,OAAAnC,EAAAhE,IAAAmG,OAAArD,EACA+H,OAAA7G,EAAAnE,MAAAgL,OAAArL,EACAsL,aAAAtL,EAAAiL,EAAAzG,EAAAnE,MAAAiL,aAAAL,GAEAzK,IAAAoF,OAAAC,OAAA,GAA+BrB,EAAAhE,MAE/BgE,EAAAhE,IAAAoF,OAAAC,OAAA,GAAmCxB,EAAAhE,OACnCmE,EAAAnE,MAAAsG,SAAAnC,EAAAhE,IAAAmG,OACAf,OAAAC,OAAArB,EAAAH,IAEAmB,EAAArF,OAAAwI,EAAA,WAAAtE,EAAAuE,GAAA,QAAAvE,EAAAuE,IACAD,GAAA,GAGAA,IAGA,OAAAnD,EC9KO,SAAA4E,EAAAnG,EAAAuB,EAAAoD,GAEP,MAAA2C,EAAA,GACA,IAAAvL,GAAA,EACA,OAAAA,EAAAiE,EAAAhE,QAAA,CACA,MAAA2J,EAAA3F,EAAAjE,GAAAoK,WACAR,IAAA2B,EAAA3D,SAAAgC,KACApE,EAAAoE,EAAApE,EAAAoD,GACA2C,EAAAzK,KAAA8I,IAGA,OAAApE,ECkBO,SAAAgG,EAAAxH,EAAAyH,EAAA9K,GAEP,IAAA8E,EAAAG,OAAAC,OAAAlF,EAAAiF,OAAAC,OAAA,GAAmDlF,GAAA,CACnD+F,KAAA,EACA0E,OAAA,EACAzE,OAAA,GACG,CACH0E,OAAA,EACAC,cAAA,IAGA,MAAAI,EAAA,GAEAC,EAAA,GAEA,IAAAZ,EAAA,GAEApG,EAAA,GAEAiH,GAAA,EAOA,MAAA5I,EAAA,CACAS,QAqJA,SAAAhC,GACQa,EAAkBb,IAC1BgE,EAAAiB,OACAjB,EAAA2F,OAAA,EACA3F,EAAAkB,SAAA,IAAAlF,EAAA,IACAoK,MACK,IAAApK,IACLgE,EAAA2F,SACA3F,EAAAkB,UAIAlB,EAAA6F,aAAA,EACA7F,EAAA4F,UAEA5F,EAAA6F,eAKA7F,EAAA6F,eAAAP,EAAAtF,EAAA4F,QAAApL,SACAwF,EAAA6F,cAAA,EACA7F,EAAA4F,WAKAzC,EAAAxE,SAAA3C,EAGAmK,GAAA,GAlLArI,MAsLA,SAAA/D,EAAAsM,GAGA,MAAAzH,EAAAyH,GAAA,GAKA,OAJAzH,EAAA7E,OACA6E,EAAAhE,MAAAoG,IACAmC,EAAApD,OAAA1E,KAAA,SAAAuD,EAAAuE,IACAjE,EAAA7D,KAAAuD,GACAA,GA7LAX,KAiMA,SAAAlE,GACA,MAAA6E,EAAAM,EAAA2E,MAGA,OAFAjF,EAAA7D,IAAAiG,IACAmC,EAAApD,OAAA1E,KAAA,QAAAuD,EAAAuE,IACAvE,GApMAP,QAAAiI,EA4MA,SAAAC,EAAAC,GACAC,EAAAF,EAAAC,EAAAtL,QA5MAyF,MAAA2F,EAAAI,GACAjG,UAAA6F,EAAAI,EAAA,CACAjG,WAAA,KASA0C,EAAA,CACAxE,SAAA,KACA3C,KAAA,KACAwD,eAAA,GACAO,OAAA,GACAxB,SACAmD,cACA4C,eA6CA,SAAA1F,EAAA+H,GACA,OAwXA,SAAArB,EAAAqB,GACA,IAAApM,GAAA,EAEA,MAAAD,EAAA,GAEA,IAAAsM,EACA,OAAArM,EAAA+K,EAAA9K,QAAA,CACA,MAAAiL,EAAAH,EAAA/K,GAEA,IAAAb,EACA,qBAAA+L,EACA/L,EAAA+L,OACK,OAAAA,GACL,OAEA/L,EAAA,KACA,MAEA,OAEAA,EAAA,KACA,MAEA,OAEAA,EAAA,OACA,MAEA,OAEAA,EAAAiN,EAAA,SACA,MAEA,OAEA,IAAAA,GAAAC,EAAA,SACAlN,EAAA,IACA,MAEA,QAGAA,EAAA0D,OAAAC,aAAAoI,GAGAmB,GAAA,IAAAnB,EACAnL,EAAAe,KAAA3B,GAEA,OAAAY,EAAAG,KAAA,IAxaAoM,CAAAnF,EAAA9C,GAAA+H,IA7CA3F,MACAW,WAwEA,SAAAjI,GACAuM,EAAAvM,EAAAuH,MAAAvH,EAAAiM,OACAS,KAzEAxE,MAsBA,SAAAxG,GAKA,GAJAkK,EAAajK,EAAIiK,EAAAlK,GAmEjB,WAEA,IAAA0L,EACA,KAAA9G,EAAA4F,OAAAN,EAAA9K,QAAA,CACA,MAAAiL,EAAAH,EAAAtF,EAAA4F,QAGA,qBAAAH,EAKA,IAJAqB,EAAA9G,EAAA4F,OACA5F,EAAA6F,aAAA,IACA7F,EAAA6F,aAAA,GAEA7F,EAAA4F,SAAAkB,GAAA9G,EAAA6F,aAAAJ,EAAAjL,QACAuM,EAAAtB,EAAAC,WAAA1F,EAAA6F,oBAGAkB,EAAAtB,IAlFAuB,GAGA,OAAA1B,IAAA9K,OAAA,GACA,SAMA,OAJAiM,EAAAT,EAAA,GAGA7C,EAAApD,OAAqB4E,EAAUuB,EAAA/C,EAAApD,OAAAoD,GAC/BA,EAAApD,SA1BA,IAOAkH,EAPAC,EAAAlB,EAAA7H,SAAAtC,KAAAsH,EAAA5F,GAWA,OAHAyI,EAAArB,YACAuB,EAAA7K,KAAA2K,GAEA7C,EA4BA,SAAAzB,EAAA9C,GACA,OAgVA,SAAA0G,EAAA1G,GACA,MAAAuI,EAAAvI,EAAAhE,MAAAgL,OACAwB,EAAAxI,EAAAhE,MAAAiL,aACAwB,EAAAzI,EAAA7D,IAAA6K,OACA0B,EAAA1I,EAAA7D,IAAA8K,aAEA,IAAA0B,EACA,GAAAJ,IAAAE,EAEAE,EAAA,CAAAjC,EAAA6B,GAAA/L,MAAAgM,EAAAE,QACG,CAEH,GADAC,EAAAjC,EAAAlK,MAAA+L,EAAAE,GACAD,GAAA,GACA,MAAAI,EAAAD,EAAA,GACA,kBAAAC,EACAD,EAAA,GAAAC,EAAApM,MAAAgM,GAEAG,EAAAE,QAGAH,EAAA,GAEAC,EAAAlM,KAAAiK,EAAA+B,GAAAjM,MAAA,EAAAkM,IAGA,OAAAC,EAzWAG,CAAApC,EAAA1G,GAIA,SAAAoC,IAEA,MAAAC,KACAA,EAAA0E,OACAA,EAAAzE,OACAA,EAAA0E,OACAA,EAAAC,aACAA,GACK7F,EACL,OACAiB,OACA0E,SACAzE,SACA0E,SACAC,gBAmDA,SAAAkB,EAAA/K,GACAmK,OAAArK,EACAmL,EAAAjL,EACAkL,IAAAlL,GAuEA,SAAA0K,EAAAiB,EAAAnB,GACAA,EAAAoB,UASA,SAAAtB,EAAAuB,EAAAxB,GACA,OAWA,SAAA7H,EAAAsJ,EAAAC,GAEA,IAAAC,EAEAC,EAEA3H,EAEAkG,EACA,OAAArM,MAAAC,QAAAoE,GAAA0J,EAAA1J,GAAA,aAAAA,EAEA0J,EAAA,CAAA1J,IAQA,SAAA2J,GACA,OAGA,SAAAnM,GACA,MAAAoM,EAAA,OAAApM,GAAAmM,EAAAnM,GACAP,EAAA,OAAAO,GAAAmM,EAAAjG,KAKA,OAAAgG,EAJA,IAGA/N,MAAAC,QAAAgO,OAAA,CAAAA,GAAA,MAAAjO,MAAAC,QAAAqB,OAAA,CAAAA,GAAA,IACAyM,CAAAlM,IAnBAqM,CAAA7J,GA6BA,SAAA0J,EAAAvN,GAGA,OAFAqN,EAAArN,EACAsN,EAAA,EACA,IAAAtN,EAAAH,OACAuN,EAEAO,EAAA3N,EAAAsN,IASA,SAAAK,EAAA/B,GACA,OAGA,SAAAvK,GAKAwK,EA4DA,WACA,MAAA+B,EAAAvH,IACAwH,EAAArF,EAAAxE,SACA8J,EAAAtF,EAAA7C,iBACAoI,EAAAvF,EAAApD,OAAAvF,OACAmO,EAAAxO,MAAAe,KAAAgE,GACA,OACA0I,QASA,WACA5H,EAAAuI,EACApF,EAAAxE,SAAA6J,EACArF,EAAA7C,iBAAAmI,EACAtF,EAAApD,OAAAvF,OAAAkO,EACAxJ,EAAAyJ,EACAvC,KAdAlL,KAAAwN,GApEAE,GACAtI,EAAAiG,EACAA,EAAAjE,UACAa,EAAA7C,iBAAAiG,GAKA,GAAAA,EAAAsC,MAAA1F,EAAA5E,OAAAC,WAAAyD,QAAAC,KAAAC,SAAAoE,EAAAsC,MACA,OAAA9G,EAAA/F,GAEA,OAAAuK,EAAApI,SAAAtC,KAIAwK,EAAAlG,OAAAC,OAAAD,OAAA2I,OAAA3F,GAAAkD,GAAAlD,EAAA5F,EAAAC,EAAAuE,EAJAwE,CAIAvK,IAKA,SAAAwB,EAAAxB,GAGA,OAFAmK,GAAA,EACA0B,EAAAvH,EAAAkG,GACAsB,EAIA,SAAA/F,EAAA/F,GAGA,OAFAmK,GAAA,EACAK,EAAAoB,YACAK,EAAAD,EAAAxN,OACA8N,EAAAN,EAAAC,IAEAF,IAUA,SAAAtB,EAAAF,EAAArL,GACAqL,EAAA5B,aAAAuB,EAAA/D,SAAAoE,IACAL,EAAA7K,KAAAkL,GAEAA,EAAApC,SACMzJ,EAAMyI,EAAApD,OAAA7E,EAAAiI,EAAApD,OAAAvF,OAAAU,EAAAqL,EAAApC,QAAAhB,EAAApD,OAAA3E,MAAAF,GAAAiI,IAEZoD,EAAAwC,YACA5F,EAAApD,OAAAwG,EAAAwC,UAAA5F,EAAApD,OAAAoD,IAyCA,SAAAiD,IACApG,EAAAiB,QAAAgF,GAAAjG,EAAA2F,OAAA,IACA3F,EAAA2F,OAAAM,EAAAjG,EAAAiB,MACAjB,EAAAkB,QAAA+E,EAAAjG,EAAAiB,MAAA,IC5cO,MAAM+H,EAAa,CAC1BH,KAAA,gBACA1K,SAOA,SAAAZ,EAAAC,EAAAuE,GACA,IAEAkH,EAFApL,EAAA,EAGA,OAYA,SAAA7B,GAGA,OAFAuB,EAAAO,MAAA,iBAeA,SAAA9B,GAEA,OADAiN,EAAAjN,EACAmJ,EAAAnJ,GAfAG,CAAAH,IA4BA,SAAAmJ,EAAAnJ,GACA,OAAAA,IAAAiN,GACA1L,EAAAO,MAAA,yBACAoL,EAAAlN,IAEA6B,GAAA,WAAA7B,GAAuCa,EAAkBb,KACzDuB,EAAAU,KAAA,iBACAT,EAAAxB,IAEA+F,EAAA/F,GAaA,SAAAkN,EAAAlN,GACA,OAAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACA6B,IACAqL,IAEA3L,EAAAU,KAAA,yBACWlB,EAAaf,GAASsB,EAAYC,EAAA4H,EAAA,aAAZ7H,CAAYtB,GAAAmJ,EAAAnJ,OChFtC,MAAMmN,EAAI,CACjBN,KAAA,OACA1K,SA0BA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA+F,EAAApF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,GACA,IAAA4O,EAAA/E,GAAA,eAAAA,EAAA,GAAAtK,KAAAsK,EAAA,GAAAC,eAAAD,EAAA,OAAA7J,OAAA,EACAqD,EAAA,EACA,OAGA,SAAA7B,GACA,MAAAqN,EAAApK,EAAAO,eAAAzF,OAAA,KAAAiC,GAAA,KAAAA,GAAA,KAAAA,EAAA,+BACA,qBAAAqN,GAAApK,EAAAO,eAAAyJ,QAAAjN,IAAAiD,EAAAO,eAAAyJ,OAAwGvM,EAAUV,GAAA,CAOlH,GANAiD,EAAAO,eAAAzF,OACAkF,EAAAO,eAAAzF,KAAAsP,EACA9L,EAAAO,MAAAuL,EAAA,CACApG,YAAA,KAGA,kBAAAoG,EAEA,OADA9L,EAAAO,MAAA,kBACA,KAAA9B,GAAA,KAAAA,EAAAuB,EAAAoD,MAA0DqI,EAAajH,EAAAuH,EAAvE/L,CAAuEvB,GAAAsN,EAAAtN,GAEvE,IAAAiD,EAAAwB,WAAA,KAAAzE,EAGA,OAFAuB,EAAAO,MAAA,kBACAP,EAAAO,MAAA,iBACAyL,EAAAvN,GAGA,OAAA+F,EAAA/F,IAIA,SAAAuN,EAAAvN,GACA,OAAQU,EAAUV,MAAA6B,EAAA,IAClBN,EAAAS,QAAAhC,GACAuN,KAEAtK,EAAAwB,WAAA5C,EAAA,KAAAoB,EAAAO,eAAAyJ,OAAAjN,IAAAiD,EAAAO,eAAAyJ,OAAA,KAAAjN,GAAA,KAAAA,IACAuB,EAAAU,KAAA,iBACAqL,EAAAtN,IAEA+F,EAAA/F,GAMA,SAAAsN,EAAAtN,GAKA,OAJAuB,EAAAO,MAAA,kBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,kBACAgB,EAAAO,eAAAyJ,OAAAhK,EAAAO,eAAAyJ,QAAAjN,EACAuB,EAAAoD,MAAyByB,EAEzBnD,EAAAwB,UAAAsB,EAAAyH,EAAAjM,EAAAc,QAAAoL,EAAAC,EAAAC,IAIA,SAAAH,EAAAxN,GAGA,OAFAiD,EAAAO,eAAAoK,kBAAA,EACAR,IACAM,EAAA1N,GAIA,SAAA2N,EAAA3N,GACA,OAAQe,EAAaf,IACrBuB,EAAAO,MAAA,4BACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,4BACAyL,GAEA3H,EAAA/F,GAIA,SAAA0N,EAAA1N,GAEA,OADAiD,EAAAO,eAAA3B,KAAAuL,EAAAnK,EAAAqF,eAAA/G,EAAAU,KAAA,sBAAAzD,OACAgD,EAAAxB,KAtGAyD,aAAA,CACAtB,SA6GA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KAEA,OADAW,EAAAO,eAAAI,gBAAA9D,EACAyB,EAAAoD,MAAuByB,EAGvB,SAAApG,GAKA,OAJAiD,EAAAO,eAAAqK,kBAAA5K,EAAAO,eAAAqK,mBAAA5K,EAAAO,eAAAoK,iBAIWtM,EAAYC,EAAAC,EAAA,iBAAAyB,EAAAO,eAAA3B,KAAA,EAAZP,CAAYtB,IAIvB,SAAAA,GACA,OAAAiD,EAAAO,eAAAqK,oBAAkD9M,EAAaf,IAC/DiD,EAAAO,eAAAqK,uBAAA/N,EACAmD,EAAAO,eAAAoK,sBAAA9N,EACAgO,EAAA9N,KAEAiD,EAAAO,eAAAqK,uBAAA/N,EACAmD,EAAAO,eAAAoK,sBAAA9N,EACAyB,EAAAc,QAAA0L,EAAAvM,EAAAsM,EAAAvM,CAAAvB,MAIA,SAAA8N,EAAA9N,GAOA,OALAiD,EAAAO,eAAAI,YAAA,EAEAX,EAAAwB,eAAA3E,EAGWwB,EAAYC,IAAAc,QAA0B8K,EAAI3L,EAAAuE,GAAA,aAAA9C,EAAAV,OAAAC,WAAAyD,QAAAC,KAAAC,SAAA,qBAAArG,EAAA,EAA1CwB,CAA0CtB,MA7IrDiC,KAoKA,SAAAV,GACAA,EAAAU,KAAAK,KAAAkB,eAAAzF,QAjKA0P,EAAA,CACAtL,SAuKA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KAIA,OAAShB,EAAYC,EAGrB,SAAAvB,GACA,MAAAqI,EAAApF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,GACA,OAAYuC,EAAaf,IAAAqI,GAAA,6BAAAA,EAAA,GAAAtK,KAAAyD,EAAAxB,GAAA+F,EAAA/F,IALJ,2BAAAiD,EAAAV,OAAAC,WAAAyD,QAAAC,KAAAC,SAAA,qBAAArG,EAAA,IA3KrBwG,SAAA,GAIAyH,EAAA,CACA5L,SA0IA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAAShB,EAAYC,EAGrB,SAAAvB,GACA,MAAAqI,EAAApF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,GACA,OAAA6J,GAAA,mBAAAA,EAAA,GAAAtK,MAAAsK,EAAA,GAAAC,eAAAD,EAAA,OAAA7J,SAAAyE,EAAAO,eAAA3B,KAAAL,EAAAxB,GAAA+F,EAAA/F,IALqB,iBAAAiD,EAAAO,eAAA3B,KAAA,IA3IrByE,SAAA,GCvBO,MAAM0H,EAAU,CACvBnB,KAAA,aACA1K,SAWA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAYA,SAAAtC,GACA,QAAAA,EAAA,CACA,MAAAkL,EAAAjI,EAAAO,eAWA,OAVA0H,EAAA+C,OACA1M,EAAAO,MAAA,cACAmF,YAAA,IAEAiE,EAAA+C,MAAA,GAEA1M,EAAAO,MAAA,oBACAP,EAAAO,MAAA,oBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,oBACAoE,EAEA,OAAAN,EAAA/F,IAaA,SAAAqG,EAAArG,GACA,OAAQe,EAAaf,IACrBuB,EAAAO,MAAA,8BACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,8BACAV,EAAAU,KAAA,oBACAT,IAEAD,EAAAU,KAAA,oBACAT,EAAAxB,MA7DAyD,aAAA,CACAtB,SA4EA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAeA,SAAAtC,GACA,GAAQe,EAAaf,GAGrB,OAAasB,EAAYC,EAAA2M,EAAA,aAAAjL,EAAAV,OAAAC,WAAAyD,QAAAC,KAAAC,SAAA,qBAAArG,EAAA,EAAZwB,CAAYtB,GAEzB,OAAAkO,EAAAlO,IAgBA,SAAAkO,EAAAlO,GACA,OAAAuB,EAAAc,QAA2B2L,EAAUxM,EAAAuE,EAArCxE,CAAqCvB,MAlHrCiC,KAuHA,SAAaV,GACbA,EAAAU,KAAA,gBC7FO,SAAAkM,EAAA5M,EAAAC,EAAAuE,EAAAhI,EAAAqQ,EAAAC,EAAAC,EAAAC,EAAA9M,GACP,MAAAC,EAAAD,GAAAE,OAAAC,kBACA,IAAA4M,EAAA,EACA,OAcA,SAAAxO,GACA,QAAAA,EAMA,OALAuB,EAAAO,MAAA/D,GACAwD,EAAAO,MAAAsM,GACA7M,EAAAO,MAAAuM,GACA9M,EAAAS,QAAAhC,GACAuB,EAAAU,KAAAoM,GACAI,EAIA,UAAAzO,GAAA,KAAAA,GAAA,KAAAA,GAAuDS,EAAYT,GACnE,OAAA+F,EAAA/F,GAQA,OANAuB,EAAAO,MAAA/D,GACAwD,EAAAO,MAAAwM,GACA/M,EAAAO,MAAAyM,GACAhN,EAAAO,MAAA,eACAe,YAAA,WAEA6L,EAAA1O,IAaA,SAAAyO,EAAAzO,GACA,YAAAA,GACAuB,EAAAO,MAAAuM,GACA9M,EAAAS,QAAAhC,GACAuB,EAAAU,KAAAoM,GACA9M,EAAAU,KAAAmM,GACA7M,EAAAU,KAAAlE,GACAyD,IAEAD,EAAAO,MAAAyM,GACAhN,EAAAO,MAAA,eACAe,YAAA,WAEA8L,EAAA3O,IAaA,SAAA2O,EAAA3O,GACA,YAAAA,GACAuB,EAAAU,KAAA,eACAV,EAAAU,KAAAsM,GACAE,EAAAzO,IAEA,OAAAA,GAAA,KAAAA,GAAwCa,EAAkBb,GAC1D+F,EAAA/F,IAEAuB,EAAAS,QAAAhC,GACA,KAAAA,EAAA4O,EAAAD,GAaA,SAAAC,EAAA5O,GACA,YAAAA,GAAA,KAAAA,GAAA,KAAAA,GACAuB,EAAAS,QAAAhC,GACA2O,GAEAA,EAAA3O,GAaA,SAAA0O,EAAA1O,GACA,OAAAwO,GAAA,OAAAxO,GAAA,KAAAA,IAAqDc,EAAyBd,GAO9EwO,EAAA9M,GAAA,KAAA1B,GACAuB,EAAAS,QAAAhC,GACAwO,IACAE,GAEA,KAAA1O,GACAuB,EAAAS,QAAAhC,GACAwO,IACAE,GAMA,OAAA1O,GAAA,KAAAA,GAAA,KAAAA,GAAuDS,EAAYT,GACnE+F,EAAA/F,IAEAuB,EAAAS,QAAAhC,GACA,KAAAA,EAAA6O,EAAAH,IAxBAnN,EAAAU,KAAA,eACAV,EAAAU,KAAAsM,GACAhN,EAAAU,KAAAqM,GACA/M,EAAAU,KAAAlE,GACAyD,EAAAxB,IAiCA,SAAA6O,EAAA7O,GACA,YAAAA,GAAA,KAAAA,GAAA,KAAAA,GACAuB,EAAAS,QAAAhC,GACA0O,GAEAA,EAAA1O,ICtKO,SAAA8O,EAAAvN,EAAAC,EAAAuE,EAAAhI,EAAAgR,EAAAR,GACP,MAAAtL,EAAAX,KACA,IAEAuD,EAFAhE,EAAA,EAGA,OAYA,SAAA7B,GAMA,OALAuB,EAAAO,MAAA/D,GACAwD,EAAAO,MAAAiN,GACAxN,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA8M,GACAxN,EAAAO,MAAAyM,GACApF,GAaA,SAAAA,EAAAnJ,GACA,OAAA6B,EAAA,YAAA7B,GAAA,KAAAA,GAAA,KAAAA,IAAA6F,GAMA,KAAA7F,IAAA6B,GAAA,2BAAAoB,EAAAV,OAAAC,WACAuD,EAAA/F,GAEA,KAAAA,GACAuB,EAAAU,KAAAsM,GACAhN,EAAAO,MAAAiN,GACAxN,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA8M,GACAxN,EAAAU,KAAAlE,GACAyD,GAIQX,EAAkBb,IAC1BuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACAkH,IAEA5H,EAAAO,MAAA,eACAe,YAAA,WAEAmM,EAAAhP,IAaA,SAAAgP,EAAAhP,GACA,cAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAuDa,EAAkBb,IAAA6B,IAAA,KACzEN,EAAAU,KAAA,eACAkH,EAAAnJ,KAEAuB,EAAAS,QAAAhC,GACA6F,OAAuB9E,EAAaf,IACpC,KAAAA,EAAAiP,EAAAD,GAaA,SAAAC,EAAAjP,GACA,YAAAA,GAAA,KAAAA,GAAA,KAAAA,GACAuB,EAAAS,QAAAhC,GACA6B,IACAmN,GAEAA,EAAAhP,ICvGO,SAAAkP,EAAA3N,EAAAC,EAAAuE,EAAAhI,EAAAgR,EAAAR,GAEP,IAAAtB,EACA,OAYA,SAAAjN,GACA,QAAAA,GAAA,KAAAA,GAAA,KAAAA,EAMA,OALAuB,EAAAO,MAAA/D,GACAwD,EAAAO,MAAAiN,GACAxN,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA8M,GACA9B,EAAA,KAAAjN,EAAA,GAAAA,EACAmP,EAEA,OAAApJ,EAAA/F,IAeA,SAAAmP,EAAAnP,GACA,OAAAA,IAAAiN,GACA1L,EAAAO,MAAAiN,GACAxN,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA8M,GACAxN,EAAAU,KAAAlE,GACAyD,IAEAD,EAAAO,MAAAyM,GACApF,EAAAnJ,IAaA,SAAAmJ,EAAAnJ,GACA,OAAAA,IAAAiN,GACA1L,EAAAU,KAAAsM,GACAY,EAAAlC,IAEA,OAAAjN,EACA+F,EAAA/F,GAIQa,EAAkBb,IAE1BuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACaX,EAAYC,EAAA4H,EAAA,gBAEzB5H,EAAAO,MAAA,eACAe,YAAA,WAEA0K,EAAAvN,IAQA,SAAAuN,EAAAvN,GACA,OAAAA,IAAAiN,GAAA,OAAAjN,GAA4Ca,EAAkBb,IAC9DuB,EAAAU,KAAA,eACAkH,EAAAnJ,KAEAuB,EAAAS,QAAAhC,GACA,KAAAA,EAAAoP,EAAA7B,GAaA,SAAA6B,EAAApP,GACA,OAAAA,IAAAiN,GAAA,KAAAjN,GACAuB,EAAAS,QAAAhC,GACAuN,GAEAA,EAAAvN,IChIO,SAAAqP,EAAA9N,EAAAC,GAEP,IAAAqE,EACA,OAGA,SAAAjH,EAAAoB,GACA,GAAQa,EAAkBb,GAK1B,OAJAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACA4D,GAAA,EACAjH,EAEA,GAAQmC,EAAaf,GACrB,OAAasB,EAAYC,EAAA3C,EAAAiH,EAAA,0BAAZvE,CAAYtB,GAEzB,OAAAwB,EAAAxB,ICvBO,SAAAsP,EAAA5R,GACP,OAAAA,EAEA6R,QAAA,mBAEAA,QAAA,aAOAC,cAAAC,cChBO,MAAMC,GAAU,CACvB7C,KAAA,aACA1K,SAaA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KAEA,IAAAqN,EACA,OAYA,SAAA3P,GAKA,OADAuB,EAAAO,MAAA,cAcA,SAAA9B,GAGA,OAAW8O,EAAYjP,KAAAoD,EAAA1B,EAAAqO,EAEvB7J,EAAA,kEAFW+I,CAEX9O,GAlBAG,CAAAH,IA+BA,SAAA4P,EAAA5P,GAEA,OADA2P,EAAiBL,EAAmBrM,EAAAqF,eAAArF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,OAAAY,MAAA,OACpC,KAAAY,GACAuB,EAAAO,MAAA,oBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,oBACA4N,GAEA9J,EAAA/F,GAaA,SAAA6P,EAAA7P,GAEA,OAAWc,EAAyBd,GAASqP,EAAiB9N,EAAAuO,EAAjBT,CAAiBrP,GAAA8P,EAAA9P,GAa9D,SAAA8P,EAAA9P,GACA,OAAWmO,EAAkB5M,EAAAwO,EAE7BhK,EAAA,qJAFWoI,CAEXnO,GAaA,SAAA+P,EAAA/P,GACA,OAAAuB,EAAAc,QAA2B2N,GAAW3J,IAAtC9E,CAAsCvB,GAetC,SAAAqG,EAAArG,GACA,OAAWe,EAAaf,GAASsB,EAAYC,EAAA0O,EAAA,aAAZ3O,CAAYtB,GAAAiQ,EAAAjQ,GAe7C,SAAAiQ,EAAAjQ,GACA,cAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,cAKAgB,EAAAV,OAAA2N,QAAA7Q,KAAAsQ,GAKAnO,EAAAxB,IAEA+F,EAAA/F,MA/JMgQ,GAAW,CACjB7N,SAsKA,SAAAZ,EAAAC,EAAAuE,GACA,OAcA,SAAA/F,GACA,OAAWc,EAAyBd,GAASqP,EAAiB9N,EAAA4O,EAAjBd,CAAiBrP,GAAA+F,EAAA/F,IAc9D,SAAAmQ,EAAAnQ,GACA,OAAWkP,EAAY3N,EAAA6O,EAAArK,EAAA,kEAAZmJ,CAAYlP,GAavB,SAAAoQ,EAAApQ,GACA,OAAWe,EAAaf,GAASsB,EAAYC,EAAA8O,EAAA,aAAZ/O,CAAYtB,GAAAqQ,EAAArQ,GAa7C,SAAAqQ,EAAArQ,GACA,cAAAA,GAA4Ba,EAAkBb,GAAAwB,EAAAxB,GAAA+F,EAAA/F,KAhO9CsG,SAAA,GCbO,MAAAgK,GAAA,CACPzD,KAAA,eACA1K,SAaA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAgBA,SAAAtC,GAMA,OAHAuB,EAAAO,MAAA,gBAGWR,EAAYC,EAAAgP,EAAA,eAAZjP,CAAYtB,IAavB,SAAAuQ,EAAAvQ,GACA,MAAAqI,EAAApF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,GACA,OAAA6J,GAAA,eAAAA,EAAA,GAAAtK,MAAAsK,EAAA,GAAAC,eAAAD,EAAA,OAAA7J,QAAA,EAAA2K,EAAAnJ,GAAA+F,EAAA/F,GAaA,SAAAmJ,EAAAnJ,GACA,cAAAA,EACAqG,EAAArG,GAEQa,EAAkBb,GAC1BuB,EAAAc,QAA6BmO,GAAYrH,EAAA9C,EAAzC9E,CAAyCvB,IAEzCuB,EAAAO,MAAA,iBACAyL,EAAAvN,IAaA,SAAAuN,EAAAvN,GACA,cAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,iBACAkH,EAAAnJ,KAEAuB,EAAAS,QAAAhC,GACAuN,GAIA,SAAAlH,EAAArG,GAKA,OAJAuB,EAAAU,KAAA,gBAIAT,EAAAxB,MAjGMwQ,GAAY,CAClBrO,SAwGA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAAAmO,EAaA,SAAAA,EAAAzQ,GAGA,OAAAiD,EAAAV,OAAAwC,KAAA9B,EAAA+B,MAAAC,MACAc,EAAA/F,GAEQa,EAAkBb,IAC1BuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACAwO,GASWnP,EAAYC,EAAAgP,EAAA,eAAZjP,CAAYtB,GAavB,SAAAuQ,EAAAvQ,GACA,MAAAqI,EAAApF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,GACA,OAAA6J,GAAA,eAAAA,EAAA,GAAAtK,MAAAsK,EAAA,GAAAC,eAAAD,EAAA,OAAA7J,QAAA,EAAAgD,EAAAxB,GAAmHa,EAAkBb,GAAAyQ,EAAAzQ,GAAA+F,EAAA/F,KAxJrIsG,SAAA,GCNO,MAAAoK,GAAA,CACP7D,KAAA,kBACA1K,SAkEA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KAEA,IAAA2K,EACA,OAaA,SAAAjN,GACA,IAEA2Q,EAFApS,EAAA0E,EAAAc,OAAAvF,OAIA,KAAAD,KAGA,kBAAA0E,EAAAc,OAAAxF,GAAA,GAAAR,MAAA,eAAAkF,EAAAc,OAAAxF,GAAA,GAAAR,MAAA,YAAAkF,EAAAc,OAAAxF,GAAA,GAAAR,KAAA,CACA4S,EAAA,cAAA1N,EAAAc,OAAAxF,GAAA,GAAAR,KACA,MAMA,IAAAkF,EAAAV,OAAAwC,KAAA9B,EAAA+B,MAAAC,QAAAhC,EAAAwB,WAAAkM,GAGA,OAFApP,EAAAO,MAAA,qBACAmL,EAAAjN,EAiBA,SAAAA,GAEA,OADAuB,EAAAO,MAAA,6BACAyL,EAAAvN,GAlBAG,CAAAH,GAEA,OAAA+F,EAAA/F,IA8BA,SAAAuN,EAAAvN,GACA,OAAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACAuN,IAEAhM,EAAAU,KAAA,6BACWlB,EAAaf,GAASsB,EAAYC,EAAA8E,EAAA,aAAZ/E,CAAYtB,GAAAqG,EAAArG,IAc7C,SAAAqG,EAAArG,GACA,cAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,qBACAT,EAAAxB,IAEA+F,EAAA/F,KA9JA+M,UAIA,SAAAhJ,EAAAoD,GAEA,IAEAyJ,EAEA3H,EAEA4H,EANAtS,EAAAwF,EAAAvF,OAUA,KAAAD,KACA,aAAAwF,EAAAxF,GAAA,IACA,eAAAwF,EAAAxF,GAAA,GAAAR,KAAA,CACA6S,EAAArS,EACA,MAEA,cAAAwF,EAAAxF,GAAA,GAAAR,OACAkL,EAAA1K,OAKA,YAAAwF,EAAAxF,GAAA,GAAAR,MAEAgG,EAAArF,OAAAH,EAAA,GAEAsS,GAAA,eAAA9M,EAAAxF,GAAA,GAAAR,OACA8S,EAAAtS,GAIA,MAAAuS,EAAA,CACA/S,KAAA,gBACAa,MAAAuF,OAAAC,OAAA,GAA2BL,EAAAkF,GAAA,GAAArK,OAC3BG,IAAAoF,OAAAC,OAAA,GAAyBL,IAAAvF,OAAA,MAAAO,MAIzBgF,EAAAkF,GAAA,GAAAlL,KAAA,oBAIA8S,GACA9M,EAAArF,OAAAuK,EAAA,WAAA6H,EAAA3J,IACApD,EAAArF,OAAAmS,EAAA,YAAA9M,EAAA6M,GAAA,GAAAzJ,IACApD,EAAA6M,GAAA,GAAA7R,IAAAoF,OAAAC,OAAA,GAA6CL,EAAA8M,GAAA,GAAA9R,MAE7CgF,EAAA6M,GAAA,GAAAE,EAKA,OADA/M,EAAA1E,KAAA,QAAAyR,EAAA3J,IACApD,IC1DO,MAAAgN,GAAA,keAcAC,GAAA,oCCfAC,GAAA,CACPpE,KAAA,WACA1K,SAsCA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KAEA,IAAA2K,EAEAiE,EAEAC,EAEA5S,EAEA6S,EACA,OAYA,SAAApR,GAEA,OAaA,SAAAA,GAIA,OAHAuB,EAAAO,MAAA,YACAP,EAAAO,MAAA,gBACAP,EAAAS,QAAAhC,GACAiO,EAjBA9N,CAAAH,IAkCA,SAAAiO,EAAAjO,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAqR,GAEA,KAAArR,GACAuB,EAAAS,QAAAhC,GACAkR,GAAA,EACAI,GAEA,KAAAtR,GACAuB,EAAAS,QAAAhC,GACAiN,EAAA,EAMAhK,EAAAwB,UAAAjD,EAAA+P,GAIQlR,EAAUL,IAClBuB,EAAAS,QAAAhC,GAEAmR,EAAA/P,OAAAC,aAAArB,GACAwR,GAEAzL,EAAA/F,GAiBA,SAAAqR,EAAArR,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAiN,EAAA,EACAwE,GAEA,KAAAzR,GACAuB,EAAAS,QAAAhC,GACAiN,EAAA,EACA1O,EAAA,EACAmT,GAIQrR,EAAUL,IAClBuB,EAAAS,QAAAhC,GACAiN,EAAA,EAGAhK,EAAAwB,UAAAjD,EAAA+P,GAEAxL,EAAA/F,GAaA,SAAAyR,EAAAzR,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GAGAiD,EAAAwB,UAAAjD,EAAA+P,GAEAxL,EAAA/F,GAaA,SAAA0R,EAAA1R,GAEA,OAAAA,IADA,SACA0J,WAAAnL,MACAgD,EAAAS,QAAAhC,GACAzB,IAHA,SAGAC,OAGAyE,EAAAwB,UAAAjD,EAAAiC,EAEAiO,GAEA3L,EAAA/F,GAaA,SAAAsR,EAAAtR,GACA,OAAQK,EAAUL,IAClBuB,EAAAS,QAAAhC,GAEAmR,EAAA/P,OAAAC,aAAArB,GACAwR,GAEAzL,EAAA/F,GAeA,SAAAwR,EAAAxR,GACA,UAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAuDc,EAAyBd,GAAA,CAChF,MAAA2R,EAAA,KAAA3R,EACA6M,EAAAsE,EAAA3B,cACA,OAAAmC,GAAAT,IAAmCF,GAAY7K,SAAA0G,GAMrCkE,GAAc5K,SAAAgL,EAAA3B,gBACxBvC,EAAA,EACA0E,GACApQ,EAAAS,QAAAhC,GACA4R,GAKA3O,EAAAwB,UAAAjD,EAAAxB,GAAAyD,EAAAzD,KAEAiN,EAAA,EAEAhK,EAAAwB,YAAAxB,EAAAV,OAAAwC,KAAA9B,EAAA+B,MAAAC,MAAAc,EAAA/F,GAAAkR,EAAAW,EAAA7R,GAAA8R,EAAA9R,KAlBAiN,EAAA,EAGAhK,EAAAwB,UAAAjD,EAAAxB,GAAAyD,EAAAzD,IAmBA,YAAAA,GAAuBO,EAAiBP,IACxCuB,EAAAS,QAAAhC,GACAmR,GAAA/P,OAAAC,aAAArB,GACAwR,GAEAzL,EAAA/F,GAaA,SAAA4R,EAAA5R,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GAGAiD,EAAAwB,UAAAjD,EAAAiC,GAEAsC,EAAA/F,GAaA,SAAA6R,EAAA7R,GACA,OAAQe,EAAaf,IACrBuB,EAAAS,QAAAhC,GACA6R,GAEAE,EAAA/R,GA0BA,SAAA8R,EAAA9R,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACA+R,GAIA,KAAA/R,GAAA,KAAAA,GAAsCK,EAAUL,IAChDuB,EAAAS,QAAAhC,GACAgS,GAEQjR,EAAaf,IACrBuB,EAAAS,QAAAhC,GACA8R,GAEAC,EAAA/R,GAiBA,SAAAgS,EAAAhS,GAEA,YAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAoEO,EAAiBP,IACrFuB,EAAAS,QAAAhC,GACAgS,GAEAC,EAAAjS,GAgBA,SAAAiS,EAAAjS,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAkS,GAEQnR,EAAaf,IACrBuB,EAAAS,QAAAhC,GACAiS,GAEAH,EAAA9R,GAgBA,SAAAkS,EAAAlS,GACA,cAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,EACA+F,EAAA/F,GAEA,KAAAA,GAAA,KAAAA,GACAuB,EAAAS,QAAAhC,GACAoR,EAAApR,EACAmS,GAEQpR,EAAaf,IACrBuB,EAAAS,QAAAhC,GACAkS,GAEAE,EAAApS,GAeA,SAAAmS,EAAAnS,GACA,OAAAA,IAAAoR,GACA7P,EAAAS,QAAAhC,GACAoR,EAAA,KACAiB,GAEA,OAAArS,GAAyBa,EAAkBb,GAC3C+F,EAAA/F,IAEAuB,EAAAS,QAAAhC,GACAmS,GAaA,SAAAC,EAAApS,GACA,cAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAkIc,EAAyBd,GAC3JiS,EAAAjS,IAEAuB,EAAAS,QAAAhC,GACAoS,GAcA,SAAAC,EAAArS,GACA,YAAAA,GAAA,KAAAA,GAAsCe,EAAaf,GACnD8R,EAAA9R,GAEA+F,EAAA/F,GAaA,SAAA+R,EAAA/R,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAsS,GAEAvM,EAAA/F,GAaA,SAAAsS,EAAAtS,GACA,cAAAA,GAAyBa,EAAkBb,GAG3CyD,EAAAzD,GAEQe,EAAaf,IACrBuB,EAAAS,QAAAhC,GACAsS,GAEAvM,EAAA/F,GAaA,SAAAyD,EAAAzD,GACA,YAAAA,GAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACAuS,GAEA,KAAAvS,GAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACAwS,GAEA,KAAAxS,GAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACAyS,GAEA,KAAAzS,GAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACAuR,GAEA,KAAAvR,GAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACA0S,IAEQ7R,EAAkBb,IAAA,IAAAiN,GAAA,IAAAA,EAI1B,OAAAjN,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,gBACA0Q,EAAA3S,KAEAuB,EAAAS,QAAAhC,GACAyD,IARAlC,EAAAU,KAAA,gBACAV,EAAAoD,MAAAiO,GAAAC,EAAAF,EAAApR,CAAAvB,IAqBA,SAAA2S,EAAA3S,GACA,OAAAuB,EAAAoD,MAAAmO,GAAAC,EAAAF,EAAAtR,CAAAvB,GAcA,SAAA+S,EAAA/S,GAIA,OAHAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACA+Q,EAcA,SAAAA,EAAAhT,GACA,cAAAA,GAAyBa,EAAkBb,GAC3C2S,EAAA3S,IAEAuB,EAAAO,MAAA,gBACA2B,EAAAzD,IAaA,SAAAuS,EAAAvS,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAuR,GAEA9N,EAAAzD,GAaA,SAAAwS,EAAAxS,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAmR,EAAA,GACA8B,GAEAxP,EAAAzD,GAaA,SAAAiT,EAAAjT,GACA,QAAAA,EAAA,CACA,MAAA6M,EAAAsE,EAAA3B,cACA,OAAUwB,GAAY7K,SAAA0G,IACtBtL,EAAAS,QAAAhC,GACAyS,GAEAhP,EAAAzD,GAEA,OAAQK,EAAUL,IAAAmR,EAAA3S,OAAA,GAClB+C,EAAAS,QAAAhC,GAEAmR,GAAA/P,OAAAC,aAAArB,GACAiT,GAEAxP,EAAAzD,GAaA,SAAA0S,EAAA1S,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAuR,GAEA9N,EAAAzD,GAqBA,SAAAuR,EAAAvR,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAyS,GAIA,KAAAzS,GAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACAuR,GAEA9N,EAAAzD,GAaA,SAAAyS,EAAAzS,GACA,cAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,gBACA4Q,EAAA7S,KAEAuB,EAAAS,QAAAhC,GACAyS,GAaA,SAAAI,EAAA7S,GAMA,OALAuB,EAAAU,KAAA,YAKAT,EAAAxB,KA5wBA+M,UAeA,SAAAhJ,GACA,IAAAxF,EAAAwF,EAAAvF,OACA,KAAAD,MACA,UAAAwF,EAAAxF,GAAA,iBAAAwF,EAAAxF,GAAA,GAAAR,QAIAQ,EAAA,kBAAAwF,EAAAxF,EAAA,MAAAR,OAEAgG,EAAAxF,GAAA,GAAAK,MAAAmF,EAAAxF,EAAA,MAAAK,MAEAmF,EAAAxF,EAAA,MAAAK,MAAAmF,EAAAxF,EAAA,MAAAK,MAEAmF,EAAArF,OAAAH,EAAA,MAEA,OAAAwF,GA7BAQ,UAAA,GAIAqO,GAAA,CACAzQ,SA2zBA,SAAAZ,EAAAC,EAAAuE,GACA,OAaA,SAAA/F,GAIA,OAHAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACAV,EAAAc,QAA2B+D,EAAS5E,EAAAuE,KA50BpCO,SAAA,GAEAwM,GAAA,CACA3Q,SA0wBA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAaA,SAAAtC,GACA,GAAQa,EAAkBb,GAI1B,OAHAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACAoE,EAEA,OAAAN,EAAA/F,IAcA,SAAAqG,EAAArG,GACA,OAAAiD,EAAAV,OAAAwC,KAAA9B,EAAA+B,MAAAC,MAAAc,EAAA/F,GAAAwB,EAAAxB,KA9yBAsG,SAAA,GCjBA,MAAA4M,GAAA,CACA/Q,SA+ZA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAOA,SAAAtC,GACA,UAAAA,EACA,OAAA+F,EAAA/F,GAKA,OAHAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACAS,GAQA,SAAAA,EAAA1C,GACA,OAAAiD,EAAAV,OAAAwC,KAAA9B,EAAA+B,MAAAC,MAAAc,EAAA/F,GAAAwB,EAAAxB,KAvbAsG,SAAA,GAIO6M,GAAA,CACPtG,KAAA,aACA1K,SAQA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KAEA8Q,EAAA,CACAjR,SAiSA,SAAAZ,EAAAC,EAAAuE,GACA,IAAAlE,EAAA,EACA,OAOA,SAAA7B,GAIA,OAHAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACArD,GAeA,SAAAA,EAAAoB,GAKA,OADAuB,EAAAO,MAAA,mBACaf,EAAaf,GAASsB,EAAYC,EAAA8R,EAAA,aAAApQ,EAAAV,OAAAC,WAAAyD,QAAAC,KAAAC,SAAA,qBAAArG,EAAA,EAAZwB,CAAYtB,GAAAqT,EAAArT,GAe/C,SAAAqT,EAAArT,GACA,OAAAA,IAAAiN,GACA1L,EAAAO,MAAA,2BACAwR,EAAAtT,IAEA+F,EAAA/F,GAeA,SAAAsT,EAAAtT,GACA,OAAAA,IAAAiN,GACApL,IACAN,EAAAS,QAAAhC,GACAsT,GAEAzR,GAAA0R,GACAhS,EAAAU,KAAA,2BACelB,EAAaf,GAASsB,EAAYC,EAAAiS,EAAA,aAAZlS,CAAYtB,GAAAwT,EAAAxT,IAEjD+F,EAAA/F,GAeA,SAAAwT,EAAAxT,GACA,cAAAA,GAA2Ba,EAAkBb,IAC7CuB,EAAAU,KAAA,mBACAT,EAAAxB,IAEA+F,EAAA/F,KAlYAsG,SAAA,GAEA,IAGA2G,EAHAwG,EAAA,EACAF,EAAA,EAGA,OAcA,SAAAvT,GAEA,OAeA,SAAAA,GACA,MAAAqI,EAAApF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,GAMA,OALAiV,EAAApL,GAAA,eAAAA,EAAA,GAAAtK,KAAAsK,EAAA,GAAAC,eAAAD,EAAA,OAAA7J,OAAA,EACAyO,EAAAjN,EACAuB,EAAAO,MAAA,cACAP,EAAAO,MAAA,mBACAP,EAAAO,MAAA,2BACA4R,EAAA1T,GAtBA2T,CAAA3T,IAqCA,SAAA0T,EAAA1T,GACA,OAAAA,IAAAiN,GACAsG,IACAhS,EAAAS,QAAAhC,GACA0T,GAEAH,EAAA,EACAxN,EAAA/F,IAEAuB,EAAAU,KAAA,2BACWlB,EAAaf,GAASsB,EAAYC,EAAAqS,EAAA,aAAZtS,CAAYtB,GAAA4T,EAAA5T,IAe7C,SAAA4T,EAAA5T,GACA,cAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,mBACAgB,EAAAwB,UAAAjD,EAAAxB,GAAAuB,EAAAoD,MAAAuO,GAAAW,EAAAxN,EAAA9E,CAAAvB,KAEAuB,EAAAO,MAAA,uBACAP,EAAAO,MAAA,eACAe,YAAA,WAEA2H,EAAAxK,IAeA,SAAAwK,EAAAxK,GACA,cAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,eACAV,EAAAU,KAAA,uBACA2R,EAAA5T,IAEQe,EAAaf,IACrBuB,EAAAU,KAAA,eACAV,EAAAU,KAAA,uBACaX,EAAYC,EAAAuS,EAAA,aAAZxS,CAAYtB,IAEzB,KAAAA,OAAAiN,EACAlH,EAAA/F,IAEAuB,EAAAS,QAAAhC,GACAwK,GAeA,SAAAsJ,EAAA9T,GACA,cAAAA,GAAyBa,EAAkBb,GAC3C4T,EAAA5T,IAEAuB,EAAAO,MAAA,uBACAP,EAAAO,MAAA,eACAe,YAAA,WAEAkR,EAAA/T,IAeA,SAAA+T,EAAA/T,GACA,cAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,eACAV,EAAAU,KAAA,uBACA2R,EAAA5T,IAEA,KAAAA,OAAAiN,EACAlH,EAAA/F,IAEAuB,EAAAS,QAAAhC,GACA+T,GAgBA,SAAAF,EAAA7T,GACA,OAAAuB,EAAAc,QAAA+Q,EAAA/M,EAAA2N,EAAAzS,CAAAvB,GAeA,SAAAgU,EAAAhU,GAIA,OAHAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACAG,EAeA,SAAAA,EAAApC,GACA,OAAAyT,EAAA,GAAgC1S,EAAaf,GAASsB,EAAYC,EAAA0S,EAAA,aAAAR,EAAA,EAAZnS,CAAYtB,GAAAiU,EAAAjU,GAelE,SAAAiU,EAAAjU,GACA,cAAAA,GAAyBa,EAAkBb,GAC3CuB,EAAAoD,MAAAuO,GAAAW,EAAAxN,EAAA9E,CAAAvB,IAEAuB,EAAAO,MAAA,iBACAoS,EAAAlU,IAeA,SAAAkU,EAAAlU,GACA,cAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,iBACAgS,EAAAjU,KAEAuB,EAAAS,QAAAhC,GACAkU,GAeA,SAAA7N,EAAArG,GAEA,OADAuB,EAAAU,KAAA,cACAT,EAAAxB,KArSAuE,UAAA,GCfO,MAAA4P,GAAA,CACPC,MAAA,OACAC,IAAA,IACAC,OAAA,OACAC,OAAA,SACAC,MAAA,OACAC,IAAA,SACAC,IAAA,eACAC,OAAA,OACAC,MAAA,SACAC,MAAA,SACAC,IAAA,SACAC,MAAA,SACAC,KAAA,eACAC,cAAA,SACAC,MAAA,OACAC,KAAA,eACAC,OAAA,SACAC,OAAA,OACAC,KAAA,OACAC,UAAA,SACAC,KAAA,SACAC,OAAA,SACAC,IAAA,SACAC,QAAA,SACAC,WAAA,SACAC,KAAA,SACAC,IAAA,eACAC,KAAA,eACAC,MAAA,SACAC,KAAA,SACAC,OAAA,SACAC,KAAA,SACAC,KAAA,OACAC,OAAA,SACAC,IAAA,SACAC,qBAAA,SACAC,QAAA,SACAC,OAAA,SACAC,OAAA,OACAC,MAAA,SACAC,QAAA,SACAC,KAAA,SACAC,QAAA,OACAC,UAAA,OACAC,IAAA,SACAC,IAAA,SACAC,UAAA,SACAC,YAAA,SACAC,WAAA,SACAC,YAAA,SACAC,yBAAA,SACAC,sBAAA,SACAC,gBAAA,SACAC,MAAA,SACAC,OAAA,SACAC,UAAA,SACAC,OAAA,SACAC,gBAAA,SACAC,KAAA,SACAC,UAAA,SACAC,gCAAA,SACAC,MAAA,SACAC,KAAA,eACAC,IAAA,SACAC,OAAA,SACAC,GAAA,SACAC,SAAA,SACAC,KAAA,SACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,IAAA,SACAC,MAAA,SACAC,IAAA,eACAC,iBAAA,OACAC,eAAA,SACAC,uBAAA,SACAC,iBAAA,IACAC,iBAAA,SACAC,QAAA,SACAC,cAAA,SACAC,KAAA,eACAC,IAAA,OACAC,OAAA,SACAC,SAAA,SACAC,sBAAA,SACAC,UAAA,OACAC,gBAAA,SACAC,gBAAA,SACAC,qBAAA,SACAC,cAAA,SACAC,oBAAA,SACAC,yBAAA,SACAC,qBAAA,SACAC,iBAAA,SACAC,eAAA,SACAC,cAAA,SACAC,kBAAA,SACAC,kBAAA,SACAC,UAAA,SACAC,aAAA,SACAC,iBAAA,SACAC,UAAA,SACAC,oBAAA,SACAC,kBAAA,SACAC,eAAA,SACAC,kBAAA,SACAC,mBAAA,SACAC,gBAAA,SACAC,mBAAA,SACAC,QAAA,SACAC,aAAA,SACAC,UAAA,SACAC,KAAA,eACAC,OAAA,SACAC,IAAA,SACAC,IAAA,OACAC,OAAA,OACAC,OAAA,SACAC,MAAA,OACAC,IAAA,SACAC,KAAA,SACAC,IAAA,eACAC,OAAA,OACAC,QAAA,SACAC,MAAA,SACAC,iBAAA,SACAC,qBAAA,SACAC,MAAA,SACAC,KAAA,eACAC,QAAA,SACAC,MAAA,SACAC,WAAA,SACAC,YAAA,SACAC,KAAA,SACAC,KAAA,SACAC,IAAA,SACAC,KAAA,OACAC,OAAA,SACAC,aAAA,SACAC,IAAA,SACAC,IAAA,eACAC,kBAAA,SACAC,sBAAA,SACAC,KAAA,eACAC,OAAA,SACAC,WAAA,SACAC,KAAA,SACAC,KAAA,SACAC,GAAA,IACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,IAAA,SACAC,KAAA,SACAC,IAAA,eACAC,GAAA,SACAC,KAAA,eACAC,aAAA,SACAC,iBAAA,SACAC,iBAAA,SACAC,eAAA,SACAC,YAAA,SACAC,kBAAA,SACAC,aAAA,SACAC,KAAA,eACAC,GAAA,SACAC,OAAA,SACAC,MAAA,SACAC,IAAA,IACAC,MAAA,SACAC,IAAA,SACAC,aAAA,SACAC,KAAA,SACAC,eAAA,SACAC,KAAA,SACAC,OAAA,SACAC,aAAA,SACAC,UAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,SACAC,OAAA,OACAC,MAAA,OACAC,IAAA,SACAC,KAAA,SACAC,IAAA,SACAC,OAAA,OACAC,GAAA,SACAC,MAAA,SACAC,WAAA,SACAC,QAAA,SACAC,IAAA,SACAC,SAAA,SACAC,aAAA,SACAC,eAAA,SACAC,eAAA,SACAC,MAAA,SACAC,KAAA,eACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,OACAC,MAAA,SACAC,IAAA,SACAC,IAAA,eACAC,KAAA,eACAC,KAAA,eACAC,OAAA,SACAC,MAAA,SACAC,KAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,IAAA,eACAC,KAAA,eACAC,KAAA,eACAC,KAAA,SACAC,GAAA,IACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,WAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,iBAAA,SACAC,UAAA,SACAC,aAAA,SACAC,oBAAA,SACAC,YAAA,SACAC,kBAAA,SACAC,kBAAA,SACAC,eAAA,SACAC,kBAAA,SACAC,UAAA,SACAC,eAAA,SACAC,gBAAA,SACAC,QAAA,SACAC,aAAA,SACAC,cAAA,SACAC,aAAA,SACAC,gBAAA,SACAC,kBAAA,SACAC,iBAAA,SACAC,gBAAA,SACAC,aAAA,SACAC,gBAAA,SACAC,WAAA,SACAC,cAAA,SACAC,UAAA,SACAC,eAAA,SACAC,iBAAA,SACAC,cAAA,SACAC,YAAA,SACAC,SAAA,SACAC,eAAA,SACAC,UAAA,SACAC,IAAA,eACAC,GAAA,SACAC,WAAA,SACAC,OAAA,SACAC,cAAA,SACAC,mBAAA,SACAC,eAAA,SACAC,cAAA,SACAC,mBAAA,SACAC,eAAA,SACAC,KAAA,eACAC,eAAA,SACAC,gBAAA,SACAC,KAAA,SACAC,IAAA,SACAC,OAAA,SACAC,GAAA,SACAC,IAAA,SACAC,IAAA,SACAC,YAAA,SACAC,UAAA,SACAC,IAAA,eACAC,UAAA,SACAC,KAAA,eACAC,KAAA,SACAC,GAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,oBAAA,SACAC,mBAAA,SACAC,kBAAA,SACAC,sBAAA,SACAC,qBAAA,SACAC,eAAA,SACAC,QAAA,KACAC,IAAA,eACAC,QAAA,SACAC,iBAAA,OACAC,KAAA,SACAC,IAAA,SACAC,aAAA,SACAC,UAAA,SACAC,qBAAA,SACAC,WAAA,SACAC,SAAA,SACAC,cAAA,eACAC,UAAA,SACAC,WAAA,SACAC,gBAAA,SACAC,oBAAA,eACAC,kBAAA,eACAC,eAAA,SACAC,qBAAA,eACAC,gBAAA,SACAC,gBAAA,eACAC,aAAA,eACAC,gBAAA,SACAC,mBAAA,eACAC,qBAAA,SACAC,QAAA,SACAC,aAAA,SACAC,eAAA,SACAC,YAAA,eACAC,kBAAA,eACAC,aAAA,SACAC,wBAAA,eACAC,kBAAA,eACAC,YAAA,SACAC,iBAAA,eACAC,sBAAA,SACAC,kBAAA,SACAC,iBAAA,SACAC,oBAAA,eACAC,sBAAA,SACAC,gBAAA,eACAC,qBAAA,SACAC,kBAAA,eACAC,uBAAA,SACAC,UAAA,eACAC,eAAA,SACAC,YAAA,SACAC,iBAAA,eACAC,sBAAA,SACAC,iBAAA,eACAC,YAAA,eACAC,iBAAA,SACAC,SAAA,SACAC,cAAA,SACAC,kBAAA,SACAC,cAAA,SACAC,eAAA,SACAC,KAAA,eACAC,OAAA,OACAC,GAAA,SACAC,MAAA,SACAC,OAAA,OACAC,MAAA,OACAC,IAAA,SACAC,OAAA,SACAC,IAAA,eACAC,OAAA,OACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,KAAA,eACAC,qBAAA,SACAC,eAAA,SACAC,GAAA,SACAC,KAAA,eACAC,OAAA,OACAC,OAAA,OACAC,OAAA,SACAC,KAAA,OACAC,QAAA,SACAC,UAAA,SACAC,YAAA,SACAC,gBAAA,SACAC,SAAA,SACAC,IAAA,SACAC,IAAA,eACAC,IAAA,SACAC,GAAA,SACAC,UAAA,OACAC,cAAA,SACAC,KAAA,SACAC,GAAA,SACAC,SAAA,SACAC,cAAA,SACAC,mBAAA,SACAC,cAAA,SACAC,MAAA,SACAC,QAAA,SACAC,WAAA,SACAC,aAAA,SACAC,KAAA,eACAC,IAAA,SACAC,KAAA,IACAC,IAAA,eACAC,KAAA,SACAC,KAAA,eACAC,MAAA,SACAC,IAAA,OACAC,OAAA,SACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,GAAA,SACAC,eAAA,SACAC,mBAAA,SACAC,qBAAA,SACAC,IAAA,SACAC,IAAA,SACAC,kBAAA,SACAC,WAAA,SACAC,cAAA,SACAC,oBAAA,SACAC,aAAA,SACAC,mBAAA,SACAC,mBAAA,SACAC,gBAAA,SACAC,mBAAA,SACAC,WAAA,SACAC,SAAA,SACAC,cAAA,SACAC,eAAA,SACAC,cAAA,SACAC,iBAAA,SACAC,mBAAA,SACAC,kBAAA,SACAC,iBAAA,SACAC,cAAA,SACAC,iBAAA,SACAC,YAAA,SACAC,eAAA,SACAC,WAAA,SACAC,KAAA,SACAC,aAAA,SACAC,YAAA,SACAC,KAAA,SACAC,IAAA,SACAC,YAAA,SACAC,OAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,GAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,IAAA,SACAC,IAAA,eACAC,eAAA,SACAC,eAAA,SACAC,gBAAA,SACAC,aAAA,SACAC,MAAA,SACAC,YAAA,SACAC,KAAA,eACAC,KAAA,SACAC,OAAA,SACAC,mBAAA,SACAC,aAAA,SACAC,kBAAA,SACAC,eAAA,SACAC,oBAAA,SACAC,YAAA,SACAC,KAAA,eACAC,KAAA,SACAC,IAAA,SACAC,OAAA,SACAC,YAAA,SACAC,SAAA,SACAC,cAAA,SACAC,mBAAA,SACAC,cAAA,SACAC,SAAA,SACAC,IAAA,SACAC,IAAA,SACAC,SAAA,SACAC,cAAA,SACAC,OAAA,SACAC,MAAA,OACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,IAAA,KACAC,IAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,IAAA,eACAC,UAAA,SACAC,MAAA,SACAC,WAAA,eACAC,UAAA,SACAC,MAAA,SACAC,WAAA,SACAC,eAAA,SACAC,WAAA,SACAC,KAAA,eACAC,UAAA,SACAC,KAAA,eACAC,OAAA,SACAC,OAAA,OACAC,KAAA,SACAC,SAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,OACAC,IAAA,SACAC,OAAA,SACAC,IAAA,eACAC,OAAA,OACAC,MAAA,SACAC,SAAA,IACAC,WAAA,SACAC,aAAA,SACAC,iBAAA,SACAC,MAAA,SACAC,UAAA,SACAC,MAAA,SACAC,KAAA,eACAC,QAAA,SACAC,WAAA,SACAC,iBAAA,SACAC,YAAA,SACAC,cAAA,SACAC,MAAA,SACAC,WAAA,SACAC,QAAA,SACAC,YAAA,SACAC,eAAA,SACAC,gBAAA,SACAC,KAAA,SACAC,QAAA,SACAC,MAAA,SACAC,KAAA,eACAC,OAAA,SACAC,KAAA,OACAC,MAAA,SACAC,KAAA,SACAC,IAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,OAAA,SACAC,KAAA,SACAC,YAAA,SACAC,aAAA,IACAC,kBAAA,SACAC,cAAA,SACAC,cAAA,SACAC,IAAA,eACAC,KAAA,eACAC,KAAA,eACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,IAAA,eACAC,KAAA,eACAC,KAAA,eACAC,IAAA,eACAC,GAAA,SACAC,KAAA,eACAC,KAAA,eACAC,KAAA,SACAC,KAAA,SACAC,KAAA,SACAC,OAAA,OACAC,MAAA,SACAC,IAAA,SACAC,IAAA,eACAC,KAAA,eACAC,KAAA,eACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,KAAA,SACAC,eAAA,SACAC,KAAA,SACAC,IAAA,SACAC,KAAA,SACAC,KAAA,eACAC,OAAA,OACAC,OAAA,SACAC,GAAA,SACAC,IAAA,eACAC,IAAA,SACAC,MAAA,OACAC,MAAA,OACAC,IAAA,SACAC,MAAA,OACAC,GAAA,SACAC,IAAA,eACAC,OAAA,OACAC,QAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,IAAA,IACAC,IAAA,SACAC,OAAA,SACAC,KAAA,SACAC,SAAA,SACAC,KAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,SAAA,SACAC,SAAA,SACAC,SAAA,SACAC,SAAA,SACAC,SAAA,SACAC,SAAA,SACAC,SAAA,SACAC,SAAA,SACAC,MAAA,SACAC,QAAA,SACAC,SAAA,SACAC,OAAA,SACAC,MAAA,OACAC,QAAA,SACAC,MAAA,SACAC,KAAA,eACAC,GAAA,SACAC,IAAA,SACAC,OAAA,SACAC,IAAA,SACAC,KAAA,SACAC,KAAA,IACAC,OAAA,SACAC,SAAA,SACAC,MAAA,OACAC,KAAA,eACAC,IAAA,IACAC,MAAA,SACAC,QAAA,SACAC,OAAA,OACAC,KAAA,OACAC,SAAA,SACAC,MAAA,SACAC,KAAA,SACAC,SAAA,SACAC,YAAA,SACAC,UAAA,SACAC,QAAA,SACAC,UAAA,SACAC,OAAA,SACAC,OAAA,SACAC,SAAA,SACAC,KAAA,SACAC,SAAA,SACAC,MAAA,SACAC,IAAA,SACAC,MAAA,SACAC,OAAA,SACAC,QAAA,SACAC,QAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,KAAA,SACAC,QAAA,SACAC,IAAA,eACAC,OAAA,SACAC,QAAA,SACAC,OAAA,SACAC,QAAA,SACAC,SAAA,SACAC,UAAA,SACAC,SAAA,SACAC,QAAA,SACAC,gBAAA,SACAC,cAAA,SACAC,SAAA,SACAC,OAAA,SACAC,SAAA,SACAC,OAAA,SACAC,aAAA,SACAC,YAAA,SACAC,cAAA,SACAC,kBAAA,SACAC,kBAAA,SACAC,mBAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,IAAA,UACAC,QAAA,eACAC,KAAA,SACAC,KAAA,eACAC,IAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,SAAA,SACAC,QAAA,SACAC,SAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,OACAC,KAAA,eACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,KACAC,MAAA,SACAC,SAAA,SACAC,KAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,OAAA,SACAC,SAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,eACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,OACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,KAAA,SACAC,MAAA,OACAC,QAAA,SACAC,KAAA,OACAC,UAAA,OACAC,IAAA,eACAC,KAAA,SACAphC,MAAA,SACAqhC,UAAA,SACAC,IAAA,SACAC,IAAA,SACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,gBAAA,SACAC,iBAAA,SACAC,SAAA,OACAC,SAAA,SACAC,WAAA,SACAC,YAAA,SACAC,YAAA,SACAC,KAAA,SACAC,SAAA,SACAC,OAAA,SACAC,QAAA,SACAC,MAAA,SACAC,SAAA,SACAC,MAAA,IACAC,OAAA,SACAC,QAAA,SACAC,MAAA,IACAC,OAAA,IACAC,KAAA,SACAC,OAAA,SACAC,WAAA,SACAC,UAAA,SACAC,KAAA,SACAC,QAAA,SACAC,OAAA,SACAC,KAAA,eACAC,OAAA,SACAC,KAAA,OACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,eACAC,KAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,QAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,QAAA,SACAC,IAAA,SACAC,SAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,eACAC,OAAA,SACAC,QAAA,SACAC,YAAA,SACAC,YAAA,SACAC,SAAA,SACAC,WAAA,SACAC,OAAA,OACAC,eAAA,SACAC,gBAAA,SACAC,MAAA,SACAC,MAAA,SACAC,SAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,KAAA,SACAC,MAAA,SACAC,QAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,GAAA,SACAC,QAAA,SACAC,MAAA,SACAC,QAAA,SACAC,IAAA,OACAC,MAAA,SACAC,QAAA,SACAC,OAAA,SACAC,IAAA,eACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,QAAA,SACAC,YAAA,SACAC,MAAA,SACAC,IAAA,OACAC,QAAA,SACAC,MAAA,SACAC,IAAA,OACAC,OAAA,OACAC,cAAA,SACAC,OAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,IACAC,KAAA,eACAC,IAAA,SACAC,MAAA,SACAC,SAAA,SACAC,SAAA,SACAC,QAAA,SACAC,UAAA,SACAC,eAAA,SACAC,UAAA,SACAC,eAAA,SACAC,gBAAA,SACAC,iBAAA,SACAC,SAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,eACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,KAAA,SACAC,SAAA,SACAC,MAAA,SACAC,KAAA,SACAC,OAAA,OACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,OACAC,OAAA,SACAC,IAAA,SACAC,KAAA,SACAC,GAAA,SACAC,MAAA,SACAC,IAAA,eACAC,GAAA,SACAC,OAAA,OACAC,IAAA,SACAC,OAAA,SACAC,GAAA,SACAC,SAAA,SACAC,IAAA,SACAC,IAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,SAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,eACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,SACAC,QAAA,SACAC,MAAA,SACAC,OAAA,SACAC,QAAA,SACAC,MAAA,SACAC,WAAA,SACAC,YAAA,SACAC,OAAA,IACAC,OAAA,SACAC,MAAA,SACAC,QAAA,SACAC,SAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,SACAC,IAAA,SACAC,IAAA,OACAC,KAAA,OACAC,KAAA,SACAC,KAAA,IACAC,MAAA,SACAC,YAAA,SACAC,aAAA,SACAC,cAAA,SACAC,IAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,eACAC,MAAA,SACAC,MAAA,KACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,KAAA,eACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,SAAA,SACAC,OAAA,OACAC,OAAA,SACAC,OAAA,OACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,OACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,eACAC,GAAA,SACAC,IAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,OAAA,SACAC,MAAA,SACAC,IAAA,SACAC,KAAA,SACAC,GAAA,SACAC,IAAA,SACAC,IAAA,SACAC,KAAA,SACAC,SAAA,SACAC,IAAA,SACAC,MAAA,SACAC,OAAA,SACAC,QAAA,SACAC,SAAA,SACAC,KAAA,eACAC,OAAA,SACAC,IAAA,eACAC,GAAA,SACAC,IAAA,SACAC,MAAA,SACAC,KAAA,SACAC,GAAA,SACAC,IAAA,SACAC,IAAA,SACAC,IAAA,SACAC,IAAA,SACAC,KAAA,SACAC,SAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,eACAC,MAAA,IACAC,KAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,GAAA,IACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,QAAA,SACAC,UAAA,SACAC,OAAA,SACAC,OAAA,SACAC,UAAA,SACAC,WAAA,SACAC,QAAA,SACAC,OAAA,SACAC,UAAA,eACAC,KAAA,eACAC,KAAA,SACAC,OAAA,SACAC,KAAA,OACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,QAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,UAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,eACAC,SAAA,SACAC,SAAA,SACAC,MAAA,SACAC,OAAA,SACAC,cAAA,SACAC,eAAA,SACAC,KAAA,eACAC,OAAA,SACAC,KAAA,eACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,OACAC,GAAA,SACAC,MAAA,OACAC,IAAA,SACAC,KAAA,SACAC,MAAA,OACAC,IAAA,SACAC,IAAA,eACAC,OAAA,OACAC,GAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,SAAA,SACAC,SAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,GAAA,SACAC,OAAA,SACAC,MAAA,SACAC,SAAA,SACAC,OAAA,SACAC,IAAA,SACAC,OAAA,SACAC,SAAA,SACAC,SAAA,SACAC,SAAA,SACAC,QAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,eACAC,KAAA,SACAC,MAAA,SACAC,OAAA,OACAC,KAAA,eACAC,KAAA,SACAC,MAAA,SACAC,QAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,GAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,OACAC,MAAA,SACAC,IAAA,SACAC,IAAA,eACAC,MAAA,SACAC,KAAA,eACAC,KAAA,eACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,IAAA,eACAC,OAAA,SACAC,KAAA,SACAC,KAAA,SACAC,KAAA,eACAC,KAAA,eACAC,MAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,GAAA,SACAC,IAAA,SACAC,KAAA,SACAC,OAAA,SACAC,SAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,MAAA,OACAC,KAAA,SACAC,MAAA,SACAC,QAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,QAAA,SACAC,OAAA,SACAC,IAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,eACAC,MAAA,SACAC,MAAA,SACAC,OAAA,IACAC,OAAA,IACAC,MAAA,SACAC,QAAA,SACAC,QAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,IACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,QAAA,SACAC,SAAA,SACAC,KAAA,SACAC,GAAA,SACAC,UAAA,SACAC,cAAA,SACAC,gBAAA,SACAC,cAAA,SACAC,eAAA,SACAC,eAAA,SACAC,gBAAA,SACAC,kBAAA,SACAC,oBAAA,SACAC,eAAA,SACAC,IAAA,SACAC,IAAA,SACAC,KAAA,SACAC,SAAA,SACAC,IAAA,SACAC,MAAA,SACAC,OAAA,SACAC,QAAA,SACAC,SAAA,SACAC,KAAA,eACAC,OAAA,SACAC,WAAA,SACAC,QAAA,SACAC,UAAA,SACAC,WAAA,SACAC,QAAA,SACAC,QAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,eACAC,GAAA,SACAC,IAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,SACAC,GAAA,SACAC,MAAA,SACAC,SAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,WAAA,SACAC,IAAA,SACAC,KAAA,SACAC,SAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,cAAA,SACAC,mBAAA,SACAC,WAAA,SACAC,eAAA,SACAC,cAAA,SACAC,eAAA,SACAC,MAAA,SACAC,KAAA,eACAC,OAAA,SACAC,QAAA,SACAC,OAAA,SACAC,OAAA,IACAC,IAAA,SACAC,QAAA,SACAC,KAAA,SACAC,KAAA,IACAC,OAAA,SACAC,MAAA,SACAC,SAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,eACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,IACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,GAAA,IACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,QAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,SAAA,SACAC,QAAA,SACAC,UAAA,eACAC,KAAA,eACAC,MAAA,SACAC,KAAA,OACAC,KAAA,SACAC,KAAA,SACAC,QAAA,SACA57C,IAAA,SACA67C,OAAA,SACAC,WAAA,SACAC,WAAA,SACAC,SAAA,SACAl7C,OAAA,SACAm7C,OAAA,SACAC,IAAA,SACAC,MAAA,SACAC,cAAA,SACAC,IAAA,eACAC,IAAA,SACAC,MAAA,OACAC,IAAA,SACAC,OAAA,IACAC,OAAA,SACAC,OAAA,OACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,QAAA,SACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,eACAC,GAAA,SACAC,KAAA,eACAC,OAAA,SACAC,GAAA,SACAC,SAAA,SACAC,MAAA,SACAC,IAAA,eACAC,IAAA,eACAC,KAAA,eACAC,WAAA,SACAC,gBAAA,SACAC,IAAA,eACAC,IAAA,eACAC,KAAA,eACAC,YAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,eACAC,IAAA,SACAC,KAAA,eACAC,MAAA,eACAC,MAAA,SACAC,QAAA,SACAC,MAAA,SACAC,QAAA,SACAC,SAAA,SACAC,KAAA,OACAC,MAAA,eACAC,OAAA,eACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,SAAA,eACAC,KAAA,SACAC,IAAA,SACAC,MAAA,SACAC,GAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,QAAA,SACAC,MAAA,eACAC,OAAA,SACAC,OAAA,SACAC,MAAA,eACAC,OAAA,SACAC,QAAA,SACAC,IAAA,eACAC,IAAA,eACAC,IAAA,SACAC,KAAA,SACAC,MAAA,eACAC,UAAA,eACAC,KAAA,eACAC,MAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,GAAA,SACAC,IAAA,SACAC,KAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,IAAA,eACAC,MAAA,SACAC,KAAA,SACAC,IAAA,SACAC,WAAA,SACAC,gBAAA,SACAC,KAAA,SACAC,MAAA,eACAC,UAAA,eACAC,KAAA,eACAC,MAAA,SACAC,MAAA,SACAC,IAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,KAAA,eACAC,IAAA,OACAC,MAAA,SACAC,OAAA,eACAC,SAAA,eACAC,QAAA,SACAC,QAAA,SACAC,QAAA,SACAC,MAAA,SACAC,QAAA,SACAC,QAAA,SACAC,QAAA,SACAC,KAAA,SACAC,UAAA,SACAC,OAAA,eACAC,MAAA,eACAC,QAAA,SACAC,IAAA,SACAC,OAAA,SACAC,KAAA,eACAC,MAAA,SACAC,QAAA,eACAC,MAAA,SACAC,MAAA,SACAC,OAAA,eACAC,OAAA,eACAC,YAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,OAAA,SACAC,KAAA,eACAC,KAAA,eACAC,UAAA,SACAC,eAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,QAAA,SACAC,KAAA,SACAC,MAAA,eACAC,MAAA,SACAC,QAAA,eACAC,UAAA,SACAC,WAAA,eACAC,MAAA,SACAC,QAAA,eACAC,KAAA,SACAC,MAAA,eACAC,MAAA,SACAC,QAAA,eACAC,UAAA,SACAC,WAAA,eACAC,KAAA,SACAC,OAAA,OACAC,KAAA,SACAC,cAAA,SACAC,gBAAA,SACAC,eAAA,SACAC,iBAAA,SACAC,GAAA,SACAC,IAAA,IACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,eACAC,OAAA,SACAC,KAAA,eACAC,KAAA,UACAC,QAAA,SACAC,OAAA,SACAC,KAAA,eACAC,KAAA,UACAC,QAAA,eACAC,OAAA,SACAC,QAAA,eACAC,MAAA,eACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,QAAA,SACAC,OAAA,SACAC,GAAA,SACAC,OAAA,OACAC,KAAA,SACAC,KAAA,SACAC,MAAA,OACAC,IAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,IAAA,eACAC,KAAA,SACAC,OAAA,OACAC,IAAA,SACAC,MAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,MAAA,SACAC,IAAA,SACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,KAAA,SACAC,OAAA,SACAC,KAAA,eACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,GAAA,SACAC,MAAA,SACAC,IAAA,SACAC,MAAA,SACAC,QAAA,SACAC,KAAA,OACAC,KAAA,OACAC,OAAA,SACAC,KAAA,SACAC,QAAA,SACAC,IAAA,SACAC,KAAA,SACAC,OAAA,OACAC,KAAA,SACAC,OAAA,OACAC,OAAA,SACAC,SAAA,SACAC,KAAA,OACAC,MAAA,SACAC,IAAA,SACAC,KAAA,OACAC,SAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,SACAC,IAAA,SACAC,OAAA,IACAC,OAAA,IACAC,OAAA,SACAC,KAAA,SACAC,QAAA,SACAC,IAAA,eACAC,IAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,GAAA,SACAC,UAAA,SACAC,IAAA,SACAC,OAAA,SACAC,QAAA,SACAC,OAAA,SACAC,KAAA,IACAC,SAAA,SACAC,MAAA,SACAC,QAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,OACAC,QAAA,SACAC,QAAA,SACAC,GAAA,OACAC,SAAA,SACAC,KAAA,eACAC,MAAA,OACAC,GAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,IAAA,SACAC,KAAA,SACAC,WAAA,SACAC,YAAA,SACAC,OAAA,SACAC,YAAA,SACAC,SAAA,SACAC,SAAA,SACAC,QAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,SAAA,SACAC,SAAA,SACAC,SAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,eACAC,IAAA,SACAC,OAAA,SACAC,IAAA,eACAC,KAAA,SACAC,KAAA,eACAC,OAAA,SACAC,KAAA,eACAC,YAAA,SACAC,QAAA,SACAC,MAAA,IACAC,QAAA,SACAC,KAAA,IACAC,MAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,SACAC,KAAA,eACAC,OAAA,SACAC,MAAA,SACAC,SAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,OACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,QAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,QAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,UAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,IACAC,OAAA,IACAC,MAAA,SACAC,QAAA,SACAC,QAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,IACAC,IAAA,SACAC,KAAA,SACAC,QAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,KAAA,SACAC,QAAA,SACAC,SAAA,SACAC,MAAA,SACAC,KAAA,SACAC,IAAA,OACAC,OAAA,SACAC,OAAA,SACAC,IAAA,eACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,SACAC,KAAA,SACAC,WAAA,SACAC,eAAA,SACAC,iBAAA,SACAC,eAAA,SACAC,gBAAA,SACAC,kBAAA,SACAC,iBAAA,SACAC,gBAAA,SACAC,gBAAA,SACAC,KAAA,SACAC,aAAA,SACAC,MAAA,SACAC,MAAA,SACAC,IAAA,SACAC,OAAA,SACAC,WAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,eACAC,OAAA,SACAC,QAAA,SACAC,KAAA,IACAC,OAAA,SACAC,SAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,eACAC,IAAA,SACAC,KAAA,IACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,SAAA,SACAC,QAAA,SACAC,GAAA,SACAC,OAAA,SACAC,MAAA,SACAC,GAAA,SACAC,IAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,IAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,SAAA,SACAC,MAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,QAAA,SACAC,KAAA,OACAC,KAAA,IACAC,OAAA,SACAC,SAAA,SACAC,MAAA,SACAC,KAAA,SACAC,IAAA,eACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,SAAA,SACAC,cAAA,SACAC,IAAA,OACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,QAAA,SACAC,MAAA,SACAC,cAAA,SACAC,OAAA,SACAC,SAAA,SACAC,KAAA,SACAC,MAAA,SACAC,IAAA,SACAC,KAAA,SACAC,MAAA,eACAC,OAAA,SACAC,IAAA,IACAC,KAAA,SACAC,OAAA,SACAC,KAAA,eACAC,OAAA,SACAC,UAAA,SACAC,KAAA,SACAC,MAAA,SACAC,OAAA,eACAC,MAAA,SACAC,OAAA,eACAC,MAAA,SACAC,OAAA,SACAC,SAAA,SACAC,WAAA,SACAC,MAAA,SACAC,OAAA,SACAC,SAAA,SACAC,WAAA,SACAC,IAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,eACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,gBAAA,SACAC,YAAA,SACAC,MAAA,OACAC,IAAA,SACAC,KAAA,SACAC,OAAA,SACAC,KAAA,SACAC,QAAA,SACAC,QAAA,SACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,QAAA,SACAC,OAAA,SACAC,SAAA,SACAC,UAAA,SACAC,UAAA,SACAC,WAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,SACAC,WAAA,SACAC,YAAA,SACAC,OAAA,SACAC,YAAA,SACAC,SAAA,SACAC,SAAA,SACAC,QAAA,SACAC,IAAA,SACAC,KAAA,SACAC,KAAA,OACAC,KAAA,OACAC,KAAA,OACAC,IAAA,SACAC,KAAA,SACAC,OAAA,SACAC,QAAA,SACAC,KAAA,SACAC,QAAA,SACAC,QAAA,SACAC,QAAA,SACAC,QAAA,SACAC,QAAA,SACAC,MAAA,SACAC,MAAA,SACAC,QAAA,SACAC,OAAA,SACAC,SAAA,SACAC,UAAA,SACAC,UAAA,SACAC,WAAA,SACAC,OAAA,SACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,QAAA,SACAC,OAAA,SACAC,MAAA,OACAC,OAAA,SACAC,IAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,KAAA,SACAC,OAAA,SACAC,IAAA,eACAC,OAAA,SACAC,UAAA,SACAC,MAAA,SACAC,SAAA,SACAC,OAAA,SACAC,YAAA,SACAC,SAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,OACAC,MAAA,SACAC,MAAA,OACAC,OAAA,SACAC,SAAA,SACAC,OAAA,SACAC,KAAA,SACAC,KAAA,SACAC,IAAA,SACAC,OAAA,SACAC,OAAA,SACAC,KAAA,eACAC,QAAA,SACAC,KAAA,SACAC,OAAA,SACAC,MAAA,SACAC,SAAA,SACAC,aAAA,SACAC,aAAA,SACAC,eAAA,SACAC,UAAA,SACAC,cAAA,SACAC,gBAAA,SACAC,OAAA,SACAC,KAAA,SACAC,SAAA,SACAC,QAAA,SACAC,MAAA,SACAC,QAAA,SACAC,SAAA,SACAC,KAAA,eACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,iBAAA,SACAC,kBAAA,SACAC,KAAA,SACAC,KAAA,SACAC,OAAA,OACAC,KAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,OACAC,IAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,IAAA,eACAC,OAAA,OACAC,MAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,SAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,IAAA,OACAC,MAAA,SACAC,KAAA,eACAC,QAAA,SACAC,YAAA,SACAC,cAAA,SACAC,eAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,QAAA,SACAC,WAAA,SACAC,OAAA,SACAC,SAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,eACAC,MAAA,SACAC,OAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,OACAC,QAAA,SACAC,KAAA,SACAC,KAAA,SACAC,MAAA,SACAC,MAAA,SACAC,OAAA,SACAC,WAAA,SACAC,SAAA,SACAC,WAAA,SACAC,OAAA,SACAC,MAAA,SACAC,UAAA,SACAC,KAAA,SACAC,OAAA,SACAC,SAAA,SACAC,aAAA,eACAC,cAAA,eACAC,aAAA,eACAC,cAAA,eACAC,SAAA,SACAC,gBAAA,SACAC,iBAAA,SACAC,IAAA,SACAC,MAAA,SACAC,IAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,IACAC,KAAA,IACAC,IAAA,eACAC,MAAA,SACAC,MAAA,eACAC,MAAA,eACAC,KAAA,eACAC,MAAA,SACAC,MAAA,SACAC,KAAA,eACAC,OAAA,eACAC,OAAA,eACAC,OAAA,eACAC,OAAA,eACAC,QAAA,SACAC,MAAA,SACAC,OAAA,SACAC,MAAA,SACAC,OAAA,SACAC,OAAA,SACAC,IAAA,eACAC,KAAA,eACAC,GAAA,SACAC,GAAA,SACAC,OAAA,SACAC,KAAA,eACAC,KAAA,SACAC,MAAA,SACAC,KAAA,SACAC,MAAA,SACAC,IAAA,eACAC,MAAA,SACAC,MAAA,SACAC,GAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,SACAC,KAAA,SACAC,MAAA,SACAC,KAAA,eACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,MAAA,SACAC,KAAA,eACAC,OAAA,SACAC,OAAA,SACAC,MAAA,SACAC,KAAA,SACAC,OAAA,SACAC,OAAA,OACAC,KAAA,SACAC,MAAA,SACAC,IAAA,SACAC,IAAA,OACAC,IAAA,eACAC,KAAA,SACAC,KAAA,eACAC,KAAA,eACAC,KAAA,SACAC,KAAA,OACAC,OAAA,SACAC,OAAA,SACAC,IAAA,SACAC,KAAA,SACAC,OAAA,SACAC,KAAA,SACAC,IAAA,eACAC,KAAA,SACAC,QAAA,SACAC,KAAA,eACAC,KAAA,eACAC,IAAA,SACAC,KAAA,UCjlEAC,GAAA,GAAcv5E,eAaP,SAAAw5E,GAAAr7E,GACP,QAAAo7E,GAAAj5E,KAAkBsU,GAAiBzW,IAAWyW,GAAiBzW,GCJxD,MAAAs7E,GAAA,CACPnsE,KAAA,qBACA1K,SAOA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,IAEAb,EAEAN,EAJAU,EAAA,EAKA,OAgBA,SAAA7B,GAKA,OAJAuB,EAAAO,MAAA,sBACAP,EAAAO,MAAA,4BACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,4BACAgM,GAkBA,SAAAA,EAAAjO,GACA,YAAAA,GACAuB,EAAAO,MAAA,mCACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,mCACAg3E,IAEA13E,EAAAO,MAAA,2BACAL,EAAA,GACAN,EAAWZ,EACX7C,EAAAsC,IAeA,SAAAi5E,EAAAj5E,GACA,YAAAA,GAAA,MAAAA,GACAuB,EAAAO,MAAA,uCACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,uCACAV,EAAAO,MAAA,2BACAL,EAAA,EACAN,EAAaR,EACbjD,IAEA6D,EAAAO,MAAA,2BACAL,EAAA,EACAN,EAAWT,EACXhD,EAAAsC,IAoBA,SAAAtC,EAAAsC,GACA,QAAAA,GAAA6B,EAAA,CACA,MAAAe,EAAArB,EAAAU,KAAA,2BACA,OAAAd,IAAmBZ,GAAsBw4E,GAA6B91E,EAAAqF,eAAA1F,KAMtErB,EAAAO,MAAA,4BACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,4BACAV,EAAAU,KAAA,sBACAT,GATAuE,EAAA/F,GAWA,OAAAmB,EAAAnB,IAAA6B,IAAAJ,GACAF,EAAAS,QAAAhC,GACAtC,GAEAqI,EAAA/F,MCtIO,MAAAk5E,GAAA,CACPrsE,KAAA,kBACA1K,SAOA,SAAAZ,EAAAC,EAAAuE,GACA,OAYA,SAAA/F,GAKA,OAJAuB,EAAAO,MAAA,mBACAP,EAAAO,MAAA,gBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,gBACAsL,GAaA,SAAAA,EAAAvN,GAEA,OAAQY,EAAgBZ,IACxBuB,EAAAO,MAAA,wBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,wBACAV,EAAAU,KAAA,mBACAT,GAEAuE,EAAA/F,MChDO,MAAAm5E,GAAA,CACPtsE,KAAA,aACA1K,SAOA,SAAAZ,EAAAC,GACA,OAGA,SAAAxB,GAIA,OAHAuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACWX,EAAYC,EAAAC,EAAA,iBCRhB,MAAA43E,GAAA,CACPvsE,KAAA,WACA1K,SAoHA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,IAEA+2E,EAEAnpE,EAJA3R,EAAA0E,EAAAc,OAAAvF,OAOA,KAAAD,KACA,mBAAA0E,EAAAc,OAAAxF,GAAA,GAAAR,MAAA,cAAAkF,EAAAc,OAAAxF,GAAA,GAAAR,QAAAkF,EAAAc,OAAAxF,GAAA,GAAA+6E,UAAA,CACAD,EAAAp2E,EAAAc,OAAAxF,GAAA,GACA,MAGA,OAiBA,SAAAyB,GAEA,IAAAq5E,EACA,OAAAtzE,EAAA/F,GAYA,GAAAq5E,EAAAE,UACA,OAAAC,EAAAx5E,GAWA,OATAkQ,EAAAjN,EAAAV,OAAA2N,QAAA/J,SAA2CmJ,EAAmBrM,EAAAqF,eAAA,CAC9D1J,MAAAy6E,EAAAt6E,IACAA,IAAAkE,EAAA+B,UAEAzD,EAAAO,MAAA,YACAP,EAAAO,MAAA,eACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,eACAV,EAAAU,KAAA,YACAoE,GAmBA,SAAAA,EAAArG,GAKA,YAAAA,EACAuB,EAAAc,QAAAo3E,GAAAC,EAAAxpE,EAAAwpE,EAAAF,EAAAj4E,CAAAvB,GAIA,KAAAA,EACAuB,EAAAc,QAAAs3E,GAAAD,EAAAxpE,EAAA0pE,EAAAJ,EAAAj4E,CAAAvB,GAIAkQ,EAAAwpE,EAAA15E,GAAAw5E,EAAAx5E,GAiBA,SAAA45E,EAAA55E,GACA,OAAAuB,EAAAc,QAAAw3E,GAAAH,EAAAF,EAAAj4E,CAAAvB,GAmBA,SAAA05E,EAAA15E,GAEA,OAAAwB,EAAAxB,GAmBA,SAAAw5E,EAAAx5E,GAEA,OADAq5E,EAAAC,WAAA,EACAvzE,EAAA/F,KA5QA+M,UAiCA,SAAAhJ,EAAAoD,GACA,IAGAvE,EAEAqL,EAEA6rE,EAEAC,EATAx7E,EAAAwF,EAAAvF,OACA0G,EAAA,EAWA,KAAA3G,KAEA,GADAqE,EAAAmB,EAAAxF,GAAA,GACA0P,EAAA,CAEA,YAAArL,EAAA7E,MAAA,cAAA6E,EAAA7E,MAAA6E,EAAA22E,UACA,MAKA,UAAAx1E,EAAAxF,GAAA,kBAAAqE,EAAA7E,OACA6E,EAAA22E,WAAA,QAEK,GAAAO,GACL,aAAA/1E,EAAAxF,GAAA,oBAAAqE,EAAA7E,MAAA,cAAA6E,EAAA7E,QAAA6E,EAAA02E,YACArrE,EAAA1P,EACA,cAAAqE,EAAA7E,MAAA,CACAmH,EAAA,EACA,WAGK,aAAAtC,EAAA7E,OACL+7E,EAAAv7E,GAGA,MAAAy7E,EAAA,CACAj8E,KAAA,cAAAgG,EAAAkK,GAAA,GAAAlQ,KAAA,eACAa,MAAAuF,OAAAC,OAAA,GAA2BL,EAAAkK,GAAA,GAAArP,OAC3BG,IAAAoF,OAAAC,OAAA,GAAyBL,IAAAvF,OAAA,MAAAO,MAEzBk7E,EAAA,CACAl8E,KAAA,QACAa,MAAAuF,OAAAC,OAAA,GAA2BL,EAAAkK,GAAA,GAAArP,OAC3BG,IAAAoF,OAAAC,OAAA,GAAyBL,EAAA+1E,GAAA,GAAA/6E,MAEzBkK,EAAA,CACAlL,KAAA,YACAa,MAAAuF,OAAAC,OAAA,GAA2BL,EAAAkK,EAAA/I,EAAA,MAAAnG,KAC3BA,IAAAoF,OAAAC,OAAA,GAAyBL,EAAA+1E,EAAA,MAAAl7E,QAwBzB,OAnBAm7E,EAAU16E,EAHV06E,EAAA,UAAAC,EAAA7yE,GAAA,SAAA8yE,EAAA9yE,IAGcpD,EAAA3E,MAAA6O,EAAA,EAAAA,EAAA/I,EAAA,IAGd60E,EAAU16E,EAAI06E,EAAA,UAAA9wE,EAAA9B,KAKd4yE,EAAU16E,EAAI06E,EAAQpxE,EAAUxB,EAAA5E,OAAAC,WAAA03E,WAAAh0E,KAAAnC,EAAA3E,MAAA6O,EAAA/I,EAAA,EAAA40E,EAAA,GAAA3yE,IAGhC4yE,EAAU16E,EAAI06E,EAAA,SAAA9wE,EAAA9B,GAAApD,EAAA+1E,EAAA,GAAA/1E,EAAA+1E,EAAA,WAAAG,EAAA9yE,KAGd4yE,EAAU16E,EAAI06E,EAAAh2E,EAAA3E,MAAA06E,EAAA,IAGdC,EAAU16E,EAAI06E,EAAA,SAAAC,EAAA7yE,KACZzI,EAAMqF,EAAAkK,EAAAlK,EAAAvF,OAAAu7E,GACRh2E,GA3GA4E,WAiBA,SAAA5E,GACA,IAAAxF,GAAA,EACA,OAAAA,EAAAwF,EAAAvF,QAAA,CACA,MAAAoE,EAAAmB,EAAAxF,GAAA,GACA,eAAAqE,EAAA7E,MAAA,cAAA6E,EAAA7E,MAAA,aAAA6E,EAAA7E,OAEAgG,EAAArF,OAAAH,EAAA,iBAAAqE,EAAA7E,KAAA,KACA6E,EAAA7E,KAAA,OACAQ,KAGA,OAAAwF,IAxBA01E,GAAA,CACAt3E,SA8QA,SAAAZ,EAAAC,EAAAuE,GACA,OAYA,SAAA/F,GAKA,OAJAuB,EAAAO,MAAA,YACAP,EAAAO,MAAA,kBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,kBACAk4E,GAaA,SAAAA,EAAAn6E,GACA,OAAWc,EAAyBd,GAASqP,EAAiB9N,EAAA64E,EAAjB/qE,CAAiBrP,GAAAo6E,EAAAp6E,GAa9D,SAAAo6E,EAAAp6E,GACA,YAAAA,EACAq6E,EAAAr6E,GAEWmO,EAAkB5M,EAAA+4E,EAAAC,EAAA,8IAAlBpsE,CAAkBnO,GAa7B,SAAAs6E,EAAAt6E,GACA,OAAWc,EAAyBd,GAASqP,EAAiB9N,EAAAi5E,EAAjBnrE,CAAiBrP,GAAAq6E,EAAAr6E,GAa9D,SAAAu6E,EAAAv6E,GACA,OAAA+F,EAAA/F,GAaA,SAAAw6E,EAAAx6E,GACA,YAAAA,GAAA,KAAAA,GAAA,KAAAA,EACakP,EAAY3N,EAAAk5E,EAAA10E,EAAA,4DAAZmJ,CAAYlP,GAEzBq6E,EAAAr6E,GAaA,SAAAy6E,EAAAz6E,GACA,OAAWc,EAAyBd,GAASqP,EAAiB9N,EAAA84E,EAAjBhrE,CAAiBrP,GAAAq6E,EAAAr6E,GAa9D,SAAAq6E,EAAAr6E,GACA,YAAAA,GACAuB,EAAAO,MAAA,kBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,kBACAV,EAAAU,KAAA,YACAT,GAEAuE,EAAA/F,MA5YA25E,GAAA,CACAx3E,SAmZA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAYA,SAAAtC,GACA,OAAW8O,EAAYjP,KAAAoD,EAAA1B,EAAAm5E,EAAAC,EAAA,gDAAZ7rE,CAAY9O,IAavB,SAAA06E,EAAA16E,GACA,OAAAiD,EAAAV,OAAA2N,QAAA/J,SAAwCmJ,EAAmBrM,EAAAqF,eAAArF,EAAAc,OAAAd,EAAAc,OAAAvF,OAAA,OAAAY,MAAA,QAAAoC,EAAAxB,GAAA+F,EAAA/F,GAa3D,SAAA26E,EAAA36E,GACA,OAAA+F,EAAA/F,MA3bA65E,GAAA,CACA13E,SAkcA,SAAAZ,EAAAC,EAAAuE,GACA,OAcA,SAAA/F,GAOA,OAJAuB,EAAAO,MAAA,aACAP,EAAAO,MAAA,mBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,mBACA24E,GAeA,SAAAA,EAAA56E,GACA,YAAAA,GACAuB,EAAAO,MAAA,mBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,mBACAV,EAAAU,KAAA,aACAT,GAEAuE,EAAA/F,MChgBO,SAAA66E,GAAA76E,GACP,cAAAA,GAAuBc,EAAyBd,IAAUiB,EAAiBjB,GAC3E,EAEMgB,EAAkBhB,GACxB,OADA,ECPO,MAAA86E,GAAA,CACPjuE,KAAA,YACA1K,SA8HA,SAAAZ,EAAAC,GACA,MAAAu5E,EAAAz4E,KAAAC,OAAAC,WAAAu4E,iBAAA70E,KACAvD,EAAAL,KAAAK,SACAxC,EAAiB06E,GAAiBl4E,GAGlC,IAAAsK,EACA,OAYA,SAAAjN,GAGA,OAFAiN,EAAAjN,EACAuB,EAAAO,MAAA,qBACAyL,EAAAvN,IAaA,SAAAuN,EAAAvN,GACA,GAAAA,IAAAiN,EAEA,OADA1L,EAAAS,QAAAhC,GACAuN,EAEA,MAAA3K,EAAArB,EAAAU,KAAA,qBAGAoE,EAAkBw0E,GAAiB76E,GAInCiO,GAAA5H,GAAA,IAAAA,GAAAlG,GAAA46E,EAAA50E,SAAAnG,GACA85E,GAAA35E,GAAA,IAAAA,GAAAkG,GAAA00E,EAAA50E,SAAAxD,GAGA,OAFAC,EAAAo4E,MAAAn9E,QAAA,KAAAoP,EAAAgB,MAAA9N,IAAA25E,IACAl3E,EAAAq4E,OAAAp9E,QAAA,KAAAoP,EAAA6sE,MAAAzzE,IAAA4H,IACAzM,EAAAxB,KAhLA2I,WAQA,SAAA5E,EAAAoD,GACA,IAEA8G,EAEA+rE,EAEA/wE,EAEAiyE,EAEAC,EAEAC,EAEAC,EAEAn2E,EAhBA3G,GAAA,EAsBA,OAAAA,EAAAwF,EAAAvF,QAEA,aAAAuF,EAAAxF,GAAA,0BAAAwF,EAAAxF,GAAA,GAAAR,MAAAgG,EAAAxF,GAAA,GAAA08E,OAIA,IAHAhtE,EAAA1P,EAGA0P,KAEA,YAAAlK,EAAAkK,GAAA,0BAAAlK,EAAAkK,GAAA,GAAAlQ,MAAAgG,EAAAkK,GAAA,GAAA+sE,OAEA7zE,EAAAmB,eAAAvE,EAAAkK,GAAA,IAAAvE,WAAA,KAAAvC,EAAAmB,eAAAvE,EAAAxF,GAAA,IAAAmL,WAAA,IAKA,IAAA3F,EAAAkK,GAAA,GAAAgtE,QAAAl3E,EAAAxF,GAAA,GAAAy8E,SAAAj3E,EAAAxF,GAAA,GAAAQ,IAAAmG,OAAAnB,EAAAxF,GAAA,GAAAK,MAAAsG,QAAA,MAAAnB,EAAAkK,GAAA,GAAAlP,IAAAmG,OAAAnB,EAAAkK,GAAA,GAAArP,MAAAsG,OAAAnB,EAAAxF,GAAA,GAAAQ,IAAAmG,OAAAnB,EAAAxF,GAAA,GAAAK,MAAAsG,QAAA,GACA,SAIAk2E,EAAAr3E,EAAAkK,GAAA,GAAAlP,IAAAmG,OAAAnB,EAAAkK,GAAA,GAAArP,MAAAsG,OAAA,GAAAnB,EAAAxF,GAAA,GAAAQ,IAAAmG,OAAAnB,EAAAxF,GAAA,GAAAK,MAAAsG,OAAA,MACA,MAAAtG,EAAAuF,OAAAC,OAAA,GAAwCL,EAAAkK,GAAA,GAAAlP,KACxCA,EAAAoF,OAAAC,OAAA,GAAsCL,EAAAxF,GAAA,GAAAK,OACtC08E,GAAA18E,GAAAw8E,GACAE,GAAAv8E,EAAAq8E,GACAF,EAAA,CACAn9E,KAAAq9E,EAAA,sCACAx8E,QACAG,IAAAoF,OAAAC,OAAA,GAAiCL,EAAAkK,GAAA,GAAAlP,MAEjCo8E,EAAA,CACAp9E,KAAAq9E,EAAA,sCACAx8E,MAAAuF,OAAAC,OAAA,GAAmCL,EAAAxF,GAAA,GAAAK,OACnCG,OAEAkK,EAAA,CACAlL,KAAAq9E,EAAA,8BACAx8E,MAAAuF,OAAAC,OAAA,GAAmCL,EAAAkK,GAAA,GAAAlP,KACnCA,IAAAoF,OAAAC,OAAA,GAAiCL,EAAAxF,GAAA,GAAAK,QAEjCo7E,EAAA,CACAj8E,KAAAq9E,EAAA,sBACAx8E,MAAAuF,OAAAC,OAAA,GAAmC82E,EAAAt8E,OACnCG,IAAAoF,OAAAC,OAAA,GAAiC+2E,EAAAp8E,MAEjCgF,EAAAkK,GAAA,GAAAlP,IAAAoF,OAAAC,OAAA,GAAgD82E,EAAAt8E,OAChDmF,EAAAxF,GAAA,GAAAK,MAAAuF,OAAAC,OAAA,GAAmD+2E,EAAAp8E,KACnDs8E,EAAA,GAGAt3E,EAAAkK,GAAA,GAAAlP,IAAAmG,OAAAnB,EAAAkK,GAAA,GAAArP,MAAAsG,SACAm2E,EAAyBh8E,EAAIg8E,EAAA,UAAAt3E,EAAAkK,GAAA,GAAA9G,GAAA,QAAApD,EAAAkK,GAAA,GAAA9G,MAI7Bk0E,EAAuBh8E,EAAIg8E,EAAA,UAAArB,EAAA7yE,GAAA,SAAA+zE,EAAA/zE,GAAA,QAAA+zE,EAAA/zE,GAAA,SAAA8B,EAAA9B,KAK3Bk0E,EAAuBh8E,EAAIg8E,EAAa1yE,EAAUxB,EAAA5E,OAAAC,WAAA03E,WAAAh0E,KAAAnC,EAAA3E,MAAA6O,EAAA,EAAA1P,GAAA4I,IAGlDk0E,EAAuBh8E,EAAIg8E,EAAA,SAAApyE,EAAA9B,GAAA,SAAAg0E,EAAAh0E,GAAA,QAAAg0E,EAAAh0E,GAAA,QAAA6yE,EAAA7yE,KAG3BpD,EAAAxF,GAAA,GAAAQ,IAAAmG,OAAAnB,EAAAxF,GAAA,GAAAK,MAAAsG,QACAA,EAAA,EACAm2E,EAAyBh8E,EAAIg8E,EAAA,UAAAt3E,EAAAxF,GAAA,GAAA4I,GAAA,QAAApD,EAAAxF,GAAA,GAAA4I,MAE7BjC,EAAA,EAEUxG,EAAMqF,EAAAkK,EAAA,EAAA1P,EAAA0P,EAAA,EAAAotE,GAChB98E,EAAA0P,EAAAotE,EAAA78E,OAAA0G,EAAA,EACA,MAOA3G,GAAA,EACA,OAAAA,EAAAwF,EAAAvF,QACA,sBAAAuF,EAAAxF,GAAA,GAAAR,OACAgG,EAAAxF,GAAA,GAAAR,KAAA,QAGA,OAAAgG,IAwEA,SAAAu3E,GAAAt3E,EAAAkB,GACAlB,EAAA2F,QAAAzE,EACAlB,EAAAkB,UACAlB,EAAA6F,cAAA3E,EC5MO,MAAMq2E,GAAQ,CACrBC,GAAQruE,EACRsuE,GAAQtuE,EACRuuE,GAAQvuE,EACRwuE,GAAQxuE,EACRyuE,GAAQzuE,EACR0uE,GAAQ1uE,EACR2uE,GAAQ3uE,EACR4uE,GAAQ5uE,EACR6uE,GAAQ7uE,EACR8uE,GAAQ9uE,EACR+uE,GAAQ/uE,EACRgvE,GAAQhvE,EACRivE,GAAQjvE,EACRkvE,GAAQruE,GAIDvL,GAAA,CACP65E,GAAQ5sE,IAIDlH,GAAA,CACP+zE,EAAA,GAAQjsE,GACRisE,EAAA,GAAQjsE,GACRksE,GAAQlsE,IAIKmsE,GAAI,CACjBC,GC1BO,CACP7vE,KAAA,aACA1K,SA8CA,SAAAZ,EAAAC,EAAAuE,GACA,IAAAlE,EAAA,EACA,OAYA,SAAA7B,GAGA,OADAuB,EAAAO,MAAA,cAcA,SAAA9B,GAEA,OADAuB,EAAAO,MAAA,sBACA4R,EAAA1T,GAfAG,CAAAH,IA4BA,SAAA0T,EAAA1T,GACA,YAAAA,GAAA6B,IAAA,GACAN,EAAAS,QAAAhC,GACA0T,GAIA,OAAA1T,GAAyBc,EAAyBd,IAClDuB,EAAAU,KAAA,sBACAkH,EAAAnJ,IAEA+F,EAAA/F,GAaA,SAAAmJ,EAAAnJ,GACA,YAAAA,GACAuB,EAAAO,MAAA,sBACA66E,EAAA38E,IAEA,OAAAA,GAAyBa,EAAkBb,IAC3CuB,EAAAU,KAAA,cAIAT,EAAAxB,IAEQe,EAAaf,GACRsB,EAAYC,EAAA4H,EAAA,aAAZ7H,CAAYtB,IAKzBuB,EAAAO,MAAA,kBACAiB,EAAA/C,IAeA,SAAA28E,EAAA38E,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACA28E,IAEAp7E,EAAAU,KAAA,sBACAkH,EAAAnJ,IAaA,SAAA+C,EAAA/C,GACA,cAAAA,GAAA,KAAAA,GAAwCc,EAAyBd,IACjEuB,EAAAU,KAAA,kBACAkH,EAAAnJ,KAEAuB,EAAAS,QAAAhC,GACA+C,KA7KAoF,QAIA,SAAApE,EAAAoD,GACA,IAGAyJ,EAEA3H,EALAjB,EAAAjE,EAAAvF,OAAA,EACA4D,EAAA,EAOA,eAAA2B,EAAA3B,GAAA,GAAArE,OACAqE,GAAA,GAIA4F,EAAA,EAAA5F,GAAA,eAAA2B,EAAAiE,GAAA,GAAAjK,OACAiK,GAAA,GAEA,uBAAAjE,EAAAiE,GAAA,GAAAjK,OAAAqE,IAAA4F,EAAA,GAAAA,EAAA,EAAA5F,GAAA,eAAA2B,EAAAiE,EAAA,MAAAjK,QACAiK,GAAA5F,EAAA,IAAA4F,EAAA,KAEAA,EAAA5F,IACAwO,EAAA,CACA7S,KAAA,iBACAa,MAAAmF,EAAA3B,GAAA,GAAAxD,MACAG,IAAAgF,EAAAiE,GAAA,GAAAjJ,KAEAkK,EAAA,CACAlL,KAAA,YACAa,MAAAmF,EAAA3B,GAAA,GAAAxD,MACAG,IAAAgF,EAAAiE,GAAA,GAAAjJ,IACA8D,YAAA,QAEInE,EAAMqF,EAAA3B,EAAA4F,EAAA5F,EAAA,YAAAwO,EAAAzJ,GAAA,SAAA8B,EAAA9B,GAAA,QAAA8B,EAAA9B,GAAA,QAAAyJ,EAAAzJ,MAEV,OAAApD,IDdAy3E,GAAQxuE,EACR0uE,GAAA,CAAShrE,GAAiB1D,GAC1B4vE,GAAQ3rE,GACR4rE,GAAQnsE,GACRosE,GAAQ9vE,EACR+vE,GAAQ5pE,GACR6pE,IAAS7pE,IAII8pE,GAAM,CACnBC,GAAQlE,GACRmE,GAAQjE,IAIKkE,GAAI,CACjBb,EAAA,GAAQpD,GACRoD,EAAA,GAAQpD,GACRoD,EAAA,GAAQpD,GACRkE,GElDO,CACPxwE,KAAA,kBACA1K,SAQA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAYA,SAAAtC,GAKA,OAJAuB,EAAAO,MAAA,cACAP,EAAAO,MAAA,oBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,oBACAgM,GAaA,SAAAA,EAAAjO,GACA,YAAAA,GACAuB,EAAAO,MAAA,eACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,eACAV,EAAAU,KAAA,cACAoE,GAEAN,EAAA/F,GA8BA,SAAAqG,EAAArG,GAMA,YAAAA,GAAA,2BAAAiD,EAAAV,OAAAC,WAAAuD,EAAA/F,GAAAwB,EAAAxB,KAnFA2I,WAAcywE,GAAQzwE,YFgDtBu0E,GAAQlE,GACRwC,GAAQV,GACR8B,GAAA,CGtDO,CACP/vE,KAAA,WACA1K,SAOA,SAAAZ,EAAAC,EAAAuE,GACA,IAAAlE,EAAA,EACA,OAcA,SAAA7B,GAMA,OALAuB,EAAAO,MAAA,YACAP,EAAAO,MAAA,kBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,kBACAV,EAAAO,MAAA,oBACAmM,GAeA,SAAAA,EAAAjO,GACA,OAAQK,EAAUL,IAClBuB,EAAAS,QAAAhC,GACAs9E,GAEAC,EAAAv9E,GAeA,SAAAs9E,EAAAt9E,GAEA,YAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAqDO,EAAiBP,IAEtE6B,EAAA,EACA27E,EAAAx9E,IAEAu9E,EAAAv9E,GAeA,SAAAw9E,EAAAx9E,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACA6B,EAAA,EACA47E,IAIA,KAAAz9E,GAAA,KAAAA,GAAA,KAAAA,GAAsDO,EAAiBP,KAAA6B,IAAA,IACvEN,EAAAS,QAAAhC,GACAw9E,IAEA37E,EAAA,EACA07E,EAAAv9E,IAaA,SAAAy9E,EAAAz9E,GACA,YAAAA,GACAuB,EAAAU,KAAA,oBACAV,EAAAO,MAAA,kBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,kBACAV,EAAAU,KAAA,YACAT,GAIA,OAAAxB,GAAA,KAAAA,GAAA,KAAAA,GAAuDS,EAAYT,GACnE+F,EAAA/F,IAEAuB,EAAAS,QAAAhC,GACAy9E,GAaA,SAAAF,EAAAv9E,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACA09E,GAEQl9E,EAAUR,IAClBuB,EAAAS,QAAAhC,GACAu9E,GAEAx3E,EAAA/F,GAaA,SAAA09E,EAAA19E,GACA,OAAWO,EAAiBP,GAAA29E,EAAA39E,GAAA+F,EAAA/F,GAa5B,SAAA29E,EAAA39E,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACA6B,EAAA,EACA67E,GAEA,KAAA19E,GAEAuB,EAAAU,KAAA,oBAAAlE,KAAA,gBACAwD,EAAAO,MAAA,kBACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,kBACAV,EAAAU,KAAA,YACAT,GAEAo8E,EAAA59E,GAeA,SAAA49E,EAAA59E,GAEA,SAAAA,GAAwBO,EAAiBP,KAAA6B,IAAA,IACzC,MAAAiB,EAAA,KAAA9C,EAAA49E,EAAAD,EAEA,OADAp8E,EAAAS,QAAAhC,GACA8C,EAEA,OAAAiD,EAAA/F,MCrNqB,CACrB6M,KAAA,WACA1K,SAOA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KAEA,IAAA2K,EAEA1O,EAEAuN,EACA,OAYA,SAAA9L,GAIA,OAHAuB,EAAAO,MAAA,YACAP,EAAAO,MAAA,gBACAP,EAAAS,QAAAhC,GACAiO,GAiBA,SAAAA,EAAAjO,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAqR,GAEA,KAAArR,GACAuB,EAAAS,QAAAhC,GACAsR,GAEA,KAAAtR,GACAuB,EAAAS,QAAAhC,GACA69E,GAIQx9E,EAAUL,IAClBuB,EAAAS,QAAAhC,GACA89E,GAEA/3E,EAAA/F,GAiBA,SAAAqR,EAAArR,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAyR,GAEA,KAAAzR,GACAuB,EAAAS,QAAAhC,GACAzB,EAAA,EACAmT,GAEQrR,EAAUL,IAClBuB,EAAAS,QAAAhC,GACA+9E,GAEAh4E,EAAA/F,GAaA,SAAAyR,EAAAzR,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAg+E,GAEAj4E,EAAA/F,GAaA,SAAAi+E,EAAAj+E,GACA,cAAAA,EACA+F,EAAA/F,GAEA,KAAAA,GACAuB,EAAAS,QAAAhC,GACAk+E,GAEQr9E,EAAkBb,IAC1B8L,EAAAmyE,EACAE,EAAAn+E,KAEAuB,EAAAS,QAAAhC,GACAi+E,GAaA,SAAAC,EAAAl+E,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAg+E,GAEAC,EAAAj+E,GAaA,SAAAg+E,EAAAh+E,GACA,YAAAA,EAAAjB,EAAAiB,GAAA,KAAAA,EAAAk+E,EAAAl+E,GAAAi+E,EAAAj+E,GAaA,SAAA0R,EAAA1R,GAEA,OAAAA,IADA,SACA0J,WAAAnL,MACAgD,EAAAS,QAAAhC,GACAzB,IAHA,SAGAC,OAAA4/E,EAAA1sE,GAEA3L,EAAA/F,GAaA,SAAAo+E,EAAAp+E,GACA,cAAAA,EACA+F,EAAA/F,GAEA,KAAAA,GACAuB,EAAAS,QAAAhC,GACAq+E,GAEQx9E,EAAkBb,IAC1B8L,EAAAsyE,EACAD,EAAAn+E,KAEAuB,EAAAS,QAAAhC,GACAo+E,GAaA,SAAAC,EAAAr+E,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAs+E,GAEAF,EAAAp+E,GAaA,SAAAs+E,EAAAt+E,GACA,YAAAA,EACAjB,EAAAiB,GAEA,KAAAA,GACAuB,EAAAS,QAAAhC,GACAs+E,GAEAF,EAAAp+E,GAaA,SAAA+9E,EAAA/9E,GACA,cAAAA,GAAA,KAAAA,EACAjB,EAAAiB,GAEQa,EAAkBb,IAC1B8L,EAAAiyE,EACAI,EAAAn+E,KAEAuB,EAAAS,QAAAhC,GACA+9E,GAaA,SAAAF,EAAA79E,GACA,cAAAA,EACA+F,EAAA/F,GAEA,KAAAA,GACAuB,EAAAS,QAAAhC,GACAu+E,GAEQ19E,EAAkBb,IAC1B8L,EAAA+xE,EACAM,EAAAn+E,KAEAuB,EAAAS,QAAAhC,GACA69E,GAaA,SAAAU,EAAAv+E,GACA,YAAAA,EAAAjB,EAAAiB,GAAA69E,EAAA79E,GAaA,SAAAsR,EAAAtR,GAEA,OAAQK,EAAUL,IAClBuB,EAAAS,QAAAhC,GACAw+E,GAEAz4E,EAAA/F,GAaA,SAAAw+E,EAAAx+E,GAEA,YAAAA,GAAuBO,EAAiBP,IACxCuB,EAAAS,QAAAhC,GACAw+E,GAEAC,EAAAz+E,GAaA,SAAAy+E,EAAAz+E,GACA,OAAQa,EAAkBb,IAC1B8L,EAAA2yE,EACAN,EAAAn+E,IAEQe,EAAaf,IACrBuB,EAAAS,QAAAhC,GACAy+E,GAEA1/E,EAAAiB,GAaA,SAAA89E,EAAA99E,GAEA,YAAAA,GAAuBO,EAAiBP,IACxCuB,EAAAS,QAAAhC,GACA89E,GAEA,KAAA99E,GAAA,KAAAA,GAAsCc,EAAyBd,GAC/D0+E,EAAA1+E,GAEA+F,EAAA/F,GAaA,SAAA0+E,EAAA1+E,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAjB,GAIA,KAAAiB,GAAA,KAAAA,GAAsCK,EAAUL,IAChDuB,EAAAS,QAAAhC,GACA2+E,GAEQ99E,EAAkBb,IAC1B8L,EAAA4yE,EACAP,EAAAn+E,IAEQe,EAAaf,IACrBuB,EAAAS,QAAAhC,GACA0+E,GAEA3/E,EAAAiB,GAaA,SAAA2+E,EAAA3+E,GAEA,YAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAoEO,EAAiBP,IACrFuB,EAAAS,QAAAhC,GACA2+E,GAEAC,EAAA5+E,GAcA,SAAA4+E,EAAA5+E,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACA6+E,GAEQh+E,EAAkBb,IAC1B8L,EAAA8yE,EACAT,EAAAn+E,IAEQe,EAAaf,IACrBuB,EAAAS,QAAAhC,GACA4+E,GAEAF,EAAA1+E,GAcA,SAAA6+E,EAAA7+E,GACA,cAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,EACA+F,EAAA/F,GAEA,KAAAA,GAAA,KAAAA,GACAuB,EAAAS,QAAAhC,GACAiN,EAAAjN,EACA8+E,GAEQj+E,EAAkBb,IAC1B8L,EAAA+yE,EACAV,EAAAn+E,IAEQe,EAAaf,IACrBuB,EAAAS,QAAAhC,GACA6+E,IAEAt9E,EAAAS,QAAAhC,GACA++E,GAaA,SAAAD,EAAA9+E,GACA,OAAAA,IAAAiN,GACA1L,EAAAS,QAAAhC,GACAiN,OAAAnN,EACAk/E,GAEA,OAAAh/E,EACA+F,EAAA/F,GAEQa,EAAkBb,IAC1B8L,EAAAgzE,EACAX,EAAAn+E,KAEAuB,EAAAS,QAAAhC,GACA8+E,GAaA,SAAAC,EAAA/+E,GACA,cAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAA,KAAAA,EACA+F,EAAA/F,GAEA,KAAAA,GAAA,KAAAA,GAAsCc,EAAyBd,GAC/D0+E,EAAA1+E,IAEAuB,EAAAS,QAAAhC,GACA++E,GAcA,SAAAC,EAAAh/E,GACA,YAAAA,GAAA,KAAAA,GAAsCc,EAAyBd,GAC/D0+E,EAAA1+E,GAEA+F,EAAA/F,GAaA,SAAAjB,EAAAiB,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,gBACAV,EAAAU,KAAA,YACAT,GAEAuE,EAAA/F,GAiBA,SAAAm+E,EAAAn+E,GAKA,OAJAuB,EAAAU,KAAA,gBACAV,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACAg9E,EAiBA,SAAAA,EAAAj/E,GAGA,OAAWe,EAAaf,GAASsB,EAAYC,EAAA29E,EAAA,aAAAj8E,EAAAV,OAAAC,WAAAyD,QAAAC,KAAAC,SAAA,qBAAArG,EAAA,EAAZwB,CAAYtB,GAAAk/E,EAAAl/E,GAiB7C,SAAAk/E,EAAAl/E,GAEA,OADAuB,EAAAO,MAAA,gBACAgK,EAAA9L,OJhmBAs8E,GKtDO,CACPzvE,KAAA,iBACA1K,SAQA,SAAAZ,EAAAC,EAAAuE,GACA,MAAA9C,EAAAX,KACA,OAYA,SAAAtC,GAMA,OALAuB,EAAAO,MAAA,aACAP,EAAAO,MAAA,eACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,eACAV,EAAAU,KAAA,aACAoE,GAIA,SAAAA,EAAArG,GAKA,YAAAA,GAAA,2BAAAiD,EAAAV,OAAAC,WAAAuD,EAAA/F,GAAAwB,EAAAxB,KApCA2I,WAAcywE,GAAQzwE,YLoDtBw0E,GAAA,CMxDO,CACPtwE,KAAA,kBACA1K,SAOA,SAAAZ,EAAAC,EAAAuE,GACA,OAaA,SAAA/F,GAGA,OAFAuB,EAAAO,MAAA,mBACAP,EAAAS,QAAAhC,GACAqG,GAcA,SAAAA,EAAArG,GACA,OAAQa,EAAkBb,IAC1BuB,EAAAU,KAAA,mBACAT,EAAAxB,IAEA+F,EAAA/F,MNW0Bk5E,IAC1BiG,GAAQ/F,GACR0D,GAAQhC,GACRiC,GOxDqB,CACrBlwE,KAAA,WACA1K,SAmEA,SAAAZ,EAAAC,EAAAuE,GAEA,IAEAlE,EAEAe,EAJA2Q,EAAA,EAKA,OAcA,SAAAvT,GAGA,OAFAuB,EAAAO,MAAA,YACAP,EAAAO,MAAA,oBACA4R,EAAA1T,IAaA,SAAA0T,EAAA1T,GACA,YAAAA,GACAuB,EAAAS,QAAAhC,GACAuT,IACAG,IAEAnS,EAAAU,KAAA,oBACA08B,EAAA3+B,IAaA,SAAA2+B,EAAA3+B,GAEA,cAAAA,EACA+F,EAAA/F,GAMA,KAAAA,GACAuB,EAAAO,MAAA,SACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,SACA08B,GAIA,KAAA3+B,GACA4C,EAAArB,EAAAO,MAAA,oBACAD,EAAA,EACAyR,EAAAtT,IAEQa,EAAkBb,IAC1BuB,EAAAO,MAAA,cACAP,EAAAS,QAAAhC,GACAuB,EAAAU,KAAA,cACA08B,IAIAp9B,EAAAO,MAAA,gBACAiB,EAAA/C,IAaA,SAAA+C,EAAA/C,GACA,cAAAA,GAAA,KAAAA,GAAA,KAAAA,GAAuDa,EAAkBb,IACzEuB,EAAAU,KAAA,gBACA08B,EAAA3+B,KAEAuB,EAAAS,QAAAhC,GACA+C,GAaA,SAAAuQ,EAAAtT,GAEA,YAAAA,GACAuB,EAAAS,QAAAhC,GACA6B,IACAyR,GAIAzR,IAAA0R,GACAhS,EAAAU,KAAA,oBACAV,EAAAU,KAAA,YACAT,EAAAxB,KAIA4C,EAAA7E,KAAA,eACAgF,EAAA/C,MA3MAmI,QAMA,SAAApE,GACA,IAGAxF,EAEAuD,EALAs9E,EAAAr7E,EAAAvF,OAAA,EACA6gF,EAAA,EAOA,mBAAAt7E,EAAAs7E,GAAA,GAAAthF,MAAA,UAAAgG,EAAAs7E,GAAA,GAAAthF,QAAA,eAAAgG,EAAAq7E,GAAA,GAAArhF,MAAA,UAAAgG,EAAAq7E,GAAA,GAAArhF,MAIA,IAHAQ,EAAA8gF,IAGA9gF,EAAA6gF,GACA,oBAAAr7E,EAAAxF,GAAA,GAAAR,KAAA,CAEAgG,EAAAs7E,GAAA,GAAAthF,KAAA,kBACAgG,EAAAq7E,GAAA,GAAArhF,KAAA,kBACAshF,GAAA,EACAD,GAAA,EACA,MAMA7gF,EAAA8gF,EAAA,EACAD,IACA,OAAA7gF,GAAA6gF,QACAt/E,IAAAgC,EACAvD,IAAA6gF,GAAA,eAAAr7E,EAAAxF,GAAA,GAAAR,OACA+D,EAAAvD,GAEKA,IAAA6gF,GAAA,eAAAr7E,EAAAxF,GAAA,GAAAR,OACLgG,EAAAjC,GAAA,GAAA/D,KAAA,eACAQ,IAAAuD,EAAA,IACAiC,EAAAjC,GAAA,GAAA/C,IAAAgF,EAAAxF,EAAA,MAAAQ,IACAgF,EAAArF,OAAAoD,EAAA,EAAAvD,EAAAuD,EAAA,GACAs9E,GAAA7gF,EAAAuD,EAAA,EACAvD,EAAAuD,EAAA,GAEAA,OAAAhC,GAGA,OAAAiE,GAjDApB,SAwDA,SAAiB3C,GAEjB,YAAAA,GAAA,oBAAAsC,KAAAyB,OAAAzB,KAAAyB,OAAAvF,OAAA,MAAAT,QPFOm8E,GAAA,CACPh0E,KAAA,CAAS40E,GAAWpyE,IAIP42E,GAAgB,CAC7Bp5E,KAAA,SAIOD,GAAA,CACPC,KAAA,IQ/DO,SAAAq5E,GAAAC,GACP,MAKAj9E,EAAA,CACA2N,QAAA,GACAnL,KAAA,GACAvC,W3CXO,SAAAi9E,GAEP,MAAAhgF,EAAA,GACA,IAAAlB,GAAA,EACA,OAAAA,EAAAkhF,EAAAjhF,QACAgB,EAAAC,EAAAggF,EAAAlhF,IAEA,OAAAkB,E2CFEigF,CAAiB,CAAEC,MAFrBH,GAAA,IAEsCC,YAAA,KAOtC7uE,QAAA9D,EAAoB5K,GACpB8D,SAAA8G,EAAqB9J,GACrBoC,KAAA0H,EAAiB1H,GACjBw6E,OAAA9yE,EAAmBjE,GACnBI,KAAA6D,EAAiB/D,IAEjB,OAAAxG,EAKA,SAAAuK,EAAAvE,GACA,OAEA,SAAArJ,GACA,OAAa6K,EAAexH,EAAAgG,EAAArJ,KC9B5B,MAAA2gF,GAAA,cCDO,SAAAC,GAAApiF,EAAAqiF,GACP,MAAA//E,EAAA2B,OAAAq+E,SAAAtiF,EAAAqiF,GACA,OAEA//E,EAAA,QAAAA,KAAA,IAAAA,EAAA,IAEAA,EAAA,KAAAA,EAAA,KAEAA,EAAA,OAAAA,EAAA,OAEAA,EAAA,OAAAA,EAAA,sBAAAA,IAAA,eAAAA,IAEAA,EAAA,QACA,SAEAoB,OAAAC,aAAArB,GC3BA,MAAAigF,GAAA,oEAwBA,SAAAC,GAAAC,EAAAC,EAAAC,GACA,GAAAD,EAEA,OAAAA,EAKA,QADAC,EAAA32E,WAAA,GACA,CACA,MAAA8B,EAAA60E,EAAA32E,WAAA,GACA42E,EAAA,MAAA90E,GAAA,KAAAA,EACA,OAAWs0E,GAA+BO,EAAAjhF,MAAAkhF,EAAA,KAAAA,EAAA,OAE1C,OAASvH,GAA6BsH,IAAAF,ECH/B,SAAAI,GAAA7iF,GAEP,OAAAA,GAAA,kBAAAA,EAKA,aAAAA,GAAA,SAAAA,EACA8iF,GAAA9iF,EAAA8iF,UAIA,UAAA9iF,GAAA,QAAAA,EACA8iF,GAAA9iF,GAIA,SAAAA,GAAA,WAAAA,EACW+iF,GAAK/iF,GAIhB,GAnBA,GA0BA,SAAS+iF,GAAKz8E,GACd,OAAS08E,GAAK18E,KAAAiB,MAAA,IAA8By7E,GAAK18E,KAAA2F,QAOjD,SAAA62E,GAAAG,GACA,OAASF,GAAKE,KAAA/hF,OAAA,IAA2B6hF,GAAKE,KAAA5hF,KAO9C,SAAS2hF,GAAKhjF,GACd,OAAAA,GAAA,kBAAAA,IAAA,ECyEA,MAAMkjF,GAAG,GAAKrhF,eAYPshF,GAcP,SAAAnjF,EAAAojF,EAAAtB,GAKA,MAJA,kBAAAsB,IACAtB,EAAAsB,EACAA,OAAAhhF,GAUA,SAAA0/E,GAEA,MAAAuB,EAAA,CACAC,WAAA,GACAC,eAAA,uDACAn/E,MAAA,CACAo/E,SAAAC,EAAAC,GACAC,iBAAAC,EACAC,cAAAD,EACAE,WAAAL,EAAArwE,GACA2wE,WAAAN,EA41BA,WACA,OACApjF,KAAA,aACAG,SAAA,MA91BAg7E,gBAAAoI,EACAtI,mBAAAsI,EACAnuE,WAAAguE,EAAAO,GACAC,oBAAAxwE,EACAywE,oBAAAzwE,EACAb,aAAA6wE,EAAAO,EAAAvwE,GACA0wE,SAAAV,EAu2BA,WACA,OACApjF,KAAA,aACAL,MAAA,KA12BAyT,GACA2wE,aAAAR,EACAv+E,KAAAu+E,EACAS,cAAAT,EACAzwE,WAAAswE,EA22BA,WACA,OACApjF,KAAA,aACA4R,WAAA,GACAsqE,MAAA,KACA+H,MAAA,KACAC,IAAA,MAh3BAC,4BAAA/wE,EACAgxE,sBAAAhxE,EACAixE,sBAAAjxE,EACAkxE,SAAAlB,EAk3BA,WACA,OACApjF,KAAA,WACAG,SAAA,MAp3BAokF,gBAAAnB,EAAAoB,GACAC,kBAAArB,EAAAoB,GACAtxE,SAAAkwE,EAAAsB,EAAAtxE,GACAuxE,aAAApB,EACAqB,SAAAxB,EAAAsB,EAAAtxE,GACAyxE,aAAAtB,EACAvmC,MAAAomC,EA44BA,WACA,OACApjF,KAAA,QACAikF,MAAA,KACAC,IAAA,GACAjkF,IAAA,QAh5BAi8E,MAAA9oE,EACAiwE,KAAAD,EAAAC,GACAyB,SAAA1B,EA86BA,SAAAv+E,GACA,OACA7E,KAAA,WACA+kF,OAAAlgF,EAAAmgF,QACAC,QAAA,KACA9kF,SAAA,MAl7BA+kF,cAyZA,SAAArgF,GACA,GAAAsgF,EAAA,gCACA,MAAAC,EAAA7gF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACA2kF,EAAAvkF,MAAA+C,OAAAq+E,SAAA19E,KAAAgG,eAAA1F,GAAA,IACAwgF,EAAA,iCA5ZAC,YAAAlC,EAAAxiF,EAgZA,WACAykF,EAAA,oCAhZAE,cAAAnC,EAAAxiF,GACAgS,UAAAwwE,EAo7BA,WACA,OACApjF,KAAA,YACAG,SAAA,MAt7BAqlF,UAmvBA,WACAH,EAAA,8BAnvBAI,gBAAAryE,EACAsyE,0BAAAtyE,EACAuyE,oBAAAvyE,EACAwyE,cAAAxC,EAAArwE,GACA8yE,OAAAzC,EAs7BA,WACA,OACApjF,KAAA,SACAG,SAAA,MAx7BA2lF,cAAA1C,EAq8BA,WACA,OACApjF,KAAA,oBAr8BAkE,KAAA,CACAu/E,WAAAsC,IACAC,mBA0eA,SAAAnhF,GACA,MAAAohF,EAAA1hF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACA,IAAAwlF,EAAAC,MAAA,CACA,MAAAA,EAAA3hF,KAAAgG,eAAA1F,GAAApE,OACAwlF,EAAAC,UA7eA/C,SAAA4C,IACAvC,cAuyBA,SAAA3+E,GACAshF,EAAArkF,KAAAyC,KAAAM,GACAN,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAyjF,IAAA,UAAA3/E,KAAAgG,eAAA1F,IAzyBAy+E,iBA4xBA,SAAAz+E,GACAshF,EAAArkF,KAAAyC,KAAAM,GACAN,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAyjF,IAAA3/E,KAAAgG,eAAA1F,IA9xBA6+E,WAAAqC,IACAK,qBAAAD,EACAE,oCAAAC,EACAC,gCAAAD,EACAE,wBAkwBA,SAAA3hF,GACA,MAAAG,EAAAT,KAAAgG,eAAA1F,GACA7E,EAAAmlF,EAAA,0BAEA,IAAAxlF,EACA,GAAAK,EACAL,EAAcoiF,GAA+B/8E,EAAA,oCAAAhF,EAAA,OAC7CqlF,EAAA,8BACK,CACL,MAAA9kF,EAAqBy6E,GAA6Bh2E,GAClDrF,EAAAY,EAEA,MAAA+J,EAAA/F,KAAAY,MAAA2E,MACAQ,EAAA3K,SACA2K,EAAAm4E,SAAAzhF,IAAwBylF,GAAK5hF,EAAA7D,MA/wB7BoU,WAAA2wE,EA6aA,WACA,MAAA/gF,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAd,MAAAqF,EAAAwM,QAAA,+BACA6zE,EAAA,oBAhbAsB,gBAiaA,WAEA,GAAAxB,EAAA,yBACA5gF,KAAA6O,SACAiyE,EAAA,sBApaAzB,oBA4YA,WACA,MAAA5+E,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAsgD,KAAA/7C,GA9YA6+E,oBAqZA,WACA,MAAA7+E,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAuV,KAAAhR,GAvZAg/E,cAAAmC,EACA5zE,aAAAwzE,EAmbA,WACA,MAAA/gF,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAd,MAAAqF,EAAAwM,QAAA,qBArbAsyE,SAAAiC,EAolBA,WACA,MAAA/gF,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAd,MAAAqF,IAtlBA++E,aAAAoC,EACAnhF,KAAAmhF,EACArzE,WAAAizE,IACA5B,4BA6cA,WACA,MAAAn/E,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAyjF,IAAAl/E,GA/cAo/E,sBAubA,SAAAv/E,GACA,MAAAq3E,EAAA33E,KAAAmiF,SACAT,EAAA1hF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAwlF,EAAA/J,QACA+J,EAAAr0E,WAAsBL,EAAmBhN,KAAAgG,eAAA1F,IAAA4M,eA1bzC4yE,sBAicA,WACA,MAAAr/E,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAwjF,MAAAj/E,GAncAs/E,SAAAyB,IACAxB,gBAAAwB,EAAAa,GACAnC,kBAAAsB,EAAAa,GACA1zE,SAAA6yE,EAojBA,WACA,MAAA/gF,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAd,MAAAqF,IAtjBA2/E,aAAAwB,EACAvB,SAAAmB,EA6jBA,WACA,MAAA/gF,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAd,MAAAqF,IA/jBA6/E,aAAAsB,EACAnpC,MAAA+oC,EA6mBA,WACA,MAAAE,EAAA1hF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GAIA,GAAA0kF,EAAA,gBAEA,MAAA0B,EAAA1B,EAAA,6BACAc,EAAAjmF,MAAA,YAEAimF,EAAAY,uBAEAZ,EAAA/B,WACA+B,EAAAhC,kBAGAgC,EAAAr0E,kBAEAq0E,EAAA/J,MAEAmJ,EAAA,mBAhoBAnJ,MAupBA,WACA,MAAA4K,EAAAviF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAd,EAAA4E,KAAAmiF,SACAT,EAAA1hF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GAGA,GADA4kF,EAAA,kBACA,SAAAY,EAAAjmF,KAAA,CAGA,MAAAG,EAAA2mF,EAAA3mF,SACA8lF,EAAA9lF,gBAEA8lF,EAAAhmF,IAAAN,GAlqBAonF,UAuoBA,SAAAliF,GACA,MAAAg9E,EAAAt9E,KAAAgG,eAAA1F,GACAugF,EAAA7gF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GAGA2kF,EAAAlJ,OF/4BOv8E,EE+4B0BkiF,EF94BjCliF,EAAA6R,QAAA0wE,GAAAC,KEg5BAiD,EAAAxzE,WAA0BL,EAAmBswE,GAAApwE,cFj5BtC,IAAA9R,GEoQPy7E,WAghBA,SAAAv2E,GACA,MAAAuE,EAAA7E,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GAEA,GAAA0kF,EAAA,gBACA,MAAA76E,EAAAlB,EAAAjJ,SAAAiJ,EAAAjJ,SAAAM,OAAA,GAGA,OAFA6J,EAAAm4E,SAAAzhF,IAA0BylF,GAAK5hF,EAAA7D,UAC/BqkF,EAAA,gBAGAF,EAAA,iCAAAnC,EAAAE,eAAA96E,SAAAgB,EAAApJ,QACAujF,EAAAzhF,KAAAyC,KAAAM,GACAshF,EAAArkF,KAAAyC,KAAAM,KA1hBAw+E,KAAA0C,EA6kBA,WACA,MAAAE,EAAA1hF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GAIA,GAAA0kF,EAAA,gBAEA,MAAA0B,EAAA1B,EAAA,6BACAc,EAAAjmF,MAAA,YAEAimF,EAAAY,uBAEAZ,EAAA/B,WACA+B,EAAAhC,kBAGAgC,EAAAr0E,kBAEAq0E,EAAA/J,MAEAmJ,EAAA,mBAhmBAP,SAAAiB,IACAT,YAAAS,IACAR,cAAAQ,IACAnzE,UAAAmzE,IACAN,gBA4sBA,SAAA5gF,GACA,MAAAq3E,EAAA33E,KAAAmiF,SACAT,EAAA1hF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GAGAwlF,EAAA/J,QAEA+J,EAAAr0E,WAAsBL,EAAmBhN,KAAAgG,eAAA1F,IAAA4M,cACzC4zE,EAAA,yBAntBAK,0BAmqBA,WACA,MAAA1gF,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAyjF,IAAAl/E,GArqBA2gF,oBA6qBA,WACA,MAAA3gF,EAAAT,KAAAmiF,SACAniF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAwjF,MAAAj/E,GA/qBAgiF,SAurBA,WACA3B,EAAA,gBAvrBAO,cAAAG,EA6dA,WACAV,EAAA,kCA7dA4B,0BAmdA,SAAApiF,GACAN,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACAylF,MAAA,KAAA3hF,KAAAgG,eAAA1F,GAAA8G,WAAA,QApdAu7E,kBA0cA,WACA7B,EAAA,oCA1cAQ,OAAAE,IACAD,cAAAC,OA+6BA,SAAAoB,EAAAC,EAAA1F,GACA,IAAAlhF,GAAA,EACA,OAAAA,EAAAkhF,EAAAjhF,QAAA,CACA,MAAAd,EAAA+hF,EAAAlhF,GACAJ,MAAAC,QAAAV,GACAwnF,EAAAC,EAAAznF,GAEAgC,GAAAylF,EAAAznF,IAn7BAwnF,CAAAnE,GAAAvB,GAAA,IAAkC4F,iBAAA,IAGlC,MAAAriF,EAAA,GACA,OAUA,SAAAgB,GAEA,IAAAshF,EAAA,CACAtnF,KAAA,OACAG,SAAA,IAGA,MAAAiJ,EAAA,CACAjE,MAAA,CAAAmiF,GACAC,WAAA,GACAvE,SACAj/E,QACAG,OACAkP,SACAszE,SACArB,UACAF,WAGAqC,EAAA,GACA,IAAAhnF,GAAA,EACA,OAAAA,EAAAwF,EAAAvF,QAGA,mBAAAuF,EAAAxF,GAAA,GAAAR,MAAA,kBAAAgG,EAAAxF,GAAA,GAAAR,KACA,aAAAgG,EAAAxF,GAAA,GACAgnF,EAAAlmF,KAAAd,OACS,CACT,MAAA8J,EAAAk9E,EAAA19E,MACAtJ,EAAAinF,EAAAzhF,EAAAsE,EAAA9J,GAIAA,GAAA,EACA,OAAAA,EAAAwF,EAAAvF,QAAA,CACA,MAAAinF,EAAA1E,EAAAh9E,EAAAxF,GAAA,IACUqiF,GAAG/gF,KAAA4lF,EAAA1hF,EAAAxF,GAAA,GAAAR,OACb0nF,EAAA1hF,EAAAxF,GAAA,GAAAR,MAAA8B,KAAAsE,OAAAC,OAAA,CACAkE,eAAAvE,EAAAxF,GAAA,GAAA+J,gBACSnB,GAAApD,EAAAxF,GAAA,IAKT,GAAA4I,EAAAm+E,WAAA9mF,OAAA,GACA,MAAA6J,EAAAlB,EAAAm+E,WAAAn+E,EAAAm+E,WAAA9mF,OAAA,GACAinF,EAAAp9E,EAAA,IAAAq9E,GACAD,EAAA5lF,KAAAsH,OAAArH,EAAAuI,EAAA,IAIAg9E,EAAA7E,SAAA,CACA5hF,MAAa4lF,GAAKzgF,EAAAvF,OAAA,EAAAuF,EAAA,MAAAnF,MAAA,CAClBqG,KAAA,EACA0E,OAAA,EACAzE,OAAA,IAEAnG,IAAWylF,GAAKzgF,EAAAvF,OAAA,EAAAuF,IAAAvF,OAAA,MAAAO,IAAA,CAChBkG,KAAA,EACA0E,OAAA,EACAzE,OAAA,KAKA3G,GAAA,EACA,OAAAA,EAAAwiF,EAAAC,WAAAxiF,QACA6mF,EAAAtE,EAAAC,WAAAziF,GAAA8mF,MAEA,OAAAA,GASA,SAAAG,EAAAzhF,EAAAnF,EAAAJ,GACA,IAIAqkF,EAEAn8E,EAEAi/E,EAEAr4E,EAVA/O,EAAAK,EAAA,EACAgnF,GAAA,EACAC,GAAA,EASA,OAAAtnF,GAAAC,GAAA,CACA,MAAAiI,EAAA1C,EAAAxF,GAoBA,GAnBA,kBAAAkI,EAAA,GAAA1I,MAAA,gBAAA0I,EAAA,GAAA1I,MAAA,eAAA0I,EAAA,GAAA1I,MACA,UAAA0I,EAAA,GACAm/E,IAEAA,IAEAt4E,OAAAxN,GACO,oBAAA2G,EAAA,GAAA1I,KACP,UAAA0I,EAAA,MACAo8E,GAAAv1E,GAAAs4E,GAAAD,IACAA,EAAApnF,GAEA+O,OAAAxN,GAEO,eAAA2G,EAAA,GAAA1I,MAAA,kBAAA0I,EAAA,GAAA1I,MAAA,mBAAA0I,EAAA,GAAA1I,MAAA,mBAAA0I,EAAA,GAAA1I,MAAA,6BAAA0I,EAAA,GAAA1I,OAGPuP,OAAAxN,IAEA8lF,GAAA,UAAAn/E,EAAA,uBAAAA,EAAA,GAAA1I,OAAA,IAAA6nF,GAAA,SAAAn/E,EAAA,uBAAAA,EAAA,GAAA1I,MAAA,gBAAA0I,EAAA,GAAA1I,MAAA,CACA,GAAA8kF,EAAA,CACA,IAAAiD,EAAAvnF,EAEA,IADAmI,OAAA5G,EACAgmF,KAAA,CACA,MAAAC,EAAAhiF,EAAA+hF,GACA,kBAAAC,EAAA,GAAAhoF,MAAA,oBAAAgoF,EAAA,GAAAhoF,KAAA,CACA,YAAAgoF,EAAA,YACAr/E,IACA3C,EAAA2C,GAAA,GAAA3I,KAAA,kBACA8nF,GAAA,GAEAE,EAAA,GAAAhoF,KAAA,aACA2I,EAAAo/E,OACa,kBAAAC,EAAA,GAAAhoF,MAAA,qBAAAgoF,EAAA,GAAAhoF,MAAA,+BAAAgoF,EAAA,GAAAhoF,MAAA,qBAAAgoF,EAAA,GAAAhoF,MAAA,mBAAAgoF,EAAA,GAAAhoF,KAGb,MAGA4nF,KAAAj/E,GAAAi/E,EAAAj/E,KACAm8E,EAAAE,SAAA,GAIAF,EAAA9jF,IAAAoF,OAAAC,OAAA,GAAyCsC,EAAA3C,EAAA2C,GAAA,GAAA9H,MAAA6H,EAAA,GAAA1H,KACzCgF,EAAArF,OAAAgI,GAAAnI,EAAA,UAAAskF,EAAAp8E,EAAA,KACAlI,IACAC,IAIA,mBAAAiI,EAAA,GAAA1I,OACA8kF,EAAA,CACA9kF,KAAA,WACAglF,SAAA,EACAnkF,MAAAuF,OAAAC,OAAA,GAAmCqC,EAAA,GAAA7H,OAEnCG,SAAAe,GAGAiE,EAAArF,OAAAH,EAAA,WAAAskF,EAAAp8E,EAAA,KACAlI,IACAC,IACAmnF,OAAA7lF,EACAwN,GAAA,IAKA,OADAvJ,EAAAnF,GAAA,GAAAmkF,QAAA8C,EACArnF,EAeA,SAAA4kF,EAAA4C,EAAAtoF,GACAqF,EAAAijF,GAAAtoF,EAaA,SAAAwlF,EAAA8C,GACA,OAAAjjF,EAAAijF,GAaA,SAAA7E,EAAAr0E,EAAA8tB,GACA,OAOA,SAAAh4B,GACAd,EAAAjC,KAAAyC,KAAAwK,EAAAlK,MACAg4B,KAAA/6B,KAAAyC,KAAAM,IAQA,SAAAuO,IACA7O,KAAAY,MAAA7D,KAAA,CACAtB,KAAA,WACAG,SAAA,KAkBA,SAAA4D,EAAAkiF,EAAAphF,EAAAqjF,GACA,MAAAC,EAAA5jF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GASA,OAPA0nF,EAAAhoF,SAAAmB,KAAA2kF,GACA1hF,KAAAY,MAAA7D,KAAA2kF,GACA1hF,KAAAgjF,WAAAjmF,KAAA,CAAAuD,EAAAqjF,IAEAjC,EAAAxD,SAAA,CACA5hF,MAAa4lF,GAAK5hF,EAAAhE,QAElBolF,EAWA,SAAAF,EAAAlpD,GACA,OAOA,SAAAh4B,GACAg4B,KAAA/6B,KAAAyC,KAAAM,GACAX,EAAApC,KAAAyC,KAAAM,IAcA,SAAAX,EAAAW,EAAAujF,GACA,MAAAnC,EAAA1hF,KAAAY,MAAA2E,MACAoG,EAAA3L,KAAAgjF,WAAAz9E,MACA,IAAAoG,EACA,UAAAm4E,MAAA,iBAAAxjF,EAAA7E,KAAA,MAA8DwiF,GAAiB,CAC/E3hF,MAAAgE,EAAAhE,MACAG,IAAA6D,EAAA7D,MACO,yBACF,GAAAkP,EAAA,GAAAlQ,OAAA6E,EAAA7E,KACL,GAAAooF,EACAA,EAAAtmF,KAAAyC,KAAAM,EAAAqL,EAAA,QACO,CACP,MAAAw3E,EAAAx3E,EAAA,IAAAy3E,GACAD,EAAA5lF,KAAAyC,KAAAM,EAAAqL,EAAA,IAIA,OADA+1E,EAAAxD,SAAAzhF,IAAwBylF,GAAK5hF,EAAA7D,KAC7BilF,EAOA,SAAAS,IACA,OlDjlBO,SAAiB/mF,EAAA8hF,GACxB,MAAA6G,EAAA7G,GAAAhiF,EAGA,OAAAC,EAAAC,EAFA,mBAAA2oF,EAAA1oF,iBAAA0oF,EAAA1oF,gBACA,mBAAA0oF,EAAAzoF,aAAAyoF,EAAAzoF,akD8kBW0oF,CAAQhkF,KAAAY,MAAA2E,OAwJnB,SAAAy5E,EAAA1+E,GACA,MAAAohF,EAAA1hF,KAAAY,MAAAZ,KAAAY,MAAA1E,OAAA,GACA,IAAA6J,EAAA27E,EAAA9lF,SAAA8lF,EAAA9lF,SAAAM,OAAA,GACA6J,GAAA,SAAAA,EAAAtK,QAEAsK,EAqaA,CACAtK,KAAA,OACAL,MAAA,KAraA8iF,SAAA,CACA5hF,MAAe4lF,GAAK5hF,EAAAhE,QAGpBolF,EAAA9lF,SAAAmB,KAAAgJ,IAEA/F,KAAAY,MAAA7D,KAAAgJ,GAQA,SAAA67E,EAAAthF,GACA,MAAAyF,EAAA/F,KAAAY,MAAA2E,MACAQ,EAAA3K,OAAA4E,KAAAgG,eAAA1F,GACAyF,EAAAm4E,SAAAzhF,IAAwBylF,GAAK5hF,EAAA7D,KA4B7B,SAAA4lF,IACAvB,EAAA,kBA6LA,SAAAiB,EAAAzhF,GACAwgF,EAAA,yBAAAxgF,EAAA7E,MAyDA,SAAA2jF,IACA,OACA3jF,KAAA,OACA+gD,KAAA,KACA/qC,KAAA,KACArW,MAAA,IAgCA,SAAAoT,IAEA,OACA/S,KAAA,UACAkmF,WAAAnkF,EACA5B,SAAA,IAKA,SAAAqkF,IACA,OACAxkF,KAAA,SAKA,SAAA0kF,IACA,OACA1kF,KAAA,OACAL,MAAA,IAeA,SAAA0jF,IACA,OACArjF,KAAA,OACAikF,MAAA,KACAC,IAAA,GACA/jF,SAAA,IAQA,SAAAS,EAAAiE,GACA,OACA7E,KAAA,OACAwoF,QAAA,gBAAA3jF,EAAA7E,KACAa,MAAA,KACAkkF,OAAAlgF,EAAAmgF,QACA7kF,SAAA,KAj9BAsoF,CAAAhH,EAAAgH,CChLO,SAAAziF,GACP,MAAUwC,EAAWxC,KAGrB,OAAAA,ED4K2B0iF,CAAYlH,GAAKC,GAAAx5E,WAAAJ,MJtKrC,WACP,IAKA8gF,EALA/8E,EAAA,EACAwH,EAAA,GAEAvS,GAAA,EAGA,OAGA,SAAAlB,EAAAojF,EAAA/hF,GAEA,MAAAuK,EAAA,GAEA,IAAAq9E,EAEA7jF,EAEAsE,EAEAw/E,EAEA5mF,EAaA,IAVAtC,EAAAyT,EAAAzT,EAAAmpF,SAAA/F,GACA15E,EAAA,EACA+J,EAAA,GACAvS,IAEA,QAAAlB,EAAAgM,WAAA,IACAtC,IAEAxI,OAAAkB,GAEAsH,EAAA1J,EAAAc,QAAA,CAKA,GAJAqhF,GAAAiH,UAAA1/E,EACAu/E,EAAA9G,GAAAkH,KAAArpF,GACAkpF,EAAAD,QAAA7mF,IAAA6mF,EAAApoF,MAAAooF,EAAApoF,MAAAb,EAAAc,OACAwB,EAAAtC,EAAAgM,WAAAk9E,IACAD,EAAA,CACAx1E,EAAAzT,EAAA0B,MAAAgI,GACA,MAEA,QAAApH,GAAAoH,IAAAw/E,GAAAF,EACAp9E,EAAAjK,MAAA,GACAqnF,OAAA5mF,OAUA,OARA4mF,IACAp9E,EAAAjK,MAAA,GACAqnF,OAAA5mF,GAEAsH,EAAAw/E,IACAt9E,EAAAjK,KAAA3B,EAAA0B,MAAAgI,EAAAw/E,IACAj9E,GAAAi9E,EAAAx/E,GAEApH,GACA,OAEAsJ,EAAAjK,KAAA,OACAsK,IACA,MAEA,OAIA,IAFA7G,EAAA,EAAAkkF,KAAAC,KAAAt9E,EAAA,GACAL,EAAAjK,MAAA,GACAsK,IAAA7G,GAAAwG,EAAAjK,MAAA,GACA,MAEA,QAEAiK,EAAAjK,MAAA,GACAsK,EAAA,EACA,MAEA,QAEA+8E,GAAA,EACA/8E,EAAA,EAIAvC,EAAAw/E,EAAA,EAOA,OALA7nF,IACA2nF,GAAAp9E,EAAAjK,MAAA,GACA8R,GAAA7H,EAAAjK,KAAA8R,GACA7H,EAAAjK,KAAA,OAEAiK,GI4EuE49E,GAAUxpF,EAAAojF,GAAA,OA0gCjF,SAAS0D,GAAK2C,GACd,OACAliF,KAAAkiF,EAAAliF,KACA0E,OAAAw9E,EAAAx9E,OACAzE,OAAAiiF,EAAAjiF,QA0BA,SAAAxF,GAAAylF,EAAAzlF,GAEA,IAAAsmF,EACA,IAAAA,KAAAtmF,EACA,GAAQkhF,GAAG/gF,KAAAH,EAAAsmF,GACX,sBAAAA,EAAA,CACA,MAAAjmF,EAAAL,EAAAsmF,GACAjmF,GACAolF,EAAAa,GAAA3mF,QAAAU,QAEO,kBAAAimF,EAAA,CACP,MAAAjmF,EAAAL,EAAAsmF,GACAjmF,GACAolF,EAAAa,GAAA3mF,QAAAU,QAEO,aAAAimF,GAAA,SAAAA,EAAA,CACP,MAAAjmF,EAAAL,EAAAsmF,GACAjmF,GACAoE,OAAAC,OAAA+gF,EAAAa,GAAAjmF,IAQA,SAAA2lF,GAAA9lF,EAAAG,GACA,MAAAH,EACA,IAAAwmF,MAAA,iBAAAxmF,EAAA7B,KAAA,MAA2DwiF,GAAiB,CAC5E3hF,MAAAgB,EAAAhB,MACAG,IAAAa,EAAAb,MACK,0BAAAgB,EAAAhC,KAAA,MAAqDwiF,GAAiB,CAC3E3hF,MAAAmB,EAAAnB,MACAG,IAAAgB,EAAAhB,MACK,aAEL,IAAAqnF,MAAA,oCAAArmF,EAAAhC,KAAA,MAA+EwiF,GAAiB,CAChG3hF,MAAAmB,EAAAnB,MACAG,IAAAgB,EAAAhB,MACK,gCEjwCL,SAAAqoF,GAAAC,GACA,MAAAC,EANA,SAAAD,GACA,MAAAE,EAAAF,EAAA93E,QAAA,UAA0D,MAE1D,OAD6BpL,OAAAqjF,GAAA,EAAArjF,CAAMojF,GAInCE,CAAAJ,IACAnpF,SACAA,GACM2iF,GAAYyG,GAClBI,EAAA,KACA,IAAAC,EAAA,EAgCA,OAPAzpF,EAAA0pF,QAAAC,IACA,cAAAA,EAAA9pF,MACA8pF,EAAA3pF,SAAA0pF,QAAAE,KA1BA,SAAAC,EAAA/D,GACA,IAAAgE,EAAAC,UAAAzpF,OAAA,QAAAsB,IAAAmoF,UAAA,GAAAA,UAAA,YACA,SAAAjE,EAAAjmF,KACAimF,EAAAtmF,MAAAwqF,MAAA,MACAN,QAAA,CAAAO,EAAA5pF,KACA,IAAAA,IACAopF,IACAD,EAAAroF,KAAA,KAEA8oF,EAAAD,MAAA,KAAAN,QAAAQ,IACAA,GACAV,EAAAC,GAAAtoF,KAAA,CACAuR,QAAAw3E,EACArqF,KAAAiqF,QAKK,WAAAhE,EAAAjmF,MAAA,aAAAimF,EAAAjmF,MACLimF,EAAA9lF,SAAA0pF,QAAAE,IACAC,EAAAD,EAAA9D,EAAAjmF,QAOAgqF,CAAAD,OAIAJ,EA0BA,SAAAW,GAAAC,EAAAF,GANA,IAAAn/E,EAQA,OAEA,SAAAs/E,EAAAD,EAAAE,EAAAC,EAAA1qF,GACA,OAAA0qF,EAAAjqF,OACA,QACAoS,QAAA43E,EAAA/pF,KAAA,IACAV,QACK,CACL6S,QAAA,GACA7S,SAGA,MAAA2qF,KAAAC,GAAAF,EACA,MAAAG,EAAA,IAAAJ,EAAAE,GACA,GAAAJ,EAAA,EACA13E,QAAAg4E,EAAAnqF,KAAA,IACAV,UAEA,OAAAwqF,EAAAD,EAAAM,EAAAD,EAAA5qF,GAEA,IAAAyqF,EAAAhqF,QAAAkqF,IACAF,EAAAnpF,KAAAqpF,GACAD,EAAAh9E,SAEA,QACAmF,QAAA43E,EAAA/pF,KAAA,IACAV,QACG,CACH6S,QAAA63E,EAAAhqF,KAAA,IACAV,SA7BAwqF,CAAAD,EAAA,IARAr/E,EAOAm/E,EAAAx3E,QANAi4E,KAAAC,UACA,SAAAD,KAAAC,WAAAC,QAAA9/E,IAAAkD,IAAA68E,KAAAD,SAEA,IAAA9/E,IAIAm/E,EAAArqF,MAgCA,SAAAkrF,GAAAhkF,EAAAqjF,GACA,GAAArjF,EAAAikF,KAAAC,IACA,IAAAv4E,QACAA,GACKu4E,EACL,OAAAv4E,EAAAzK,SAAA,QAEA,UAAAigF,MAAA,6DAEA,OAEA,SAAAgD,EAAAC,EAAAf,GACA,IAAAgB,EACA,IAAA5B,EAAAO,UAAAzpF,OAAA,QAAAsB,IAAAmoF,UAAA,GAAAA,UAAA,MACA,IAAAsB,EAAAtB,UAAAzpF,OAAA,QAAAsB,IAAAmoF,UAAA,GAAAA,UAAA,MACA,OAAAoB,EAAA7qF,OAIA,OAHA+qF,EAAA/qF,OAAA,GACAkpF,EAAAroF,KAAAkqF,GAEA7B,EAAAlpF,OAAA,EAAAkpF,EAAA,GAEA,IAAA8B,EAAA,GACA,MAAAH,EAAA,GAAAz4E,UACA44E,EAAA,IACAH,EAAA59E,SAEA,MAAAg+E,EAAA,QAAAH,EAAAD,EAAA59E,eAAA,IAAA69E,IAAA,CACA14E,QAAA,IACA7S,KAAA,UAEA,MAAA2rF,EAAA,IAAAH,GACA,KAAAC,GACAE,EAAArqF,KAAA,CACAuR,QAAA44E,EACAzrF,KAAA,WAGA2rF,EAAArqF,KAAAoqF,GACA,GAAAnB,EAAAoB,GACA,OAAAN,EAAAC,EAAAf,EAAAZ,EAAAgC,GAEA,GAAAH,EAAA/qF,OAAA,EACAkpF,EAAAroF,KAAAkqF,GACAF,EAAAlqF,QAAAsqF,QACG,GAAAA,EAAA74E,QAAA,CACH,MAAA3L,EAAA0jF,GAAAN,GAAAC,EAAAmB,GACA/B,EAAAroF,KAAA,CAAA4F,IACA0jF,EAAA/3E,SACAy4E,EAAAlqF,QAAAwpF,GAGA,OAAAS,EAAAC,EAAAf,EAAAZ,GA1CA0B,CAAAnkF,EAAAqjF,GA2EA,SAAAqB,GAAAC,EAAAljF,EAAAmjF,GACA,OAAAD,EAAAE,OAAA,SAAAC,KAAA,4BAAAA,KAAA,OAAAA,KAAA,IAAArjF,EAAAmjF,EAAA,SAAAE,KAAA,KAAAF,EAAA,MAEA,SAAAG,GAAAC,EAAAJ,EAAA5kF,GACA,MAAAilF,EAAAD,EAAAH,OAAA,QACAK,EAAAR,GAAAO,EAAA,EAAAL,GACAO,GAAAD,EAAAllF,GACA,MAAAolF,EAAAF,EAAAnG,OAAAsG,wBAEA,OADAJ,EAAArrF,SACAwrF,EAEA,SAAAE,GAAAN,EAAAJ,EAAA5gF,GACA,IAAAuhF,EACA,MAAAN,EAAAD,EAAAH,OAAA,QACAK,EAAAR,GAAAO,EAAA,EAAAL,GACAO,GAAAD,EAAA,EACAv5E,QAAA3H,EACAlL,KAAA,YAEA,MAAA0sF,EAAA,OAAAD,EAAAL,EAAAnG,aAAA,EAAAwG,EAAAE,wBAIA,OAHAD,GACAP,EAAArrF,SAEA4rF,EA2BA,SAAAL,GAAAO,EAAAC,GACAD,EAAA1hF,KAAA,IACA2hF,EAAAhD,QAAA,CAAAQ,EAAA7pF,KACA,MAAAssF,EAAAF,EAAAb,OAAA,SAAAC,KAAA,0BAAA3B,EAAArqF,KAAA,mBAAAgsF,KAAA,4BAAAA,KAAA,yBAAA3B,EAAArqF,KAAA,iBACA,IAAAQ,EACAssF,EAAA5hF,KAAAm/E,EAAAx3E,SAEAi6E,EAAA5hF,KAAA,IAAAm/E,EAAAx3E,WAvPAk6E,EAAA3D,EAAA4D,EAAA,sBAAAC,KAAAF,EAAA3D,EAAA4D,EAAA,sBAAAR,KA2PA,MAAAS,GAAA,SAAAz7C,GACA,IAAAtmC,EAAAg/E,UAAAzpF,OAAA,QAAAsB,IAAAmoF,UAAA,GAAAA,UAAA,OACAgD,MACAA,EAAA,GAAAC,QACAA,GAAA,EAAAC,QACAA,EAAA,GAAAC,cACAA,GAAA,EAAAC,OACAA,GAAA,EAAAC,MACAA,EAAA,IAAAC,iBACAA,GAAA,GACGtD,UAAAzpF,OAAA,QAAAsB,IAAAmoF,UAAA,GAAAA,UAAA,MAEH,GADEuD,EAAA,EAAGhhF,KAAA,aAAAvB,EAAAgiF,EAAAC,EAAAC,EAAAC,EAAAC,EAAAE,GACLH,EAAA,CACA,MAAAzI,EAxNA,SAAA0E,GACA,MAAAnpF,SACAA,GACM2iF,GAAYwG,GAalB,OAAAnpF,EAAAiO,IAZA,SAAAs/E,EAAAzH,GACA,eAAAA,EAAAjmF,KACAimF,EAAAtmF,MAAA6R,QAAA,eACK,WAAAy0E,EAAAjmF,KACL,WAAA2tF,OAAA1H,EAAA9lF,SAAAiO,IAAAs/E,GAAAhtF,KAAA,iBACK,aAAAulF,EAAAjmF,KACL,OAAA2tF,OAAA1H,EAAA9lF,SAAAiO,IAAAs/E,GAAAhtF,KAAA,aACK,cAAAulF,EAAAjmF,KACL,MAAA2tF,OAAA1H,EAAA9lF,SAAAiO,IAAAs/E,GAAAhtF,KAAA,YAEA,yBAAAitF,OAAA1H,EAAAjmF,QAEAU,KAAA,IAwMAktF,CAAA1iF,GAOA,OA3GA,SAAA2iF,EAAA5H,EAAAsH,EAAAH,GACA,IAAAU,EAAA5D,UAAAzpF,OAAA,QAAAsB,IAAAmoF,UAAA,IAAAA,UAAA,GACA,MAAA6D,EAAAF,EAAA9B,OAAA,iBACA39C,EAAA2/C,EAAAhC,OAAA,aACA7P,EAAA+J,EAAA/J,MACA8R,EAAA/H,EAAAqH,OAAA,wBAVA,IAAAW,EAAAC,EAWA9/C,EAAAs2C,KAAA,sBAAAiJ,OAAAK,EAAA,KAAAL,OAAAP,EAAA,OAAAnH,EAAAkI,WAAA,UAAAlI,EAAAkI,WAAA,YAAAjS,EAAA,WAXA+R,EAYA7/C,GAZA8/C,EAYAjI,EAAAkI,aAVAF,EAAAjC,KAAA,QAAAkC,GAWA9/C,EAAA8+C,MAAA,wBACA9+C,EAAA8+C,MAAA,wBACA9+C,EAAA8+C,MAAA,YAAAK,EAAA,MACAn/C,EAAA49C,KAAA,wCACA8B,GACA1/C,EAAA49C,KAAA,oBAEA,IAAAoC,EAAAhgD,EAAA63C,OAAA0G,wBASA,OARAyB,EAAAb,YACAn/C,EAAA8+C,MAAA,mBACA9+C,EAAA8+C,MAAA,8BACA9+C,EAAA8+C,MAAA,QAAAK,EAAA,MACAa,EAAAhgD,EAAA63C,OAAA0G,yBAEAoB,EAAAb,MAAA,QAAAkB,EAAAb,OACAQ,EAAAb,MAAA,SAAAkB,EAAAC,QACAN,EAAA9H,OAkFAqI,CAAA98C,EALA,CACA87C,SACApR,MAAa91E,OAAAqnF,EAAA,EAAArnF,CAAcw+E,GAAApzE,QAAA,uBAAAy5E,GAAA,aAAA0C,OAAA1C,EAAAz5E,QAAA,oBAC3B28E,WAAAjB,EAAA17E,QAAA,mBAEA+7E,EAAAH,EAAAI,GAKA,OA5DA,SAAAD,EAAAgB,EAAAC,GACA,IAAAV,EAAA5D,UAAAzpF,OAAA,QAAAsB,IAAAmoF,UAAA,IAAAA,UAAA,GACA,MACAuE,EAAAF,EAAAxC,OAAA,KACA2C,EAAAD,EAAAE,OAAA,QAAA3C,KAAA,sBACAH,EAAA4C,EAAA1C,OAAA,QAAAC,KAAA,aACA,IAAArjF,EAAA,EACA,UAAAzB,KAAAsnF,EAAA,CACA,MAAAI,EAAAC,GAAA5C,GAAAwC,EANA,IAMAI,IAAAtB,EACAuB,EAAAF,EAAA1nF,GAAA,CAAAA,GAAAgkF,GAAAhkF,EAAA0nF,GACA,UAAAG,KAAAD,EAEAzC,GADAT,GAAAC,EAAAljF,EATA,KAUAomF,GACApmF,IAGA,GAAAmlF,EAAA,CACA,MAAAM,EAAAvC,EAAA5F,OAAA+I,UACAC,EAAA,EAEA,OADAP,EAAA1C,KAAA,KAAAiD,GAAAjD,KAAA,KAAAiD,GAAAjD,KAAA,QAAAoC,EAAAb,MAAA,EAAA0B,GAAAjD,KAAA,SAAAoC,EAAAC,OAAA,EAAAY,GACAR,EAAAxI,OAEA,OAAA4F,EAAA5F,OAqCAiJ,CAAA3B,EAAA/7C,EADA63C,GAAAn+E,GACAsiF","file":"static/js/1.2d065135.chunk.js","sourcesContent":["/**\n * @typedef {import('mdast').Root|import('mdast').Content} Node\n *\n * @typedef Options\n *   Configuration (optional).\n * @property {boolean | null | undefined} [includeImageAlt=true]\n *   Whether to use `alt` for `image`s.\n * @property {boolean | null | undefined} [includeHtml=true]\n *   Whether to use `value` of HTML.\n */\n\n/** @type {Options} */\nconst emptyOptions = {};\n\n/**\n * Get the text content of a node or list of nodes.\n *\n * Prefers the nodes plain-text fields, otherwise serializes its children,\n * and if the given value is an array, serialize the nodes in it.\n *\n * @param {unknown} value\n *   Thing to serialize, typically `Node`.\n * @param {Options | null | undefined} [options]\n *   Configuration (optional).\n * @returns {string}\n *   Serialized `value`.\n */\nexport function toString(value, options) {\n  const settings = options || emptyOptions;\n  const includeImageAlt = typeof settings.includeImageAlt === 'boolean' ? settings.includeImageAlt : true;\n  const includeHtml = typeof settings.includeHtml === 'boolean' ? settings.includeHtml : true;\n  return one(value, includeImageAlt, includeHtml);\n}\n\n/**\n * One node or several nodes.\n *\n * @param {unknown} value\n *   Thing to serialize.\n * @param {boolean} includeImageAlt\n *   Include image `alt`s.\n * @param {boolean} includeHtml\n *   Include HTML.\n * @returns {string}\n *   Serialized node.\n */\nfunction one(value, includeImageAlt, includeHtml) {\n  if (node(value)) {\n    if ('value' in value) {\n      return value.type === 'html' && !includeHtml ? '' : value.value;\n    }\n    if (includeImageAlt && 'alt' in value && value.alt) {\n      return value.alt;\n    }\n    if ('children' in value) {\n      return all(value.children, includeImageAlt, includeHtml);\n    }\n  }\n  if (Array.isArray(value)) {\n    return all(value, includeImageAlt, includeHtml);\n  }\n  return '';\n}\n\n/**\n * Serialize a list of nodes.\n *\n * @param {Array<unknown>} values\n *   Thing to serialize.\n * @param {boolean} includeImageAlt\n *   Include image `alt`s.\n * @param {boolean} includeHtml\n *   Include HTML.\n * @returns {string}\n *   Serialized nodes.\n */\nfunction all(values, includeImageAlt, includeHtml) {\n  /** @type {Array<string>} */\n  const result = [];\n  let index = -1;\n  while (++index < values.length) {\n    result[index] = one(values[index], includeImageAlt, includeHtml);\n  }\n  return result.join('');\n}\n\n/**\n * Check if `value` looks like a node.\n *\n * @param {unknown} value\n *   Thing.\n * @returns {value is Node}\n *   Whether `value` is a node.\n */\nfunction node(value) {\n  return Boolean(value && typeof value === 'object');\n}","/**\n * Like `Array#splice`, but smarter for giant arrays.\n *\n * `Array#splice` takes all items to be inserted as individual argument which\n * causes a stack overflow in V8 when trying to insert 100k items for instance.\n *\n * Otherwise, this does not return the removed items, and takes `items` as an\n * array instead of rest parameters.\n *\n * @template {unknown} T\n *   Item type.\n * @param {Array<T>} list\n *   List to operate on.\n * @param {number} start\n *   Index to remove/insert at (can be negative).\n * @param {number} remove\n *   Number of items to remove.\n * @param {Array<T>} items\n *   Items to inject into `list`.\n * @returns {void}\n *   Nothing.\n */\nexport function splice(list, start, remove, items) {\n  const end = list.length;\n  let chunkStart = 0;\n  /** @type {Array<unknown>} */\n  let parameters;\n\n  // Make start between zero and `end` (included).\n  if (start < 0) {\n    start = -start > end ? 0 : end + start;\n  } else {\n    start = start > end ? end : start;\n  }\n  remove = remove > 0 ? remove : 0;\n\n  // No need to chunk the items if theres only a couple (10k) items.\n  if (items.length < 10000) {\n    parameters = Array.from(items);\n    parameters.unshift(start, remove);\n    // @ts-expect-error Hush, its fine.\n    list.splice(...parameters);\n  } else {\n    // Delete `remove` items starting from `start`\n    if (remove) list.splice(start, remove);\n\n    // Insert the items in chunks to not cause stack overflows.\n    while (chunkStart < items.length) {\n      parameters = items.slice(chunkStart, chunkStart + 10000);\n      parameters.unshift(start, 0);\n      // @ts-expect-error Hush, its fine.\n      list.splice(...parameters);\n      chunkStart += 10000;\n      start += 10000;\n    }\n  }\n}\n\n/**\n * Append `items` (an array) at the end of `list` (another array).\n * When `list` was empty, returns `items` instead.\n *\n * This prevents a potentially expensive operation when `list` is empty,\n * and adds items in batches to prevent V8 from hanging.\n *\n * @template {unknown} T\n *   Item type.\n * @param {Array<T>} list\n *   List to operate on.\n * @param {Array<T>} items\n *   Items to add to `list`.\n * @returns {Array<T>}\n *   Either `list` or `items`.\n */\nexport function push(list, items) {\n  if (list.length > 0) {\n    splice(list, list.length, 0, items);\n    return list;\n  }\n  return items;\n}","/**\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').Handles} Handles\n * @typedef {import('micromark-util-types').HtmlExtension} HtmlExtension\n * @typedef {import('micromark-util-types').NormalizedExtension} NormalizedExtension\n */\n\nimport { splice } from 'micromark-util-chunked';\nconst hasOwnProperty = {}.hasOwnProperty;\n\n/**\n * Combine multiple syntax extensions into one.\n *\n * @param {Array<Extension>} extensions\n *   List of syntax extensions.\n * @returns {NormalizedExtension}\n *   A single combined extension.\n */\nexport function combineExtensions(extensions) {\n  /** @type {NormalizedExtension} */\n  const all = {};\n  let index = -1;\n  while (++index < extensions.length) {\n    syntaxExtension(all, extensions[index]);\n  }\n  return all;\n}\n\n/**\n * Merge `extension` into `all`.\n *\n * @param {NormalizedExtension} all\n *   Extension to merge into.\n * @param {Extension} extension\n *   Extension to merge.\n * @returns {void}\n */\nfunction syntaxExtension(all, extension) {\n  /** @type {keyof Extension} */\n  let hook;\n  for (hook in extension) {\n    const maybe = hasOwnProperty.call(all, hook) ? all[hook] : undefined;\n    /** @type {Record<string, unknown>} */\n    const left = maybe || (all[hook] = {});\n    /** @type {Record<string, unknown> | undefined} */\n    const right = extension[hook];\n    /** @type {string} */\n    let code;\n    if (right) {\n      for (code in right) {\n        if (!hasOwnProperty.call(left, code)) left[code] = [];\n        const value = right[code];\n        constructs(\n        // @ts-expect-error Looks like a list.\n        left[code], Array.isArray(value) ? value : value ? [value] : []);\n      }\n    }\n  }\n}\n\n/**\n * Merge `list` into `existing` (both lists of constructs).\n * Mutates `existing`.\n *\n * @param {Array<unknown>} existing\n * @param {Array<unknown>} list\n * @returns {void}\n */\nfunction constructs(existing, list) {\n  let index = -1;\n  /** @type {Array<unknown>} */\n  const before = [];\n  while (++index < list.length) {\n    // @ts-expect-error Looks like an object.\n    ;\n    (list[index].add === 'after' ? existing : before).push(list[index]);\n  }\n  splice(existing, 0, 0, before);\n}\n\n/**\n * Combine multiple HTML extensions into one.\n *\n * @param {Array<HtmlExtension>} htmlExtensions\n *   List of HTML extensions.\n * @returns {HtmlExtension}\n *   A single combined HTML extension.\n */\nexport function combineHtmlExtensions(htmlExtensions) {\n  /** @type {HtmlExtension} */\n  const handlers = {};\n  let index = -1;\n  while (++index < htmlExtensions.length) {\n    htmlExtension(handlers, htmlExtensions[index]);\n  }\n  return handlers;\n}\n\n/**\n * Merge `extension` into `all`.\n *\n * @param {HtmlExtension} all\n *   Extension to merge into.\n * @param {HtmlExtension} extension\n *   Extension to merge.\n * @returns {void}\n */\nfunction htmlExtension(all, extension) {\n  /** @type {keyof HtmlExtension} */\n  let hook;\n  for (hook in extension) {\n    const maybe = hasOwnProperty.call(all, hook) ? all[hook] : undefined;\n    const left = maybe || (all[hook] = {});\n    const right = extension[hook];\n    /** @type {keyof Handles} */\n    let type;\n    if (right) {\n      for (type in right) {\n        // @ts-expect-error assume document vs regular handler are managed correctly.\n        left[type] = right[type];\n      }\n    }\n  }\n}","// This module is generated by `script/`.\n//\n// CommonMark handles attention (emphasis, strong) markers based on what comes\n// before or after them.\n// One such difference is if those characters are Unicode punctuation.\n// This script is generated from the Unicode data.\n\n/**\n * Regular expression that matches a unicode punctuation character.\n */\nexport const unicodePunctuationRegex = /[!-\\/:-@\\[-`\\{-~\\xA1\\xA7\\xAB\\xB6\\xB7\\xBB\\xBF\\u037E\\u0387\\u055A-\\u055F\\u0589\\u058A\\u05BE\\u05C0\\u05C3\\u05C6\\u05F3\\u05F4\\u0609\\u060A\\u060C\\u060D\\u061B\\u061D-\\u061F\\u066A-\\u066D\\u06D4\\u0700-\\u070D\\u07F7-\\u07F9\\u0830-\\u083E\\u085E\\u0964\\u0965\\u0970\\u09FD\\u0A76\\u0AF0\\u0C77\\u0C84\\u0DF4\\u0E4F\\u0E5A\\u0E5B\\u0F04-\\u0F12\\u0F14\\u0F3A-\\u0F3D\\u0F85\\u0FD0-\\u0FD4\\u0FD9\\u0FDA\\u104A-\\u104F\\u10FB\\u1360-\\u1368\\u1400\\u166E\\u169B\\u169C\\u16EB-\\u16ED\\u1735\\u1736\\u17D4-\\u17D6\\u17D8-\\u17DA\\u1800-\\u180A\\u1944\\u1945\\u1A1E\\u1A1F\\u1AA0-\\u1AA6\\u1AA8-\\u1AAD\\u1B5A-\\u1B60\\u1B7D\\u1B7E\\u1BFC-\\u1BFF\\u1C3B-\\u1C3F\\u1C7E\\u1C7F\\u1CC0-\\u1CC7\\u1CD3\\u2010-\\u2027\\u2030-\\u2043\\u2045-\\u2051\\u2053-\\u205E\\u207D\\u207E\\u208D\\u208E\\u2308-\\u230B\\u2329\\u232A\\u2768-\\u2775\\u27C5\\u27C6\\u27E6-\\u27EF\\u2983-\\u2998\\u29D8-\\u29DB\\u29FC\\u29FD\\u2CF9-\\u2CFC\\u2CFE\\u2CFF\\u2D70\\u2E00-\\u2E2E\\u2E30-\\u2E4F\\u2E52-\\u2E5D\\u3001-\\u3003\\u3008-\\u3011\\u3014-\\u301F\\u3030\\u303D\\u30A0\\u30FB\\uA4FE\\uA4FF\\uA60D-\\uA60F\\uA673\\uA67E\\uA6F2-\\uA6F7\\uA874-\\uA877\\uA8CE\\uA8CF\\uA8F8-\\uA8FA\\uA8FC\\uA92E\\uA92F\\uA95F\\uA9C1-\\uA9CD\\uA9DE\\uA9DF\\uAA5C-\\uAA5F\\uAADE\\uAADF\\uAAF0\\uAAF1\\uABEB\\uFD3E\\uFD3F\\uFE10-\\uFE19\\uFE30-\\uFE52\\uFE54-\\uFE61\\uFE63\\uFE68\\uFE6A\\uFE6B\\uFF01-\\uFF03\\uFF05-\\uFF0A\\uFF0C-\\uFF0F\\uFF1A\\uFF1B\\uFF1F\\uFF20\\uFF3B-\\uFF3D\\uFF3F\\uFF5B\\uFF5D\\uFF5F-\\uFF65]/;","/**\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport { unicodePunctuationRegex } from './lib/unicode-punctuation-regex.js';\n\n/**\n * Check whether the character code represents an ASCII alpha (`a` through `z`,\n * case insensitive).\n *\n * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.\n *\n * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)\n * to U+005A (`Z`).\n *\n * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)\n * to U+007A (`z`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlpha = regexCheck(/[A-Za-z]/);\n\n/**\n * Check whether the character code represents an ASCII alphanumeric (`a`\n * through `z`, case insensitive, or `0` through `9`).\n *\n * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha\n * (see `asciiAlpha`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlphanumeric = regexCheck(/[\\dA-Za-z]/);\n\n/**\n * Check whether the character code represents an ASCII atext.\n *\n * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in\n * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),\n * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F\n * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E\n * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE\n * (`{`) to U+007E TILDE (`~`).\n *\n * See:\n * **\\[RFC5322]**:\n * [Internet Message Format](https://tools.ietf.org/html/rfc5322).\n * P. Resnick.\n * IETF.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAtext = regexCheck(/[#-'*+\\--9=?A-Z^-~]/);\n\n/**\n * Check whether a character code is an ASCII control character.\n *\n * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)\n * to U+001F (US), or U+007F (DEL).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function asciiControl(code) {\n  return (\n    // Special whitespace codes (which have negative values), C0 and Control\n    // character DEL\n    code !== null && (code < 32 || code === 127)\n  );\n}\n\n/**\n * Check whether the character code represents an ASCII digit (`0` through `9`).\n *\n * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to\n * U+0039 (`9`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiDigit = regexCheck(/\\d/);\n\n/**\n * Check whether the character code represents an ASCII hex digit (`a` through\n * `f`, case insensitive, or `0` through `9`).\n *\n * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex\n * digit, or an ASCII lower hex digit.\n *\n * An **ASCII upper hex digit** is a character in the inclusive range U+0041\n * (`A`) to U+0046 (`F`).\n *\n * An **ASCII lower hex digit** is a character in the inclusive range U+0061\n * (`a`) to U+0066 (`f`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiHexDigit = regexCheck(/[\\dA-Fa-f]/);\n\n/**\n * Check whether the character code represents ASCII punctuation.\n *\n * An **ASCII punctuation** is a character in the inclusive ranges U+0021\n * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT\n * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT\n * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/);\n\n/**\n * Check whether a character code is a markdown line ending.\n *\n * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN\n * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).\n *\n * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE\n * RETURN (CR) are replaced by these virtual characters depending on whether\n * they occurred together.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEnding(code) {\n  return code !== null && code < -2;\n}\n\n/**\n * Check whether a character code is a markdown line ending (see\n * `markdownLineEnding`) or markdown space (see `markdownSpace`).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEndingOrSpace(code) {\n  return code !== null && (code < 0 || code === 32);\n}\n\n/**\n * Check whether a character code is a markdown space.\n *\n * A **markdown space** is the concrete character U+0020 SPACE (SP) and the\n * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).\n *\n * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is\n * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL\n * SPACE (VS) characters, depending on the column at which the tab occurred.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownSpace(code) {\n  return code === -2 || code === -1 || code === 32;\n}\n\n// Size note: removing ASCII from the regex and using `asciiPunctuation` here\n// In fact adds to the bundle size.\n/**\n * Check whether the character code represents Unicode punctuation.\n *\n * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,\n * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`\n * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`\n * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII\n * punctuation (see `asciiPunctuation`).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodePunctuation = regexCheck(unicodePunctuationRegex);\n\n/**\n * Check whether the character code represents Unicode whitespace.\n *\n * Note that this does handle micromark specific markdown whitespace characters.\n * See `markdownLineEndingOrSpace` to check that.\n *\n * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,\n * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),\n * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\\[UNICODE]**).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodeWhitespace = regexCheck(/\\s/);\n\n/**\n * Create a code check from a regex.\n *\n * @param {RegExp} regex\n * @returns {(code: Code) => boolean}\n */\nfunction regexCheck(regex) {\n  return check;\n\n  /**\n   * Check whether a code matches the bound regex.\n   *\n   * @param {Code} code\n   *   Character code.\n   * @returns {boolean}\n   *   Whether the character code matches the bound regex.\n   */\n  function check(code) {\n    return code !== null && regex.test(String.fromCharCode(code));\n  }\n}","/**\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenType} TokenType\n */\n\nimport { markdownSpace } from 'micromark-util-character';\n\n// To do: implement `spaceOrTab`, `spaceOrTabMinMax`, `spaceOrTabWithOptions`.\n\n/**\n * Parse spaces and tabs.\n *\n * There is no `nok` parameter:\n *\n * *   spaces in markdown are often optional, in which case this factory can be\n *     used and `ok` will be switched to whether spaces were found or not\n * *   one line ending or space can be detected with `markdownSpace(code)` right\n *     before using `factorySpace`\n *\n * ###### Examples\n *\n * Where `` represents a tab (plus how much it expands) and `` represents a\n * single space.\n *\n * ```markdown\n * \n * \n * \n * ```\n *\n * @param {Effects} effects\n *   Context.\n * @param {State} ok\n *   State switched to when successful.\n * @param {TokenType} type\n *   Type (`' \\t'`).\n * @param {number | undefined} [max=Infinity]\n *   Max (exclusive).\n * @returns\n *   Start state.\n */\nexport function factorySpace(effects, ok, type, max) {\n  const limit = max ? max - 1 : Number.POSITIVE_INFINITY;\n  let size = 0;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    if (markdownSpace(code)) {\n      effects.enter(type);\n      return prefix(code);\n    }\n    return ok(code);\n  }\n\n  /** @type {State} */\n  function prefix(code) {\n    if (markdownSpace(code) && size++ < limit) {\n      effects.consume(code);\n      return prefix;\n    }\n    effects.exit(type);\n    return ok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);\n  /** @type {Token} */\n  let previous;\n  return contentStart;\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return factorySpace(effects, contentStart, 'linePrefix');\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter('paragraph');\n    return lineStart(code);\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous\n    });\n    if (previous) {\n      previous.next = token;\n    }\n    previous = token;\n    return data(code);\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText');\n      effects.exit('paragraph');\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      effects.exit('chunkText');\n      return lineStart;\n    }\n\n    // Data.\n    effects.consume(code);\n    return data;\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n};\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeDocument(effects) {\n  const self = this;\n  /** @type {Array<StackItem>} */\n  const stack = [];\n  let continued = 0;\n  /** @type {TokenizeContext | undefined} */\n  let childFlow;\n  /** @type {Token | undefined} */\n  let childToken;\n  /** @type {number} */\n  let lineStartOffset;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued];\n      self.containerState = item[1];\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\n    }\n\n    // Done.\n    return checkNewContainers(code);\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++;\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but its already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined;\n      if (childFlow) {\n        closeFlow();\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === 'chunkFlow') {\n          point = self.events[indexBeforeFlow][1].end;\n          break;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      let index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point);\n        index++;\n      }\n\n      // Inject the exits earlier (theyre still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n      return checkNewContainers(code);\n    }\n    return start(code);\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether theres a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code);\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we cant have containers pierce into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code);\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but wed be interrupting it w/ a new container if theres a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\n    }\n\n    // Check if there is a new container.\n    self.containerState = {};\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow();\n    exitContainers(continued);\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length;\n    lineStartOffset = self.now().offset;\n    return flowStart(code);\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {};\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++;\n    stack.push([self.currentConstruct, self.containerState]);\n    // Try another.\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow();\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    childFlow = childFlow || self.parser.flow(self.now());\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    });\n    return flowContinue(code);\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true);\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      writeToChild(effects.exit('chunkFlow'));\n      // Get ready for the next line.\n      continued = 0;\n      self.interrupt = undefined;\n      return start;\n    }\n    effects.consume(code);\n    return flowContinue;\n  }\n\n  /**\n   * @param {Token} token\n   * @param {boolean | undefined} [eof]\n   * @returns {void}\n   */\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token);\n    if (eof) stream.push(null);\n    token.previous = childToken;\n    if (childToken) childToken.next = token;\n    childToken = token;\n    childFlow.defineSkip(token.start);\n    childFlow.write(stream);\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line cant unmake it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which unmakes the first line\n    // and turns the whole into one content block.\n    //\n    // Weve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length;\n      while (index--) {\n        if (\n        // The token starts before the line ending\n        childFlow.events[index][1].start.offset < lineStartOffset && (\n        // and either is not ended yet\n        !childFlow.events[index][1].end ||\n        // or ends after it.\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\n          // Exit: theres still something open, which means its a lazy line\n          // part of something.\n          return;\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {boolean | undefined} */\n      let seen;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === 'chunkFlow') {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end;\n            break;\n          }\n          seen = true;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point);\n        index++;\n      }\n\n      // Inject the exits earlier (theyre still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n    }\n  }\n\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n  function exitContainers(size) {\n    let index = stack.length;\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index];\n      self.containerState = entry[1];\n      entry[0].exit.call(self, effects);\n    }\n    stack.length = size;\n  }\n  function closeFlow() {\n    childFlow.write([null]);\n    childToken = undefined;\n    childFlow = undefined;\n    self.containerState._closeFlow = undefined;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), 'linePrefix', this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const blankLine = {\n  tokenize: tokenizeBlankLine,\n  partial: true\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlankLine(effects, ok, nok) {\n  return start;\n\n  /**\n   * Start of blank line.\n   *\n   * >  **Note**: `` represents a space character.\n   *\n   * ```markdown\n   * > | \n   *     ^\n   * > | \n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    return markdownSpace(code) ? factorySpace(effects, after, 'linePrefix')(code) : after(code);\n  }\n\n  /**\n   * At eof/eol, after optional whitespace.\n   *\n   * >  **Note**: `` represents a space character.\n   *\n   * ```markdown\n   * > | \n   *       ^\n   * > | \n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Token} Token\n */\n\nimport { splice } from 'micromark-util-chunked';\n/**\n * Tokenize subcontent.\n *\n * @param {Array<Event>} events\n *   List of events.\n * @returns {boolean}\n *   Whether subtokens were found.\n */\nexport function subtokenize(events) {\n  /** @type {Record<string, number>} */\n  const jumps = {};\n  let index = -1;\n  /** @type {Event} */\n  let event;\n  /** @type {number | undefined} */\n  let lineIndex;\n  /** @type {number} */\n  let otherIndex;\n  /** @type {Event} */\n  let otherEvent;\n  /** @type {Array<Event>} */\n  let parameters;\n  /** @type {Array<Event>} */\n  let subevents;\n  /** @type {boolean | undefined} */\n  let more;\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index];\n    }\n    event = events[index];\n\n    // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n    if (index && event[1].type === 'chunkFlow' && events[index - 1][1].type === 'listItemPrefix') {\n      subevents = event[1]._tokenizer.events;\n      otherIndex = 0;\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === 'lineEndingBlank') {\n        otherIndex += 2;\n      }\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === 'content') {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === 'content') {\n            break;\n          }\n          if (subevents[otherIndex][1].type === 'chunkText') {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true;\n            otherIndex++;\n          }\n        }\n      }\n    }\n\n    // Enter.\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index));\n        index = jumps[index];\n        more = true;\n      }\n    }\n    // Exit.\n    else if (event[1]._container) {\n      otherIndex = index;\n      lineIndex = undefined;\n      while (otherIndex--) {\n        otherEvent = events[otherIndex];\n        if (otherEvent[1].type === 'lineEnding' || otherEvent[1].type === 'lineEndingBlank') {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events[lineIndex][1].type = 'lineEndingBlank';\n            }\n            otherEvent[1].type = 'lineEnding';\n            lineIndex = otherIndex;\n          }\n        } else {\n          break;\n        }\n      }\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = Object.assign({}, events[lineIndex][1].start);\n\n        // Switch container exit w/ line endings.\n        parameters = events.slice(lineIndex, index);\n        parameters.unshift(event);\n        splice(events, lineIndex, index - lineIndex + 1, parameters);\n      }\n    }\n  }\n  return !more;\n}\n\n/**\n * Tokenize embedded tokens.\n *\n * @param {Array<Event>} events\n * @param {number} eventIndex\n * @returns {Record<string, number>}\n */\nfunction subcontent(events, eventIndex) {\n  const token = events[eventIndex][1];\n  const context = events[eventIndex][2];\n  let startPosition = eventIndex - 1;\n  /** @type {Array<number>} */\n  const startPositions = [];\n  const tokenizer = token._tokenizer || context.parser[token.contentType](token.start);\n  const childEvents = tokenizer.events;\n  /** @type {Array<[number, number]>} */\n  const jumps = [];\n  /** @type {Record<string, number>} */\n  const gaps = {};\n  /** @type {Array<Chunk>} */\n  let stream;\n  /** @type {Token | undefined} */\n  let previous;\n  let index = -1;\n  /** @type {Token | undefined} */\n  let current = token;\n  let adjust = 0;\n  let start = 0;\n  const breaks = [start];\n\n  // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n  while (current) {\n    // Find the position of the event for this token.\n    while (events[++startPosition][1] !== current) {\n      // Empty.\n    }\n    startPositions.push(startPosition);\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current);\n      if (!current.next) {\n        stream.push(null);\n      }\n      if (previous) {\n        tokenizer.defineSkip(current.start);\n      }\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true;\n      }\n      tokenizer.write(stream);\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined;\n      }\n    }\n\n    // Unravel the next token.\n    previous = current;\n    current = current.next;\n  }\n\n  // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n  current = token;\n  while (++index < childEvents.length) {\n    if (\n    // Find a void token that includes a break.\n    childEvents[index][0] === 'exit' && childEvents[index - 1][0] === 'enter' && childEvents[index][1].type === childEvents[index - 1][1].type && childEvents[index][1].start.line !== childEvents[index][1].end.line) {\n      start = index + 1;\n      breaks.push(start);\n      // Help GC.\n      current._tokenizer = undefined;\n      current.previous = undefined;\n      current = current.next;\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = [];\n\n  // If theres one more token (which is the cases for lines that end in an\n  // EOF), thats perfect: the last point we found starts it.\n  // If there isnt then make sure any remaining content is added to it.\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined;\n    current.previous = undefined;\n  } else {\n    breaks.pop();\n  }\n\n  // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices arent affected.\n  index = breaks.length;\n  while (index--) {\n    const slice = childEvents.slice(breaks[index], breaks[index + 1]);\n    const start = startPositions.pop();\n    jumps.unshift([start, start + slice.length - 1]);\n    splice(events, start, 2, slice);\n  }\n  index = -1;\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];\n    adjust += jumps[index][1] - jumps[index][0] - 1;\n  }\n  return gaps;\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n};\n\n/** @type {Construct} */\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n};\n\n/**\n * Content is transparent: its parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token | undefined} */\n  let previous;\n  return chunkStart;\n\n  /**\n   * Before a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkStart(code) {\n    effects.enter('content');\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    });\n    return chunkInside(code);\n  }\n\n  /**\n   * In a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkInside(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n\n    // To do: in `markdown-rs`, each line is parsed on its own, and everything\n    // is stitched together resolving.\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    }\n\n    // Data.\n    effects.consume(code);\n    return chunkInside;\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentEnd(code) {\n    effects.exit('chunkContent');\n    effects.exit('content');\n    return ok(code);\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit('chunkContent');\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous\n    });\n    previous = previous.next;\n    return chunkInside;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function startLookahead(code) {\n    effects.exit('chunkContent');\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return factorySpace(effects, prefixed, 'linePrefix');\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    // Always populated by defaults.\n\n    const tail = self.events[self.events.length - 1];\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === 'linePrefix' && tail[2].sliceSerialize(tail[1], true).length >= 4) {\n      return ok(code);\n    }\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport { blankLine, content } from 'micromark-core-commonmark';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeFlow(effects) {\n  const self = this;\n  const initial = effects.attempt(\n  // Try to parse a blank line.\n  blankLine, atBlankEnding,\n  // Try to parse initial flow (essentially, only code).\n  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), 'linePrefix')));\n  return initial;\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter('lineEndingBlank');\n    effects.consume(code);\n    effects.exit('lineEndingBlank');\n    self.currentConstruct = undefined;\n    return initial;\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    self.currentConstruct = undefined;\n    return initial;\n  }\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n};\nexport const string = initializeFactory('string');\nexport const text = initializeFactory('text');\n\n/**\n * @param {'string' | 'text'} field\n * @returns {InitialConstruct}\n */\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined)\n  };\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this;\n    const constructs = this.parser.constructs[field];\n    const text = effects.attempt(constructs, start, notText);\n    return start;\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code);\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code);\n        return;\n      }\n      effects.enter('data');\n      effects.consume(code);\n      return data;\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data');\n        return text(code);\n      }\n\n      // Data.\n      effects.consume(code);\n      return data;\n    }\n\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true;\n      }\n      const list = constructs[code];\n      let index = -1;\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index];\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true;\n          }\n        }\n      }\n      return false;\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n * @returns {Resolver}\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText;\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1;\n    /** @type {number | undefined} */\n    let enter;\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index;\n          index++;\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Dont do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end;\n          events.splice(enter + 2, index - enter - 2);\n          index = enter + 2;\n        }\n        enter = undefined;\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events;\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we cant hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0; // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if ((eventIndex === events.length || events[eventIndex][1].type === 'lineEnding') && events[eventIndex - 1][1].type === 'data') {\n      const data = events[eventIndex - 1][1];\n      const chunks = context.sliceStream(data);\n      let index = chunks.length;\n      let bufferIndex = -1;\n      let size = 0;\n      /** @type {boolean | undefined} */\n      let tabs;\n      while (index--) {\n        const chunk = chunks[index];\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length;\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++;\n            bufferIndex--;\n          }\n          if (bufferIndex) break;\n          bufferIndex = -1;\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true;\n          size++;\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++;\n          break;\n        }\n      }\n      if (size) {\n        const token = {\n          type: eventIndex === events.length || tabs || size < 2 ? 'lineSuffix' : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        };\n        data.end = Object.assign({}, token.start);\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token);\n        } else {\n          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);\n          eventIndex += 2;\n        }\n      }\n      eventIndex++;\n    }\n  }\n  return events;\n}","/**\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * Call all `resolveAll`s.\n *\n * @param {Array<{resolveAll?: Resolver | undefined}>} constructs\n *   List of constructs, optionally with `resolveAll`s.\n * @param {Array<Event>} events\n *   List of events.\n * @param {TokenizeContext} context\n *   Context used by `tokenize`.\n * @returns {Array<Event>}\n *   Changed events.\n */\nexport function resolveAll(constructs, events, context) {\n  /** @type {Array<Resolver>} */\n  const called = [];\n  let index = -1;\n  while (++index < constructs.length) {\n    const resolve = constructs[index].resolveAll;\n    if (resolve && !called.includes(resolve)) {\n      events = resolve(events, context);\n      called.push(resolve);\n    }\n  }\n  return events;\n}","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {void}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesnt receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(from ? Object.assign({}, from) : {\n    line: 1,\n    column: 1,\n    offset: 0\n  }, {\n    _index: 0,\n    _bufferIndex: -1\n  });\n  /** @type {Record<string, number>} */\n  const columnStart = {};\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n  let chunks = [];\n  /** @type {Array<Token>} */\n  let stack = [];\n  /** @type {boolean | undefined} */\n  let consumed = true;\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  };\n\n  /**\n   * The state function.\n   *\n   * @type {State | void}\n   */\n  let state = initialize.tokenize.call(context, effects);\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode;\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n  return context;\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice);\n    main();\n\n    // Exit if were not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n    addResult(initialize, 0);\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {\n      line,\n      column,\n      offset,\n      _index,\n      _bufferIndex\n    } = point;\n    return {\n      line,\n      column,\n      offset,\n      _index,\n      _bufferIndex\n    };\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex;\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index];\n\n      // If were in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++;\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code;\n\n    // Mark as consumed.\n    consumed = true;\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook;\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs;\n      /** @type {number} */\n      let constructIndex;\n      /** @type {Construct} */\n      let currentConstruct;\n      /** @type {Info} */\n      let info;\n      return Array.isArray(constructs) /* c8 ignore next 1 */ ? handleListOfConstructs(constructs) : 'tokenize' in constructs ?\n      // @ts-expect-error Looks like a construct.\n      handleListOfConstructs([constructs]) : handleMapOfConstructs(constructs);\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          const def = code !== null && map[code];\n          const all = code !== null && map.null;\n          const list = [\n          // To do: add more extension tests.\n          /* c8 ignore next 2 */\n          ...(Array.isArray(def) ? def : def ? [def] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\n          return handleListOfConstructs(list)(code);\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        if (list.length === 0) {\n          return bogusState;\n        }\n        return handleConstruct(list[constructIndex]);\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesnt work because `inspect` in document does a check\n          // w/o a bogus, which doesnt make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          // Always populated by defaults.\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n          return construct.tokenize.call(\n          // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a live binding, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true;\n        info.restore();\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n        return bogusState;\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n    if (construct.resolve) {\n      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    const startPoint = now();\n    const startPrevious = context.previous;\n    const startCurrentConstruct = context.currentConstruct;\n    const startEventsIndex = context.events.length;\n    const startStack = Array.from(stack);\n    return {\n      restore,\n      from: startEventsIndex\n    };\n\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when its on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index;\n  const startBufferIndex = token.start._bufferIndex;\n  const endIndex = token.end._index;\n  const endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n  let view;\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n    if (startBufferIndex > -1) {\n      const head = view[0];\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex);\n      } else {\n        view.shift();\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n  return view;\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1;\n  /** @type {Array<string>} */\n  const result = [];\n  /** @type {boolean | undefined} */\n  let atTab;\n  while (++index < chunks.length) {\n    const chunk = chunks[index];\n    /** @type {string} */\n    let value;\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = '\\r';\n          break;\n        }\n      case -4:\n        {\n          value = '\\n';\n          break;\n        }\n      case -3:\n        {\n          value = '\\r' + '\\n';\n          break;\n        }\n      case -2:\n        {\n          value = expandTabs ? ' ' : '\\t';\n          break;\n        }\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = ' ';\n          break;\n        }\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n    atTab = chunk === -2;\n    result.push(value);\n  }\n  return result.join('');\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const thematicBreak = {\n  name: 'thematicBreak',\n  tokenize: tokenizeThematicBreak\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeThematicBreak(effects, ok, nok) {\n  let size = 0;\n  /** @type {NonNullable<Code>} */\n  let marker;\n  return start;\n\n  /**\n   * Start of thematic break.\n   *\n   * ```markdown\n   * > | ***\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('thematicBreak');\n    // To do: parse indent like `markdown-rs`.\n    return before(code);\n  }\n\n  /**\n   * After optional whitespace, at marker.\n   *\n   * ```markdown\n   * > | ***\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    marker = code;\n    return atBreak(code);\n  }\n\n  /**\n   * After something, before something else.\n   *\n   * ```markdown\n   * > | ***\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === marker) {\n      effects.enter('thematicBreakSequence');\n      return sequence(code);\n    }\n    if (size >= 3 && (code === null || markdownLineEnding(code))) {\n      effects.exit('thematicBreak');\n      return ok(code);\n    }\n    return nok(code);\n  }\n\n  /**\n   * In sequence.\n   *\n   * ```markdown\n   * > | ***\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequence(code) {\n    if (code === marker) {\n      effects.consume(code);\n      size++;\n      return sequence;\n    }\n    effects.exit('thematicBreakSequence');\n    return markdownSpace(code) ? factorySpace(effects, atBreak, 'whitespace')(code) : atBreak(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').Exiter} Exiter\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { asciiDigit, markdownSpace } from 'micromark-util-character';\nimport { blankLine } from './blank-line.js';\nimport { thematicBreak } from './thematic-break.js';\n\n/** @type {Construct} */\nexport const list = {\n  name: 'list',\n  tokenize: tokenizeListStart,\n  continuation: {\n    tokenize: tokenizeListContinuation\n  },\n  exit: tokenizeListEnd\n};\n\n/** @type {Construct} */\nconst listItemPrefixWhitespaceConstruct = {\n  tokenize: tokenizeListItemPrefixWhitespace,\n  partial: true\n};\n\n/** @type {Construct} */\nconst indentConstruct = {\n  tokenize: tokenizeIndent,\n  partial: true\n};\n\n// To do: `markdown-rs` parses list items on their own and later stitches them\n// together.\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\nfunction tokenizeListStart(effects, ok, nok) {\n  const self = this;\n  const tail = self.events[self.events.length - 1];\n  let initialSize = tail && tail[1].type === 'linePrefix' ? tail[2].sliceSerialize(tail[1], true).length : 0;\n  let size = 0;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    const kind = self.containerState.type || (code === 42 || code === 43 || code === 45 ? 'listUnordered' : 'listOrdered');\n    if (kind === 'listUnordered' ? !self.containerState.marker || code === self.containerState.marker : asciiDigit(code)) {\n      if (!self.containerState.type) {\n        self.containerState.type = kind;\n        effects.enter(kind, {\n          _container: true\n        });\n      }\n      if (kind === 'listUnordered') {\n        effects.enter('listItemPrefix');\n        return code === 42 || code === 45 ? effects.check(thematicBreak, nok, atMarker)(code) : atMarker(code);\n      }\n      if (!self.interrupt || code === 49) {\n        effects.enter('listItemPrefix');\n        effects.enter('listItemValue');\n        return inside(code);\n      }\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function inside(code) {\n    if (asciiDigit(code) && ++size < 10) {\n      effects.consume(code);\n      return inside;\n    }\n    if ((!self.interrupt || size < 2) && (self.containerState.marker ? code === self.containerState.marker : code === 41 || code === 46)) {\n      effects.exit('listItemValue');\n      return atMarker(code);\n    }\n    return nok(code);\n  }\n\n  /**\n   * @type {State}\n   **/\n  function atMarker(code) {\n    effects.enter('listItemMarker');\n    effects.consume(code);\n    effects.exit('listItemMarker');\n    self.containerState.marker = self.containerState.marker || code;\n    return effects.check(blankLine,\n    // Cant be empty when interrupting.\n    self.interrupt ? nok : onBlank, effects.attempt(listItemPrefixWhitespaceConstruct, endOfPrefix, otherPrefix));\n  }\n\n  /** @type {State} */\n  function onBlank(code) {\n    self.containerState.initialBlankLine = true;\n    initialSize++;\n    return endOfPrefix(code);\n  }\n\n  /** @type {State} */\n  function otherPrefix(code) {\n    if (markdownSpace(code)) {\n      effects.enter('listItemPrefixWhitespace');\n      effects.consume(code);\n      effects.exit('listItemPrefixWhitespace');\n      return endOfPrefix;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function endOfPrefix(code) {\n    self.containerState.size = initialSize + self.sliceSerialize(effects.exit('listItemPrefix'), true).length;\n    return ok(code);\n  }\n}\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\nfunction tokenizeListContinuation(effects, ok, nok) {\n  const self = this;\n  self.containerState._closeFlow = undefined;\n  return effects.check(blankLine, onBlank, notBlank);\n\n  /** @type {State} */\n  function onBlank(code) {\n    self.containerState.furtherBlankLines = self.containerState.furtherBlankLines || self.containerState.initialBlankLine;\n\n    // We have a blank line.\n    // Still, try to consume at most the items size.\n    return factorySpace(effects, ok, 'listItemIndent', self.containerState.size + 1)(code);\n  }\n\n  /** @type {State} */\n  function notBlank(code) {\n    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {\n      self.containerState.furtherBlankLines = undefined;\n      self.containerState.initialBlankLine = undefined;\n      return notInCurrentItem(code);\n    }\n    self.containerState.furtherBlankLines = undefined;\n    self.containerState.initialBlankLine = undefined;\n    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code);\n  }\n\n  /** @type {State} */\n  function notInCurrentItem(code) {\n    // While we do continue, we signal that the flow should be closed.\n    self.containerState._closeFlow = true;\n    // As were closing flow, were no longer interrupting.\n    self.interrupt = undefined;\n    // Always populated by defaults.\n\n    return factorySpace(effects, effects.attempt(list, ok, nok), 'linePrefix', self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code);\n  }\n}\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\nfunction tokenizeIndent(effects, ok, nok) {\n  const self = this;\n  return factorySpace(effects, afterPrefix, 'listItemIndent', self.containerState.size + 1);\n\n  /** @type {State} */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1];\n    return tail && tail[1].type === 'listItemIndent' && tail[2].sliceSerialize(tail[1], true).length === self.containerState.size ? ok(code) : nok(code);\n  }\n}\n\n/**\n * @type {Exiter}\n * @this {TokenizeContext}\n */\nfunction tokenizeListEnd(effects) {\n  effects.exit(this.containerState.type);\n}\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\nfunction tokenizeListItemPrefixWhitespace(effects, ok, nok) {\n  const self = this;\n\n  // Always populated by defaults.\n\n  return factorySpace(effects, afterPrefix, 'listItemPrefixWhitespace', self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4 + 1);\n\n  /** @type {State} */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1];\n    return !markdownSpace(code) && tail && tail[1].type === 'listItemPrefixWhitespace' ? ok(code) : nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Exiter} Exiter\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const blockQuote = {\n  name: 'blockQuote',\n  tokenize: tokenizeBlockQuoteStart,\n  continuation: {\n    tokenize: tokenizeBlockQuoteContinuation\n  },\n  exit\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlockQuoteStart(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   * Start of block quote.\n   *\n   * ```markdown\n   * > | > a\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === 62) {\n      const state = self.containerState;\n      if (!state.open) {\n        effects.enter('blockQuote', {\n          _container: true\n        });\n        state.open = true;\n      }\n      effects.enter('blockQuotePrefix');\n      effects.enter('blockQuoteMarker');\n      effects.consume(code);\n      effects.exit('blockQuoteMarker');\n      return after;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `>`, before optional whitespace.\n   *\n   * ```markdown\n   * > | > a\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    if (markdownSpace(code)) {\n      effects.enter('blockQuotePrefixWhitespace');\n      effects.consume(code);\n      effects.exit('blockQuotePrefixWhitespace');\n      effects.exit('blockQuotePrefix');\n      return ok;\n    }\n    effects.exit('blockQuotePrefix');\n    return ok(code);\n  }\n}\n\n/**\n * Start of block quote continuation.\n *\n * ```markdown\n *   | > a\n * > | > b\n *     ^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlockQuoteContinuation(effects, ok, nok) {\n  const self = this;\n  return contStart;\n\n  /**\n   * Start of block quote continuation.\n   *\n   * Also used to parse the first block quote opening.\n   *\n   * ```markdown\n   *   | > a\n   * > | > b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function contStart(code) {\n    if (markdownSpace(code)) {\n      // Always populated by defaults.\n\n      return factorySpace(effects, contBefore, 'linePrefix', self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code);\n    }\n    return contBefore(code);\n  }\n\n  /**\n   * At `>`, after optional whitespace.\n   *\n   * Also used to parse the first block quote opening.\n   *\n   * ```markdown\n   *   | > a\n   * > | > b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function contBefore(code) {\n    return effects.attempt(blockQuote, ok, nok)(code);\n  }\n}\n\n/** @type {Exiter} */\nfunction exit(effects) {\n  effects.exit('blockQuote');\n}","/**\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenType} TokenType\n */\n\nimport { asciiControl, markdownLineEndingOrSpace, markdownLineEnding } from 'micromark-util-character';\n/**\n * Parse destinations.\n *\n * ###### Examples\n *\n * ```markdown\n * <a>\n * <a\\>b>\n * <a b>\n * <a)>\n * a\n * a\\)b\n * a(b)c\n * a(b)\n * ```\n *\n * @param {Effects} effects\n *   Context.\n * @param {State} ok\n *   State switched to when successful.\n * @param {State} nok\n *   State switched to when unsuccessful.\n * @param {TokenType} type\n *   Type for whole (`<a>` or `b`).\n * @param {TokenType} literalType\n *   Type when enclosed (`<a>`).\n * @param {TokenType} literalMarkerType\n *   Type for enclosing (`<` and `>`).\n * @param {TokenType} rawType\n *   Type when not enclosed (`b`).\n * @param {TokenType} stringType\n *   Type for the value (`a` or `b`).\n * @param {number | undefined} [max=Infinity]\n *   Depth of nested parens (inclusive).\n * @returns {State}\n *   Start state.\n */ // eslint-disable-next-line max-params\nexport function factoryDestination(effects, ok, nok, type, literalType, literalMarkerType, rawType, stringType, max) {\n  const limit = max || Number.POSITIVE_INFINITY;\n  let balance = 0;\n  return start;\n\n  /**\n   * Start of destination.\n   *\n   * ```markdown\n   * > | <aa>\n   *     ^\n   * > | aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === 60) {\n      effects.enter(type);\n      effects.enter(literalType);\n      effects.enter(literalMarkerType);\n      effects.consume(code);\n      effects.exit(literalMarkerType);\n      return enclosedBefore;\n    }\n\n    // ASCII control, space, closing paren.\n    if (code === null || code === 32 || code === 41 || asciiControl(code)) {\n      return nok(code);\n    }\n    effects.enter(type);\n    effects.enter(rawType);\n    effects.enter(stringType);\n    effects.enter('chunkString', {\n      contentType: 'string'\n    });\n    return raw(code);\n  }\n\n  /**\n   * After `<`, at an enclosed destination.\n   *\n   * ```markdown\n   * > | <aa>\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function enclosedBefore(code) {\n    if (code === 62) {\n      effects.enter(literalMarkerType);\n      effects.consume(code);\n      effects.exit(literalMarkerType);\n      effects.exit(literalType);\n      effects.exit(type);\n      return ok;\n    }\n    effects.enter(stringType);\n    effects.enter('chunkString', {\n      contentType: 'string'\n    });\n    return enclosed(code);\n  }\n\n  /**\n   * In enclosed destination.\n   *\n   * ```markdown\n   * > | <aa>\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function enclosed(code) {\n    if (code === 62) {\n      effects.exit('chunkString');\n      effects.exit(stringType);\n      return enclosedBefore(code);\n    }\n    if (code === null || code === 60 || markdownLineEnding(code)) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return code === 92 ? enclosedEscape : enclosed;\n  }\n\n  /**\n   * After `\\`, at a special character.\n   *\n   * ```markdown\n   * > | <a\\*a>\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function enclosedEscape(code) {\n    if (code === 60 || code === 62 || code === 92) {\n      effects.consume(code);\n      return enclosed;\n    }\n    return enclosed(code);\n  }\n\n  /**\n   * In raw destination.\n   *\n   * ```markdown\n   * > | aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function raw(code) {\n    if (!balance && (code === null || code === 41 || markdownLineEndingOrSpace(code))) {\n      effects.exit('chunkString');\n      effects.exit(stringType);\n      effects.exit(rawType);\n      effects.exit(type);\n      return ok(code);\n    }\n    if (balance < limit && code === 40) {\n      effects.consume(code);\n      balance++;\n      return raw;\n    }\n    if (code === 41) {\n      effects.consume(code);\n      balance--;\n      return raw;\n    }\n\n    // ASCII control (but *not* `\\0`) and space and `(`.\n    // Note: in `markdown-rs`, `\\0` exists in codes, in `micromark-js` it\n    // doesnt.\n    if (code === null || code === 32 || code === 40 || asciiControl(code)) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return code === 92 ? rawEscape : raw;\n  }\n\n  /**\n   * After `\\`, at special character.\n   *\n   * ```markdown\n   * > | a\\*a\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function rawEscape(code) {\n    if (code === 40 || code === 41 || code === 92) {\n      effects.consume(code);\n      return raw;\n    }\n    return raw(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').TokenType} TokenType\n */\n\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/**\n * Parse labels.\n *\n * >  **Note**: labels in markdown are capped at 999 characters in the string.\n *\n * ###### Examples\n *\n * ```markdown\n * [a]\n * [a\n * b]\n * [a\\]b]\n * ```\n *\n * @this {TokenizeContext}\n *   Tokenize context.\n * @param {Effects} effects\n *   Context.\n * @param {State} ok\n *   State switched to when successful.\n * @param {State} nok\n *   State switched to when unsuccessful.\n * @param {TokenType} type\n *   Type of the whole label (`[a]`).\n * @param {TokenType} markerType\n *   Type for the markers (`[` and `]`).\n * @param {TokenType} stringType\n *   Type for the identifier (`a`).\n * @returns {State}\n *   Start state.\n */ // eslint-disable-next-line max-params\nexport function factoryLabel(effects, ok, nok, type, markerType, stringType) {\n  const self = this;\n  let size = 0;\n  /** @type {boolean} */\n  let seen;\n  return start;\n\n  /**\n   * Start of label.\n   *\n   * ```markdown\n   * > | [a]\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter(type);\n    effects.enter(markerType);\n    effects.consume(code);\n    effects.exit(markerType);\n    effects.enter(stringType);\n    return atBreak;\n  }\n\n  /**\n   * In label, at something, before something else.\n   *\n   * ```markdown\n   * > | [a]\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (size > 999 || code === null || code === 91 || code === 93 && !seen ||\n    // To do: remove in the future once weve switched from\n    // `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,\n    // which doesnt need this.\n    // Hidden footnotes hook.\n    /* c8 ignore next 3 */\n    code === 94 && !size && '_hiddenFootnoteSupport' in self.parser.constructs) {\n      return nok(code);\n    }\n    if (code === 93) {\n      effects.exit(stringType);\n      effects.enter(markerType);\n      effects.consume(code);\n      effects.exit(markerType);\n      effects.exit(type);\n      return ok;\n    }\n\n    // To do: indent? Link chunks and EOLs together?\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding');\n      effects.consume(code);\n      effects.exit('lineEnding');\n      return atBreak;\n    }\n    effects.enter('chunkString', {\n      contentType: 'string'\n    });\n    return labelInside(code);\n  }\n\n  /**\n   * In label, in text.\n   *\n   * ```markdown\n   * > | [a]\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelInside(code) {\n    if (code === null || code === 91 || code === 93 || markdownLineEnding(code) || size++ > 999) {\n      effects.exit('chunkString');\n      return atBreak(code);\n    }\n    effects.consume(code);\n    if (!seen) seen = !markdownSpace(code);\n    return code === 92 ? labelEscape : labelInside;\n  }\n\n  /**\n   * After `\\`, at a special character.\n   *\n   * ```markdown\n   * > | [a\\*a]\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelEscape(code) {\n    if (code === 91 || code === 92 || code === 93) {\n      effects.consume(code);\n      size++;\n      return labelInside;\n    }\n    return labelInside(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenType} TokenType\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/**\n * Parse titles.\n *\n * ###### Examples\n *\n * ```markdown\n * \"a\"\n * 'b'\n * (c)\n * \"a\n * b\"\n * 'a\n *     b'\n * (a\\)b)\n * ```\n *\n * @param {Effects} effects\n *   Context.\n * @param {State} ok\n *   State switched to when successful.\n * @param {State} nok\n *   State switched to when unsuccessful.\n * @param {TokenType} type\n *   Type of the whole title (`\"a\"`, `'b'`, `(c)`).\n * @param {TokenType} markerType\n *   Type for the markers (`\"`, `'`, `(`, and `)`).\n * @param {TokenType} stringType\n *   Type for the value (`a`).\n * @returns {State}\n *   Start state.\n */ // eslint-disable-next-line max-params\nexport function factoryTitle(effects, ok, nok, type, markerType, stringType) {\n  /** @type {NonNullable<Code>} */\n  let marker;\n  return start;\n\n  /**\n   * Start of title.\n   *\n   * ```markdown\n   * > | \"a\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === 34 || code === 39 || code === 40) {\n      effects.enter(type);\n      effects.enter(markerType);\n      effects.consume(code);\n      effects.exit(markerType);\n      marker = code === 40 ? 41 : code;\n      return begin;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After opening marker.\n   *\n   * This is also used at the closing marker.\n   *\n   * ```markdown\n   * > | \"a\"\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function begin(code) {\n    if (code === marker) {\n      effects.enter(markerType);\n      effects.consume(code);\n      effects.exit(markerType);\n      effects.exit(type);\n      return ok;\n    }\n    effects.enter(stringType);\n    return atBreak(code);\n  }\n\n  /**\n   * At something, before something else.\n   *\n   * ```markdown\n   * > | \"a\"\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === marker) {\n      effects.exit(stringType);\n      return begin(marker);\n    }\n    if (code === null) {\n      return nok(code);\n    }\n\n    // Note: blank lines cant exist in content.\n    if (markdownLineEnding(code)) {\n      // To do: use `space_or_tab_eol_with_options`, connect.\n      effects.enter('lineEnding');\n      effects.consume(code);\n      effects.exit('lineEnding');\n      return factorySpace(effects, atBreak, 'linePrefix');\n    }\n    effects.enter('chunkString', {\n      contentType: 'string'\n    });\n    return inside(code);\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === marker || code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString');\n      return atBreak(code);\n    }\n    effects.consume(code);\n    return code === 92 ? escape : inside;\n  }\n\n  /**\n   * After `\\`, at a special character.\n   *\n   * ```markdown\n   * > | \"a\\*b\"\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function escape(code) {\n    if (code === marker || code === 92) {\n      effects.consume(code);\n      return inside;\n    }\n    return inside(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').State} State\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/**\n * Parse spaces and tabs.\n *\n * There is no `nok` parameter:\n *\n * *   line endings or spaces in markdown are often optional, in which case this\n *     factory can be used and `ok` will be switched to whether spaces were found\n *     or not\n * *   one line ending or space can be detected with\n *     `markdownLineEndingOrSpace(code)` right before using `factoryWhitespace`\n *\n * @param {Effects} effects\n *   Context.\n * @param {State} ok\n *   State switched to when successful.\n * @returns\n *   Start state.\n */\nexport function factoryWhitespace(effects, ok) {\n  /** @type {boolean} */\n  let seen;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding');\n      effects.consume(code);\n      effects.exit('lineEnding');\n      seen = true;\n      return start;\n    }\n    if (markdownSpace(code)) {\n      return factorySpace(effects, start, seen ? 'linePrefix' : 'lineSuffix')(code);\n    }\n    return ok(code);\n  }\n}","/**\n * Normalize an identifier (as found in references, definitions).\n *\n * Collapses markdown whitespace, trim, and then lower- and uppercase.\n *\n * Some characters are considered uppercase, such as U+03F4 (``), but if their\n * lowercase counterpart (U+03B8 (``)) is uppercased will result in a different\n * uppercase character (U+0398 (``)).\n * So, to get a canonical form, we perform both lower- and uppercase.\n *\n * Using uppercase last makes sure keys will never interact with default\n * prototypal values (such as `constructor`): nothing in the prototype of\n * `Object` is uppercase.\n *\n * @param {string} value\n *   Identifier to normalize.\n * @returns {string}\n *   Normalized identifier.\n */\nexport function normalizeIdentifier(value) {\n  return value\n  // Collapse markdown whitespace.\n  .replace(/[\\t\\n\\r ]+/g, ' ')\n  // Trim.\n  .replace(/^ | $/g, '')\n  // Some characters are considered uppercase, but if their lowercase\n  // counterpart is uppercased will result in a different uppercase\n  // character.\n  // Hence, to get that form, we perform both lower- and uppercase.\n  // Upper case makes sure keys will not interact with default prototypal\n  // methods: no method is uppercase.\n  .toLowerCase().toUpperCase();\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factoryDestination } from 'micromark-factory-destination';\nimport { factoryLabel } from 'micromark-factory-label';\nimport { factorySpace } from 'micromark-factory-space';\nimport { factoryTitle } from 'micromark-factory-title';\nimport { factoryWhitespace } from 'micromark-factory-whitespace';\nimport { markdownLineEnding, markdownLineEndingOrSpace, markdownSpace } from 'micromark-util-character';\nimport { normalizeIdentifier } from 'micromark-util-normalize-identifier';\n/** @type {Construct} */\nexport const definition = {\n  name: 'definition',\n  tokenize: tokenizeDefinition\n};\n\n/** @type {Construct} */\nconst titleBefore = {\n  tokenize: tokenizeTitleBefore,\n  partial: true\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeDefinition(effects, ok, nok) {\n  const self = this;\n  /** @type {string} */\n  let identifier;\n  return start;\n\n  /**\n   * At start of a definition.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // Do not interrupt paragraphs (but do follow definitions).\n    // To do: do `interrupt` the way `markdown-rs` does.\n    // To do: parse whitespace the way `markdown-rs` does.\n    effects.enter('definition');\n    return before(code);\n  }\n\n  /**\n   * After optional whitespace, at `[`.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    // To do: parse whitespace the way `markdown-rs` does.\n\n    return factoryLabel.call(self, effects, labelAfter,\n    // Note: we dont need to reset the way `markdown-rs` does.\n    nok, 'definitionLabel', 'definitionLabelMarker', 'definitionLabelString')(code);\n  }\n\n  /**\n   * After label.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelAfter(code) {\n    identifier = normalizeIdentifier(self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1));\n    if (code === 58) {\n      effects.enter('definitionMarker');\n      effects.consume(code);\n      effects.exit('definitionMarker');\n      return markerAfter;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After marker.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function markerAfter(code) {\n    // Note: whitespace is optional.\n    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, destinationBefore)(code) : destinationBefore(code);\n  }\n\n  /**\n   * Before destination.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function destinationBefore(code) {\n    return factoryDestination(effects, destinationAfter,\n    // Note: we dont need to reset the way `markdown-rs` does.\n    nok, 'definitionDestination', 'definitionDestinationLiteral', 'definitionDestinationLiteralMarker', 'definitionDestinationRaw', 'definitionDestinationString')(code);\n  }\n\n  /**\n   * After destination.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function destinationAfter(code) {\n    return effects.attempt(titleBefore, after, after)(code);\n  }\n\n  /**\n   * After definition.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return markdownSpace(code) ? factorySpace(effects, afterWhitespace, 'whitespace')(code) : afterWhitespace(code);\n  }\n\n  /**\n   * After definition, after optional whitespace.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterWhitespace(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('definition');\n\n      // Note: we dont care about uniqueness.\n      // Its likely that that doesnt happen very frequently.\n      // It is more likely that it wastes precious time.\n      self.parser.defined.push(identifier);\n\n      // To do: `markdown-rs` interrupt.\n      // // Youd be interrupting.\n      // tokenizer.interrupt = true\n      return ok(code);\n    }\n    return nok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeTitleBefore(effects, ok, nok) {\n  return titleBefore;\n\n  /**\n   * After destination, at whitespace.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleBefore(code) {\n    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, beforeMarker)(code) : nok(code);\n  }\n\n  /**\n   * At title.\n   *\n   * ```markdown\n   *   | [a]: b\n   * > | \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeMarker(code) {\n    return factoryTitle(effects, titleAfter, nok, 'definitionTitle', 'definitionTitleMarker', 'definitionTitleString')(code);\n  }\n\n  /**\n   * After title.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleAfter(code) {\n    return markdownSpace(code) ? factorySpace(effects, titleAfterOptionalWhitespace, 'whitespace')(code) : titleAfterOptionalWhitespace(code);\n  }\n\n  /**\n   * After title, after optional whitespace.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleAfterOptionalWhitespace(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const codeIndented = {\n  name: 'codeIndented',\n  tokenize: tokenizeCodeIndented\n};\n\n/** @type {Construct} */\nconst furtherStart = {\n  tokenize: tokenizeFurtherStart,\n  partial: true\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeIndented(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   * Start of code (indented).\n   *\n   * > **Parsing note**: it is not needed to check if this first line is a\n   * > filled line (that it has a non-whitespace character), because blank lines\n   * > are parsed already, so we never run into that.\n   *\n   * ```markdown\n   * > |     aaa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: manually check if interrupting like `markdown-rs`.\n\n    effects.enter('codeIndented');\n    // To do: use an improved `space_or_tab` function like `markdown-rs`,\n    // so that we can drop the next state.\n    return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)(code);\n  }\n\n  /**\n   * At start, after 1 or 4 spaces.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1];\n    return tail && tail[1].type === 'linePrefix' && tail[2].sliceSerialize(tail[1], true).length >= 4 ? atBreak(code) : nok(code);\n  }\n\n  /**\n   * At a break.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^  ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === null) {\n      return after(code);\n    }\n    if (markdownLineEnding(code)) {\n      return effects.attempt(furtherStart, atBreak, after)(code);\n    }\n    effects.enter('codeFlowValue');\n    return inside(code);\n  }\n\n  /**\n   * In code content.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue');\n      return atBreak(code);\n    }\n    effects.consume(code);\n    return inside;\n  }\n\n  /** @type {State} */\n  function after(code) {\n    effects.exit('codeIndented');\n    // To do: allow interrupting like `markdown-rs`.\n    // Feel free to interrupt.\n    // tokenizer.interrupt = false\n    return ok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeFurtherStart(effects, ok, nok) {\n  const self = this;\n  return furtherStart;\n\n  /**\n   * At eol, trying to parse another indent.\n   *\n   * ```markdown\n   * > |     aaa\n   *            ^\n   *   |     bbb\n   * ```\n   *\n   * @type {State}\n   */\n  function furtherStart(code) {\n    // To do: improve `lazy` / `pierce` handling.\n    // If this is a lazy line, it cant be code.\n    if (self.parser.lazy[self.now().line]) {\n      return nok(code);\n    }\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding');\n      effects.consume(code);\n      effects.exit('lineEnding');\n      return furtherStart;\n    }\n\n    // To do: the code here in `micromark-js` is a bit different from\n    // `markdown-rs` because there it can attempt spaces.\n    // We cant yet.\n    //\n    // To do: use an improved `space_or_tab` function like `markdown-rs`,\n    // so that we can drop the next state.\n    return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)(code);\n  }\n\n  /**\n   * At start, after 1 or 4 spaces.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1];\n    return tail && tail[1].type === 'linePrefix' && tail[2].sliceSerialize(tail[1], true).length >= 4 ? ok(code) : markdownLineEnding(code) ? furtherStart(code) : nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const setextUnderline = {\n  name: 'setextUnderline',\n  tokenize: tokenizeSetextUnderline,\n  resolveTo: resolveToSetextUnderline\n};\n\n/** @type {Resolver} */\nfunction resolveToSetextUnderline(events, context) {\n  // To do: resolve like `markdown-rs`.\n  let index = events.length;\n  /** @type {number | undefined} */\n  let content;\n  /** @type {number | undefined} */\n  let text;\n  /** @type {number | undefined} */\n  let definition;\n\n  // Find the opening of the content.\n  // Itll always exist: we dont tokenize if it isnt there.\n  while (index--) {\n    if (events[index][0] === 'enter') {\n      if (events[index][1].type === 'content') {\n        content = index;\n        break;\n      }\n      if (events[index][1].type === 'paragraph') {\n        text = index;\n      }\n    }\n    // Exit\n    else {\n      if (events[index][1].type === 'content') {\n        // Remove the content end (if needed well add it later)\n        events.splice(index, 1);\n      }\n      if (!definition && events[index][1].type === 'definition') {\n        definition = index;\n      }\n    }\n  }\n  const heading = {\n    type: 'setextHeading',\n    start: Object.assign({}, events[text][1].start),\n    end: Object.assign({}, events[events.length - 1][1].end)\n  };\n\n  // Change the paragraph to setext heading text.\n  events[text][1].type = 'setextHeadingText';\n\n  // If we have definitions in the content, well keep on having content,\n  // but we need move it.\n  if (definition) {\n    events.splice(text, 0, ['enter', heading, context]);\n    events.splice(definition + 1, 0, ['exit', events[content][1], context]);\n    events[content][1].end = Object.assign({}, events[definition][1].end);\n  } else {\n    events[content][1] = heading;\n  }\n\n  // Add the heading exit at the end.\n  events.push(['exit', heading, context]);\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeSetextUnderline(effects, ok, nok) {\n  const self = this;\n  /** @type {NonNullable<Code>} */\n  let marker;\n  return start;\n\n  /**\n   * At start of heading (setext) underline.\n   *\n   * ```markdown\n   *   | aa\n   * > | ==\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    let index = self.events.length;\n    /** @type {boolean | undefined} */\n    let paragraph;\n    // Find an opening.\n    while (index--) {\n      // Skip enter/exit of line ending, line prefix, and content.\n      // We can now either have a definition or a paragraph.\n      if (self.events[index][1].type !== 'lineEnding' && self.events[index][1].type !== 'linePrefix' && self.events[index][1].type !== 'content') {\n        paragraph = self.events[index][1].type === 'paragraph';\n        break;\n      }\n    }\n\n    // To do: handle lazy/pierce like `markdown-rs`.\n    // To do: parse indent like `markdown-rs`.\n    if (!self.parser.lazy[self.now().line] && (self.interrupt || paragraph)) {\n      effects.enter('setextHeadingLine');\n      marker = code;\n      return before(code);\n    }\n    return nok(code);\n  }\n\n  /**\n   * After optional whitespace, at `-` or `=`.\n   *\n   * ```markdown\n   *   | aa\n   * > | ==\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    effects.enter('setextHeadingLineSequence');\n    return inside(code);\n  }\n\n  /**\n   * In sequence.\n   *\n   * ```markdown\n   *   | aa\n   * > | ==\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === marker) {\n      effects.consume(code);\n      return inside;\n    }\n    effects.exit('setextHeadingLineSequence');\n    return markdownSpace(code) ? factorySpace(effects, after, 'lineSuffix')(code) : after(code);\n  }\n\n  /**\n   * After sequence, after optional whitespace.\n   *\n   * ```markdown\n   *   | aa\n   * > | ==\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('setextHeadingLine');\n      return ok(code);\n    }\n    return nok(code);\n  }\n}","/**\n * List of lowercase HTML block tag names.\n *\n * The list, when parsing HTML (flow), results in more relaxed rules (condition\n * 6).\n * Because they are known blocks, the HTML-like syntax doesnt have to be\n * strictly parsed.\n * For tag names not in this list, a more strict algorithm (condition 7) is used\n * to detect whether the HTML-like syntax is seen as HTML (flow) or not.\n *\n * This is copied from:\n * <https://spec.commonmark.org/0.30/#html-blocks>.\n *\n * >  **Note**: `search` was added in `CommonMark@0.31`.\n */\nexport const htmlBlockNames = ['address', 'article', 'aside', 'base', 'basefont', 'blockquote', 'body', 'caption', 'center', 'col', 'colgroup', 'dd', 'details', 'dialog', 'dir', 'div', 'dl', 'dt', 'fieldset', 'figcaption', 'figure', 'footer', 'form', 'frame', 'frameset', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'head', 'header', 'hr', 'html', 'iframe', 'legend', 'li', 'link', 'main', 'menu', 'menuitem', 'nav', 'noframes', 'ol', 'optgroup', 'option', 'p', 'param', 'search', 'section', 'summary', 'table', 'tbody', 'td', 'tfoot', 'th', 'thead', 'title', 'tr', 'track', 'ul'];\n\n/**\n * List of lowercase HTML raw tag names.\n *\n * The list, when parsing HTML (flow), results in HTML that can include lines\n * without exiting, until a closing tag also in this list is found (condition\n * 1).\n *\n * This module is copied from:\n * <https://spec.commonmark.org/0.30/#html-blocks>.\n *\n * >  **Note**: `textarea` was added in `CommonMark@0.30`.\n */\nexport const htmlRawNames = ['pre', 'script', 'style', 'textarea'];","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { asciiAlpha, asciiAlphanumeric, markdownLineEnding, markdownLineEndingOrSpace, markdownSpace } from 'micromark-util-character';\nimport { htmlBlockNames, htmlRawNames } from 'micromark-util-html-tag-name';\nimport { blankLine } from './blank-line.js';\n\n/** @type {Construct} */\nexport const htmlFlow = {\n  name: 'htmlFlow',\n  tokenize: tokenizeHtmlFlow,\n  resolveTo: resolveToHtmlFlow,\n  concrete: true\n};\n\n/** @type {Construct} */\nconst blankLineBefore = {\n  tokenize: tokenizeBlankLineBefore,\n  partial: true\n};\nconst nonLazyContinuationStart = {\n  tokenize: tokenizeNonLazyContinuationStart,\n  partial: true\n};\n\n/** @type {Resolver} */\nfunction resolveToHtmlFlow(events) {\n  let index = events.length;\n  while (index--) {\n    if (events[index][0] === 'enter' && events[index][1].type === 'htmlFlow') {\n      break;\n    }\n  }\n  if (index > 1 && events[index - 2][1].type === 'linePrefix') {\n    // Add the prefix start to the HTML token.\n    events[index][1].start = events[index - 2][1].start;\n    // Add the prefix start to the HTML line token.\n    events[index + 1][1].start = events[index - 2][1].start;\n    // Remove the line prefix.\n    events.splice(index - 2, 2);\n  }\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeHtmlFlow(effects, ok, nok) {\n  const self = this;\n  /** @type {number} */\n  let marker;\n  /** @type {boolean} */\n  let closingTag;\n  /** @type {string} */\n  let buffer;\n  /** @type {number} */\n  let index;\n  /** @type {Code} */\n  let markerB;\n  return start;\n\n  /**\n   * Start of HTML (flow).\n   *\n   * ```markdown\n   * > | <x />\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse indent like `markdown-rs`.\n    return before(code);\n  }\n\n  /**\n   * At `<`, after optional whitespace.\n   *\n   * ```markdown\n   * > | <x />\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    effects.enter('htmlFlow');\n    effects.enter('htmlFlowData');\n    effects.consume(code);\n    return open;\n  }\n\n  /**\n   * After `<`, at tag name or other stuff.\n   *\n   * ```markdown\n   * > | <x />\n   *      ^\n   * > | <!doctype>\n   *      ^\n   * > | <!--xxx-->\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (code === 33) {\n      effects.consume(code);\n      return declarationOpen;\n    }\n    if (code === 47) {\n      effects.consume(code);\n      closingTag = true;\n      return tagCloseStart;\n    }\n    if (code === 63) {\n      effects.consume(code);\n      marker = 3;\n      // To do:\n      // tokenizer.concrete = true\n      // To do: use `markdown-rs` style interrupt.\n      // While were in an instruction instead of a declaration, were on a `?`\n      // right now, so we do need to search for `>`, similar to declarations.\n      return self.interrupt ? ok : continuationDeclarationInside;\n    }\n\n    // ASCII alphabetical.\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      // @ts-expect-error: not null.\n      buffer = String.fromCharCode(code);\n      return tagName;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `<!`, at declaration, comment, or CDATA.\n   *\n   * ```markdown\n   * > | <!doctype>\n   *       ^\n   * > | <!--xxx-->\n   *       ^\n   * > | <![CDATA[>&<]]>\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function declarationOpen(code) {\n    if (code === 45) {\n      effects.consume(code);\n      marker = 2;\n      return commentOpenInside;\n    }\n    if (code === 91) {\n      effects.consume(code);\n      marker = 5;\n      index = 0;\n      return cdataOpenInside;\n    }\n\n    // ASCII alphabetical.\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      marker = 4;\n      // // Do not form containers.\n      // tokenizer.concrete = true\n      return self.interrupt ? ok : continuationDeclarationInside;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `<!-`, inside a comment, at another `-`.\n   *\n   * ```markdown\n   * > | <!--xxx-->\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function commentOpenInside(code) {\n    if (code === 45) {\n      effects.consume(code);\n      // // Do not form containers.\n      // tokenizer.concrete = true\n      return self.interrupt ? ok : continuationDeclarationInside;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `<![`, inside CDATA, expecting `CDATA[`.\n   *\n   * ```markdown\n   * > | <![CDATA[>&<]]>\n   *        ^^^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function cdataOpenInside(code) {\n    const value = 'CDATA[';\n    if (code === value.charCodeAt(index++)) {\n      effects.consume(code);\n      if (index === value.length) {\n        // // Do not form containers.\n        // tokenizer.concrete = true\n        return self.interrupt ? ok : continuation;\n      }\n      return cdataOpenInside;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `</`, in closing tag, at tag name.\n   *\n   * ```markdown\n   * > | </x>\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagCloseStart(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      // @ts-expect-error: not null.\n      buffer = String.fromCharCode(code);\n      return tagName;\n    }\n    return nok(code);\n  }\n\n  /**\n   * In tag name.\n   *\n   * ```markdown\n   * > | <ab>\n   *      ^^\n   * > | </ab>\n   *       ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagName(code) {\n    if (code === null || code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {\n      const slash = code === 47;\n      const name = buffer.toLowerCase();\n      if (!slash && !closingTag && htmlRawNames.includes(name)) {\n        marker = 1;\n        // // Do not form containers.\n        // tokenizer.concrete = true\n        return self.interrupt ? ok(code) : continuation(code);\n      }\n      if (htmlBlockNames.includes(buffer.toLowerCase())) {\n        marker = 6;\n        if (slash) {\n          effects.consume(code);\n          return basicSelfClosing;\n        }\n\n        // // Do not form containers.\n        // tokenizer.concrete = true\n        return self.interrupt ? ok(code) : continuation(code);\n      }\n      marker = 7;\n      // Do not support complete HTML when interrupting.\n      return self.interrupt && !self.parser.lazy[self.now().line] ? nok(code) : closingTag ? completeClosingTagAfter(code) : completeAttributeNameBefore(code);\n    }\n\n    // ASCII alphanumerical and `-`.\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code);\n      buffer += String.fromCharCode(code);\n      return tagName;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After closing slash of a basic tag name.\n   *\n   * ```markdown\n   * > | <div/>\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function basicSelfClosing(code) {\n    if (code === 62) {\n      effects.consume(code);\n      // // Do not form containers.\n      // tokenizer.concrete = true\n      return self.interrupt ? ok : continuation;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After closing slash of a complete tag name.\n   *\n   * ```markdown\n   * > | <x/>\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeClosingTagAfter(code) {\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return completeClosingTagAfter;\n    }\n    return completeEnd(code);\n  }\n\n  /**\n   * At an attribute name.\n   *\n   * At first, this state is used after a complete tag name, after whitespace,\n   * where it expects optional attributes or the end of the tag.\n   * It is also reused after attributes, when expecting more optional\n   * attributes.\n   *\n   * ```markdown\n   * > | <a />\n   *        ^\n   * > | <a :b>\n   *        ^\n   * > | <a _b>\n   *        ^\n   * > | <a b>\n   *        ^\n   * > | <a >\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeAttributeNameBefore(code) {\n    if (code === 47) {\n      effects.consume(code);\n      return completeEnd;\n    }\n\n    // ASCII alphanumerical and `:` and `_`.\n    if (code === 58 || code === 95 || asciiAlpha(code)) {\n      effects.consume(code);\n      return completeAttributeName;\n    }\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return completeAttributeNameBefore;\n    }\n    return completeEnd(code);\n  }\n\n  /**\n   * In attribute name.\n   *\n   * ```markdown\n   * > | <a :b>\n   *         ^\n   * > | <a _b>\n   *         ^\n   * > | <a b>\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeAttributeName(code) {\n    // ASCII alphanumerical and `-`, `.`, `:`, and `_`.\n    if (code === 45 || code === 46 || code === 58 || code === 95 || asciiAlphanumeric(code)) {\n      effects.consume(code);\n      return completeAttributeName;\n    }\n    return completeAttributeNameAfter(code);\n  }\n\n  /**\n   * After attribute name, at an optional initializer, the end of the tag, or\n   * whitespace.\n   *\n   * ```markdown\n   * > | <a b>\n   *         ^\n   * > | <a b=c>\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeAttributeNameAfter(code) {\n    if (code === 61) {\n      effects.consume(code);\n      return completeAttributeValueBefore;\n    }\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return completeAttributeNameAfter;\n    }\n    return completeAttributeNameBefore(code);\n  }\n\n  /**\n   * Before unquoted, double quoted, or single quoted attribute value, allowing\n   * whitespace.\n   *\n   * ```markdown\n   * > | <a b=c>\n   *          ^\n   * > | <a b=\"c\">\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeAttributeValueBefore(code) {\n    if (code === null || code === 60 || code === 61 || code === 62 || code === 96) {\n      return nok(code);\n    }\n    if (code === 34 || code === 39) {\n      effects.consume(code);\n      markerB = code;\n      return completeAttributeValueQuoted;\n    }\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return completeAttributeValueBefore;\n    }\n    return completeAttributeValueUnquoted(code);\n  }\n\n  /**\n   * In double or single quoted attribute value.\n   *\n   * ```markdown\n   * > | <a b=\"c\">\n   *           ^\n   * > | <a b='c'>\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeAttributeValueQuoted(code) {\n    if (code === markerB) {\n      effects.consume(code);\n      markerB = null;\n      return completeAttributeValueQuotedAfter;\n    }\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return completeAttributeValueQuoted;\n  }\n\n  /**\n   * In unquoted attribute value.\n   *\n   * ```markdown\n   * > | <a b=c>\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeAttributeValueUnquoted(code) {\n    if (code === null || code === 34 || code === 39 || code === 47 || code === 60 || code === 61 || code === 62 || code === 96 || markdownLineEndingOrSpace(code)) {\n      return completeAttributeNameAfter(code);\n    }\n    effects.consume(code);\n    return completeAttributeValueUnquoted;\n  }\n\n  /**\n   * After double or single quoted attribute value, before whitespace or the\n   * end of the tag.\n   *\n   * ```markdown\n   * > | <a b=\"c\">\n   *            ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeAttributeValueQuotedAfter(code) {\n    if (code === 47 || code === 62 || markdownSpace(code)) {\n      return completeAttributeNameBefore(code);\n    }\n    return nok(code);\n  }\n\n  /**\n   * In certain circumstances of a complete tag where only an `>` is allowed.\n   *\n   * ```markdown\n   * > | <a b=\"c\">\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeEnd(code) {\n    if (code === 62) {\n      effects.consume(code);\n      return completeAfter;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `>` in a complete tag.\n   *\n   * ```markdown\n   * > | <x>\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function completeAfter(code) {\n    if (code === null || markdownLineEnding(code)) {\n      // // Do not form containers.\n      // tokenizer.concrete = true\n      return continuation(code);\n    }\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return completeAfter;\n    }\n    return nok(code);\n  }\n\n  /**\n   * In continuation of any HTML kind.\n   *\n   * ```markdown\n   * > | <!--xxx-->\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuation(code) {\n    if (code === 45 && marker === 2) {\n      effects.consume(code);\n      return continuationCommentInside;\n    }\n    if (code === 60 && marker === 1) {\n      effects.consume(code);\n      return continuationRawTagOpen;\n    }\n    if (code === 62 && marker === 4) {\n      effects.consume(code);\n      return continuationClose;\n    }\n    if (code === 63 && marker === 3) {\n      effects.consume(code);\n      return continuationDeclarationInside;\n    }\n    if (code === 93 && marker === 5) {\n      effects.consume(code);\n      return continuationCdataInside;\n    }\n    if (markdownLineEnding(code) && (marker === 6 || marker === 7)) {\n      effects.exit('htmlFlowData');\n      return effects.check(blankLineBefore, continuationAfter, continuationStart)(code);\n    }\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('htmlFlowData');\n      return continuationStart(code);\n    }\n    effects.consume(code);\n    return continuation;\n  }\n\n  /**\n   * In continuation, at eol.\n   *\n   * ```markdown\n   * > | <x>\n   *        ^\n   *   | asd\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationStart(code) {\n    return effects.check(nonLazyContinuationStart, continuationStartNonLazy, continuationAfter)(code);\n  }\n\n  /**\n   * In continuation, at eol, before non-lazy content.\n   *\n   * ```markdown\n   * > | <x>\n   *        ^\n   *   | asd\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationStartNonLazy(code) {\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return continuationBefore;\n  }\n\n  /**\n   * In continuation, before non-lazy content.\n   *\n   * ```markdown\n   *   | <x>\n   * > | asd\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return continuationStart(code);\n    }\n    effects.enter('htmlFlowData');\n    return continuation(code);\n  }\n\n  /**\n   * In comment continuation, after one `-`, expecting another.\n   *\n   * ```markdown\n   * > | <!--xxx-->\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationCommentInside(code) {\n    if (code === 45) {\n      effects.consume(code);\n      return continuationDeclarationInside;\n    }\n    return continuation(code);\n  }\n\n  /**\n   * In raw continuation, after `<`, at `/`.\n   *\n   * ```markdown\n   * > | <script>console.log(1)</script>\n   *                            ^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationRawTagOpen(code) {\n    if (code === 47) {\n      effects.consume(code);\n      buffer = '';\n      return continuationRawEndTag;\n    }\n    return continuation(code);\n  }\n\n  /**\n   * In raw continuation, after `</`, in a raw tag name.\n   *\n   * ```markdown\n   * > | <script>console.log(1)</script>\n   *                             ^^^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationRawEndTag(code) {\n    if (code === 62) {\n      const name = buffer.toLowerCase();\n      if (htmlRawNames.includes(name)) {\n        effects.consume(code);\n        return continuationClose;\n      }\n      return continuation(code);\n    }\n    if (asciiAlpha(code) && buffer.length < 8) {\n      effects.consume(code);\n      // @ts-expect-error: not null.\n      buffer += String.fromCharCode(code);\n      return continuationRawEndTag;\n    }\n    return continuation(code);\n  }\n\n  /**\n   * In cdata continuation, after `]`, expecting `]>`.\n   *\n   * ```markdown\n   * > | <![CDATA[>&<]]>\n   *                  ^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationCdataInside(code) {\n    if (code === 93) {\n      effects.consume(code);\n      return continuationDeclarationInside;\n    }\n    return continuation(code);\n  }\n\n  /**\n   * In declaration or instruction continuation, at `>`.\n   *\n   * ```markdown\n   * > | <!-->\n   *         ^\n   * > | <?>\n   *       ^\n   * > | <!q>\n   *        ^\n   * > | <!--ab-->\n   *             ^\n   * > | <![CDATA[>&<]]>\n   *                   ^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationDeclarationInside(code) {\n    if (code === 62) {\n      effects.consume(code);\n      return continuationClose;\n    }\n\n    // More dashes.\n    if (code === 45 && marker === 2) {\n      effects.consume(code);\n      return continuationDeclarationInside;\n    }\n    return continuation(code);\n  }\n\n  /**\n   * In closed continuation: everything we get until the eol/eof is part of it.\n   *\n   * ```markdown\n   * > | <!doctype>\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationClose(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('htmlFlowData');\n      return continuationAfter(code);\n    }\n    effects.consume(code);\n    return continuationClose;\n  }\n\n  /**\n   * Done.\n   *\n   * ```markdown\n   * > | <!doctype>\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function continuationAfter(code) {\n    effects.exit('htmlFlow');\n    // // Feel free to interrupt.\n    // tokenizer.interrupt = false\n    // // No longer concrete.\n    // tokenizer.concrete = false\n    return ok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeNonLazyContinuationStart(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   * At eol, before continuation.\n   *\n   * ```markdown\n   * > | * ```js\n   *            ^\n   *   | b\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding');\n      effects.consume(code);\n      effects.exit('lineEnding');\n      return after;\n    }\n    return nok(code);\n  }\n\n  /**\n   * A continuation.\n   *\n   * ```markdown\n   *   | * ```js\n   * > | b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return self.parser.lazy[self.now().line] ? nok(code) : ok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlankLineBefore(effects, ok, nok) {\n  return start;\n\n  /**\n   * Before eol, expecting blank line.\n   *\n   * ```markdown\n   * > | <div>\n   *          ^\n   *   |\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return effects.attempt(blankLine, ok, nok);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nconst nonLazyContinuation = {\n  tokenize: tokenizeNonLazyContinuation,\n  partial: true\n};\n\n/** @type {Construct} */\nexport const codeFenced = {\n  name: 'codeFenced',\n  tokenize: tokenizeCodeFenced,\n  concrete: true\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeFenced(effects, ok, nok) {\n  const self = this;\n  /** @type {Construct} */\n  const closeStart = {\n    tokenize: tokenizeCloseStart,\n    partial: true\n  };\n  let initialPrefix = 0;\n  let sizeOpen = 0;\n  /** @type {NonNullable<Code>} */\n  let marker;\n  return start;\n\n  /**\n   * Start of code.\n   *\n   * ```markdown\n   * > | ~~~js\n   *     ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse whitespace like `markdown-rs`.\n    return beforeSequenceOpen(code);\n  }\n\n  /**\n   * In opening fence, after prefix, at sequence.\n   *\n   * ```markdown\n   * > | ~~~js\n   *     ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeSequenceOpen(code) {\n    const tail = self.events[self.events.length - 1];\n    initialPrefix = tail && tail[1].type === 'linePrefix' ? tail[2].sliceSerialize(tail[1], true).length : 0;\n    marker = code;\n    effects.enter('codeFenced');\n    effects.enter('codeFencedFence');\n    effects.enter('codeFencedFenceSequence');\n    return sequenceOpen(code);\n  }\n\n  /**\n   * In opening fence sequence.\n   *\n   * ```markdown\n   * > | ~~~js\n   *      ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === marker) {\n      sizeOpen++;\n      effects.consume(code);\n      return sequenceOpen;\n    }\n    if (sizeOpen < 3) {\n      return nok(code);\n    }\n    effects.exit('codeFencedFenceSequence');\n    return markdownSpace(code) ? factorySpace(effects, infoBefore, 'whitespace')(code) : infoBefore(code);\n  }\n\n  /**\n   * In opening fence, after the sequence (and optional whitespace), before info.\n   *\n   * ```markdown\n   * > | ~~~js\n   *        ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function infoBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFencedFence');\n      return self.interrupt ? ok(code) : effects.check(nonLazyContinuation, atNonLazyBreak, after)(code);\n    }\n    effects.enter('codeFencedFenceInfo');\n    effects.enter('chunkString', {\n      contentType: 'string'\n    });\n    return info(code);\n  }\n\n  /**\n   * In info.\n   *\n   * ```markdown\n   * > | ~~~js\n   *        ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function info(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString');\n      effects.exit('codeFencedFenceInfo');\n      return infoBefore(code);\n    }\n    if (markdownSpace(code)) {\n      effects.exit('chunkString');\n      effects.exit('codeFencedFenceInfo');\n      return factorySpace(effects, metaBefore, 'whitespace')(code);\n    }\n    if (code === 96 && code === marker) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return info;\n  }\n\n  /**\n   * In opening fence, after info and whitespace, before meta.\n   *\n   * ```markdown\n   * > | ~~~js eval\n   *           ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function metaBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return infoBefore(code);\n    }\n    effects.enter('codeFencedFenceMeta');\n    effects.enter('chunkString', {\n      contentType: 'string'\n    });\n    return meta(code);\n  }\n\n  /**\n   * In meta.\n   *\n   * ```markdown\n   * > | ~~~js eval\n   *           ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function meta(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString');\n      effects.exit('codeFencedFenceMeta');\n      return infoBefore(code);\n    }\n    if (code === 96 && code === marker) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return meta;\n  }\n\n  /**\n   * At eol/eof in code, before a non-lazy closing fence or content.\n   *\n   * ```markdown\n   * > | ~~~js\n   *          ^\n   * > | alert(1)\n   *             ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function atNonLazyBreak(code) {\n    return effects.attempt(closeStart, after, contentBefore)(code);\n  }\n\n  /**\n   * Before code content, not a closing fence, at eol.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *             ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentBefore(code) {\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return contentStart;\n  }\n\n  /**\n   * Before code content, not a closing fence.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentStart(code) {\n    return initialPrefix > 0 && markdownSpace(code) ? factorySpace(effects, beforeContentChunk, 'linePrefix', initialPrefix + 1)(code) : beforeContentChunk(code);\n  }\n\n  /**\n   * Before code content, after optional prefix.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeContentChunk(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return effects.check(nonLazyContinuation, atNonLazyBreak, after)(code);\n    }\n    effects.enter('codeFlowValue');\n    return contentChunk(code);\n  }\n\n  /**\n   * In code content.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^^^^^^^^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentChunk(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue');\n      return beforeContentChunk(code);\n    }\n    effects.consume(code);\n    return contentChunk;\n  }\n\n  /**\n   * After code.\n   *\n   * ```markdown\n   *   | ~~~js\n   *   | alert(1)\n   * > | ~~~\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    effects.exit('codeFenced');\n    return ok(code);\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Tokenizer}\n   */\n  function tokenizeCloseStart(effects, ok, nok) {\n    let size = 0;\n    return startBefore;\n\n    /**\n     *\n     *\n     * @type {State}\n     */\n    function startBefore(code) {\n      effects.enter('lineEnding');\n      effects.consume(code);\n      effects.exit('lineEnding');\n      return start;\n    }\n\n    /**\n     * Before closing fence, at optional whitespace.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function start(code) {\n      // Always populated by defaults.\n\n      // To do: `enter` here or in next state?\n      effects.enter('codeFencedFence');\n      return markdownSpace(code) ? factorySpace(effects, beforeSequenceClose, 'linePrefix', self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code) : beforeSequenceClose(code);\n    }\n\n    /**\n     * In closing fence, after optional whitespace, at sequence.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function beforeSequenceClose(code) {\n      if (code === marker) {\n        effects.enter('codeFencedFenceSequence');\n        return sequenceClose(code);\n      }\n      return nok(code);\n    }\n\n    /**\n     * In closing fence sequence.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function sequenceClose(code) {\n      if (code === marker) {\n        size++;\n        effects.consume(code);\n        return sequenceClose;\n      }\n      if (size >= sizeOpen) {\n        effects.exit('codeFencedFenceSequence');\n        return markdownSpace(code) ? factorySpace(effects, sequenceCloseAfter, 'whitespace')(code) : sequenceCloseAfter(code);\n      }\n      return nok(code);\n    }\n\n    /**\n     * After closing fence sequence, after optional whitespace.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *        ^\n     * ```\n     *\n     * @type {State}\n     */\n    function sequenceCloseAfter(code) {\n      if (code === null || markdownLineEnding(code)) {\n        effects.exit('codeFencedFence');\n        return ok(code);\n      }\n      return nok(code);\n    }\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeNonLazyContinuation(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === null) {\n      return nok(code);\n    }\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return lineStart;\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function lineStart(code) {\n    return self.parser.lazy[self.now().line] ? nok(code) : ok(code);\n  }\n}","/**\n * Map of named character references.\n *\n * @type {Record<string, string>}\n */\nexport const characterEntities = {\n  AElig: '',\n  AMP: '&',\n  Aacute: '',\n  Abreve: '',\n  Acirc: '',\n  Acy: '',\n  Afr: '',\n  Agrave: '',\n  Alpha: '',\n  Amacr: '',\n  And: '',\n  Aogon: '',\n  Aopf: '',\n  ApplyFunction: '',\n  Aring: '',\n  Ascr: '',\n  Assign: '',\n  Atilde: '',\n  Auml: '',\n  Backslash: '',\n  Barv: '',\n  Barwed: '',\n  Bcy: '',\n  Because: '',\n  Bernoullis: '',\n  Beta: '',\n  Bfr: '',\n  Bopf: '',\n  Breve: '',\n  Bscr: '',\n  Bumpeq: '',\n  CHcy: '',\n  COPY: '',\n  Cacute: '',\n  Cap: '',\n  CapitalDifferentialD: '',\n  Cayleys: '',\n  Ccaron: '',\n  Ccedil: '',\n  Ccirc: '',\n  Cconint: '',\n  Cdot: '',\n  Cedilla: '',\n  CenterDot: '',\n  Cfr: '',\n  Chi: '',\n  CircleDot: '',\n  CircleMinus: '',\n  CirclePlus: '',\n  CircleTimes: '',\n  ClockwiseContourIntegral: '',\n  CloseCurlyDoubleQuote: '',\n  CloseCurlyQuote: '',\n  Colon: '',\n  Colone: '',\n  Congruent: '',\n  Conint: '',\n  ContourIntegral: '',\n  Copf: '',\n  Coproduct: '',\n  CounterClockwiseContourIntegral: '',\n  Cross: '',\n  Cscr: '',\n  Cup: '',\n  CupCap: '',\n  DD: '',\n  DDotrahd: '',\n  DJcy: '',\n  DScy: '',\n  DZcy: '',\n  Dagger: '',\n  Darr: '',\n  Dashv: '',\n  Dcaron: '',\n  Dcy: '',\n  Del: '',\n  Delta: '',\n  Dfr: '',\n  DiacriticalAcute: '',\n  DiacriticalDot: '',\n  DiacriticalDoubleAcute: '',\n  DiacriticalGrave: '`',\n  DiacriticalTilde: '',\n  Diamond: '',\n  DifferentialD: '',\n  Dopf: '',\n  Dot: '',\n  DotDot: '',\n  DotEqual: '',\n  DoubleContourIntegral: '',\n  DoubleDot: '',\n  DoubleDownArrow: '',\n  DoubleLeftArrow: '',\n  DoubleLeftRightArrow: '',\n  DoubleLeftTee: '',\n  DoubleLongLeftArrow: '',\n  DoubleLongLeftRightArrow: '',\n  DoubleLongRightArrow: '',\n  DoubleRightArrow: '',\n  DoubleRightTee: '',\n  DoubleUpArrow: '',\n  DoubleUpDownArrow: '',\n  DoubleVerticalBar: '',\n  DownArrow: '',\n  DownArrowBar: '',\n  DownArrowUpArrow: '',\n  DownBreve: '',\n  DownLeftRightVector: '',\n  DownLeftTeeVector: '',\n  DownLeftVector: '',\n  DownLeftVectorBar: '',\n  DownRightTeeVector: '',\n  DownRightVector: '',\n  DownRightVectorBar: '',\n  DownTee: '',\n  DownTeeArrow: '',\n  Downarrow: '',\n  Dscr: '',\n  Dstrok: '',\n  ENG: '',\n  ETH: '',\n  Eacute: '',\n  Ecaron: '',\n  Ecirc: '',\n  Ecy: '',\n  Edot: '',\n  Efr: '',\n  Egrave: '',\n  Element: '',\n  Emacr: '',\n  EmptySmallSquare: '',\n  EmptyVerySmallSquare: '',\n  Eogon: '',\n  Eopf: '',\n  Epsilon: '',\n  Equal: '',\n  EqualTilde: '',\n  Equilibrium: '',\n  Escr: '',\n  Esim: '',\n  Eta: '',\n  Euml: '',\n  Exists: '',\n  ExponentialE: '',\n  Fcy: '',\n  Ffr: '',\n  FilledSmallSquare: '',\n  FilledVerySmallSquare: '',\n  Fopf: '',\n  ForAll: '',\n  Fouriertrf: '',\n  Fscr: '',\n  GJcy: '',\n  GT: '>',\n  Gamma: '',\n  Gammad: '',\n  Gbreve: '',\n  Gcedil: '',\n  Gcirc: '',\n  Gcy: '',\n  Gdot: '',\n  Gfr: '',\n  Gg: '',\n  Gopf: '',\n  GreaterEqual: '',\n  GreaterEqualLess: '',\n  GreaterFullEqual: '',\n  GreaterGreater: '',\n  GreaterLess: '',\n  GreaterSlantEqual: '',\n  GreaterTilde: '',\n  Gscr: '',\n  Gt: '',\n  HARDcy: '',\n  Hacek: '',\n  Hat: '^',\n  Hcirc: '',\n  Hfr: '',\n  HilbertSpace: '',\n  Hopf: '',\n  HorizontalLine: '',\n  Hscr: '',\n  Hstrok: '',\n  HumpDownHump: '',\n  HumpEqual: '',\n  IEcy: '',\n  IJlig: '',\n  IOcy: '',\n  Iacute: '',\n  Icirc: '',\n  Icy: '',\n  Idot: '',\n  Ifr: '',\n  Igrave: '',\n  Im: '',\n  Imacr: '',\n  ImaginaryI: '',\n  Implies: '',\n  Int: '',\n  Integral: '',\n  Intersection: '',\n  InvisibleComma: '',\n  InvisibleTimes: '',\n  Iogon: '',\n  Iopf: '',\n  Iota: '',\n  Iscr: '',\n  Itilde: '',\n  Iukcy: '',\n  Iuml: '',\n  Jcirc: '',\n  Jcy: '',\n  Jfr: '',\n  Jopf: '',\n  Jscr: '',\n  Jsercy: '',\n  Jukcy: '',\n  KHcy: '',\n  KJcy: '',\n  Kappa: '',\n  Kcedil: '',\n  Kcy: '',\n  Kfr: '',\n  Kopf: '',\n  Kscr: '',\n  LJcy: '',\n  LT: '<',\n  Lacute: '',\n  Lambda: '',\n  Lang: '',\n  Laplacetrf: '',\n  Larr: '',\n  Lcaron: '',\n  Lcedil: '',\n  Lcy: '',\n  LeftAngleBracket: '',\n  LeftArrow: '',\n  LeftArrowBar: '',\n  LeftArrowRightArrow: '',\n  LeftCeiling: '',\n  LeftDoubleBracket: '',\n  LeftDownTeeVector: '',\n  LeftDownVector: '',\n  LeftDownVectorBar: '',\n  LeftFloor: '',\n  LeftRightArrow: '',\n  LeftRightVector: '',\n  LeftTee: '',\n  LeftTeeArrow: '',\n  LeftTeeVector: '',\n  LeftTriangle: '',\n  LeftTriangleBar: '',\n  LeftTriangleEqual: '',\n  LeftUpDownVector: '',\n  LeftUpTeeVector: '',\n  LeftUpVector: '',\n  LeftUpVectorBar: '',\n  LeftVector: '',\n  LeftVectorBar: '',\n  Leftarrow: '',\n  Leftrightarrow: '',\n  LessEqualGreater: '',\n  LessFullEqual: '',\n  LessGreater: '',\n  LessLess: '',\n  LessSlantEqual: '',\n  LessTilde: '',\n  Lfr: '',\n  Ll: '',\n  Lleftarrow: '',\n  Lmidot: '',\n  LongLeftArrow: '',\n  LongLeftRightArrow: '',\n  LongRightArrow: '',\n  Longleftarrow: '',\n  Longleftrightarrow: '',\n  Longrightarrow: '',\n  Lopf: '',\n  LowerLeftArrow: '',\n  LowerRightArrow: '',\n  Lscr: '',\n  Lsh: '',\n  Lstrok: '',\n  Lt: '',\n  Map: '',\n  Mcy: '',\n  MediumSpace: '',\n  Mellintrf: '',\n  Mfr: '',\n  MinusPlus: '',\n  Mopf: '',\n  Mscr: '',\n  Mu: '',\n  NJcy: '',\n  Nacute: '',\n  Ncaron: '',\n  Ncedil: '',\n  Ncy: '',\n  NegativeMediumSpace: '',\n  NegativeThickSpace: '',\n  NegativeThinSpace: '',\n  NegativeVeryThinSpace: '',\n  NestedGreaterGreater: '',\n  NestedLessLess: '',\n  NewLine: '\\n',\n  Nfr: '',\n  NoBreak: '',\n  NonBreakingSpace: '',\n  Nopf: '',\n  Not: '',\n  NotCongruent: '',\n  NotCupCap: '',\n  NotDoubleVerticalBar: '',\n  NotElement: '',\n  NotEqual: '',\n  NotEqualTilde: '',\n  NotExists: '',\n  NotGreater: '',\n  NotGreaterEqual: '',\n  NotGreaterFullEqual: '',\n  NotGreaterGreater: '',\n  NotGreaterLess: '',\n  NotGreaterSlantEqual: '',\n  NotGreaterTilde: '',\n  NotHumpDownHump: '',\n  NotHumpEqual: '',\n  NotLeftTriangle: '',\n  NotLeftTriangleBar: '',\n  NotLeftTriangleEqual: '',\n  NotLess: '',\n  NotLessEqual: '',\n  NotLessGreater: '',\n  NotLessLess: '',\n  NotLessSlantEqual: '',\n  NotLessTilde: '',\n  NotNestedGreaterGreater: '',\n  NotNestedLessLess: '',\n  NotPrecedes: '',\n  NotPrecedesEqual: '',\n  NotPrecedesSlantEqual: '',\n  NotReverseElement: '',\n  NotRightTriangle: '',\n  NotRightTriangleBar: '',\n  NotRightTriangleEqual: '',\n  NotSquareSubset: '',\n  NotSquareSubsetEqual: '',\n  NotSquareSuperset: '',\n  NotSquareSupersetEqual: '',\n  NotSubset: '',\n  NotSubsetEqual: '',\n  NotSucceeds: '',\n  NotSucceedsEqual: '',\n  NotSucceedsSlantEqual: '',\n  NotSucceedsTilde: '',\n  NotSuperset: '',\n  NotSupersetEqual: '',\n  NotTilde: '',\n  NotTildeEqual: '',\n  NotTildeFullEqual: '',\n  NotTildeTilde: '',\n  NotVerticalBar: '',\n  Nscr: '',\n  Ntilde: '',\n  Nu: '',\n  OElig: '',\n  Oacute: '',\n  Ocirc: '',\n  Ocy: '',\n  Odblac: '',\n  Ofr: '',\n  Ograve: '',\n  Omacr: '',\n  Omega: '',\n  Omicron: '',\n  Oopf: '',\n  OpenCurlyDoubleQuote: '',\n  OpenCurlyQuote: '',\n  Or: '',\n  Oscr: '',\n  Oslash: '',\n  Otilde: '',\n  Otimes: '',\n  Ouml: '',\n  OverBar: '',\n  OverBrace: '',\n  OverBracket: '',\n  OverParenthesis: '',\n  PartialD: '',\n  Pcy: '',\n  Pfr: '',\n  Phi: '',\n  Pi: '',\n  PlusMinus: '',\n  Poincareplane: '',\n  Popf: '',\n  Pr: '',\n  Precedes: '',\n  PrecedesEqual: '',\n  PrecedesSlantEqual: '',\n  PrecedesTilde: '',\n  Prime: '',\n  Product: '',\n  Proportion: '',\n  Proportional: '',\n  Pscr: '',\n  Psi: '',\n  QUOT: '\"',\n  Qfr: '',\n  Qopf: '',\n  Qscr: '',\n  RBarr: '',\n  REG: '',\n  Racute: '',\n  Rang: '',\n  Rarr: '',\n  Rarrtl: '',\n  Rcaron: '',\n  Rcedil: '',\n  Rcy: '',\n  Re: '',\n  ReverseElement: '',\n  ReverseEquilibrium: '',\n  ReverseUpEquilibrium: '',\n  Rfr: '',\n  Rho: '',\n  RightAngleBracket: '',\n  RightArrow: '',\n  RightArrowBar: '',\n  RightArrowLeftArrow: '',\n  RightCeiling: '',\n  RightDoubleBracket: '',\n  RightDownTeeVector: '',\n  RightDownVector: '',\n  RightDownVectorBar: '',\n  RightFloor: '',\n  RightTee: '',\n  RightTeeArrow: '',\n  RightTeeVector: '',\n  RightTriangle: '',\n  RightTriangleBar: '',\n  RightTriangleEqual: '',\n  RightUpDownVector: '',\n  RightUpTeeVector: '',\n  RightUpVector: '',\n  RightUpVectorBar: '',\n  RightVector: '',\n  RightVectorBar: '',\n  Rightarrow: '',\n  Ropf: '',\n  RoundImplies: '',\n  Rrightarrow: '',\n  Rscr: '',\n  Rsh: '',\n  RuleDelayed: '',\n  SHCHcy: '',\n  SHcy: '',\n  SOFTcy: '',\n  Sacute: '',\n  Sc: '',\n  Scaron: '',\n  Scedil: '',\n  Scirc: '',\n  Scy: '',\n  Sfr: '',\n  ShortDownArrow: '',\n  ShortLeftArrow: '',\n  ShortRightArrow: '',\n  ShortUpArrow: '',\n  Sigma: '',\n  SmallCircle: '',\n  Sopf: '',\n  Sqrt: '',\n  Square: '',\n  SquareIntersection: '',\n  SquareSubset: '',\n  SquareSubsetEqual: '',\n  SquareSuperset: '',\n  SquareSupersetEqual: '',\n  SquareUnion: '',\n  Sscr: '',\n  Star: '',\n  Sub: '',\n  Subset: '',\n  SubsetEqual: '',\n  Succeeds: '',\n  SucceedsEqual: '',\n  SucceedsSlantEqual: '',\n  SucceedsTilde: '',\n  SuchThat: '',\n  Sum: '',\n  Sup: '',\n  Superset: '',\n  SupersetEqual: '',\n  Supset: '',\n  THORN: '',\n  TRADE: '',\n  TSHcy: '',\n  TScy: '',\n  Tab: '\\t',\n  Tau: '',\n  Tcaron: '',\n  Tcedil: '',\n  Tcy: '',\n  Tfr: '',\n  Therefore: '',\n  Theta: '',\n  ThickSpace: '',\n  ThinSpace: '',\n  Tilde: '',\n  TildeEqual: '',\n  TildeFullEqual: '',\n  TildeTilde: '',\n  Topf: '',\n  TripleDot: '',\n  Tscr: '',\n  Tstrok: '',\n  Uacute: '',\n  Uarr: '',\n  Uarrocir: '',\n  Ubrcy: '',\n  Ubreve: '',\n  Ucirc: '',\n  Ucy: '',\n  Udblac: '',\n  Ufr: '',\n  Ugrave: '',\n  Umacr: '',\n  UnderBar: '_',\n  UnderBrace: '',\n  UnderBracket: '',\n  UnderParenthesis: '',\n  Union: '',\n  UnionPlus: '',\n  Uogon: '',\n  Uopf: '',\n  UpArrow: '',\n  UpArrowBar: '',\n  UpArrowDownArrow: '',\n  UpDownArrow: '',\n  UpEquilibrium: '',\n  UpTee: '',\n  UpTeeArrow: '',\n  Uparrow: '',\n  Updownarrow: '',\n  UpperLeftArrow: '',\n  UpperRightArrow: '',\n  Upsi: '',\n  Upsilon: '',\n  Uring: '',\n  Uscr: '',\n  Utilde: '',\n  Uuml: '',\n  VDash: '',\n  Vbar: '',\n  Vcy: '',\n  Vdash: '',\n  Vdashl: '',\n  Vee: '',\n  Verbar: '',\n  Vert: '',\n  VerticalBar: '',\n  VerticalLine: '|',\n  VerticalSeparator: '',\n  VerticalTilde: '',\n  VeryThinSpace: '',\n  Vfr: '',\n  Vopf: '',\n  Vscr: '',\n  Vvdash: '',\n  Wcirc: '',\n  Wedge: '',\n  Wfr: '',\n  Wopf: '',\n  Wscr: '',\n  Xfr: '',\n  Xi: '',\n  Xopf: '',\n  Xscr: '',\n  YAcy: '',\n  YIcy: '',\n  YUcy: '',\n  Yacute: '',\n  Ycirc: '',\n  Ycy: '',\n  Yfr: '',\n  Yopf: '',\n  Yscr: '',\n  Yuml: '',\n  ZHcy: '',\n  Zacute: '',\n  Zcaron: '',\n  Zcy: '',\n  Zdot: '',\n  ZeroWidthSpace: '',\n  Zeta: '',\n  Zfr: '',\n  Zopf: '',\n  Zscr: '',\n  aacute: '',\n  abreve: '',\n  ac: '',\n  acE: '',\n  acd: '',\n  acirc: '',\n  acute: '',\n  acy: '',\n  aelig: '',\n  af: '',\n  afr: '',\n  agrave: '',\n  alefsym: '',\n  aleph: '',\n  alpha: '',\n  amacr: '',\n  amalg: '',\n  amp: '&',\n  and: '',\n  andand: '',\n  andd: '',\n  andslope: '',\n  andv: '',\n  ang: '',\n  ange: '',\n  angle: '',\n  angmsd: '',\n  angmsdaa: '',\n  angmsdab: '',\n  angmsdac: '',\n  angmsdad: '',\n  angmsdae: '',\n  angmsdaf: '',\n  angmsdag: '',\n  angmsdah: '',\n  angrt: '',\n  angrtvb: '',\n  angrtvbd: '',\n  angsph: '',\n  angst: '',\n  angzarr: '',\n  aogon: '',\n  aopf: '',\n  ap: '',\n  apE: '',\n  apacir: '',\n  ape: '',\n  apid: '',\n  apos: \"'\",\n  approx: '',\n  approxeq: '',\n  aring: '',\n  ascr: '',\n  ast: '*',\n  asymp: '',\n  asympeq: '',\n  atilde: '',\n  auml: '',\n  awconint: '',\n  awint: '',\n  bNot: '',\n  backcong: '',\n  backepsilon: '',\n  backprime: '',\n  backsim: '',\n  backsimeq: '',\n  barvee: '',\n  barwed: '',\n  barwedge: '',\n  bbrk: '',\n  bbrktbrk: '',\n  bcong: '',\n  bcy: '',\n  bdquo: '',\n  becaus: '',\n  because: '',\n  bemptyv: '',\n  bepsi: '',\n  bernou: '',\n  beta: '',\n  beth: '',\n  between: '',\n  bfr: '',\n  bigcap: '',\n  bigcirc: '',\n  bigcup: '',\n  bigodot: '',\n  bigoplus: '',\n  bigotimes: '',\n  bigsqcup: '',\n  bigstar: '',\n  bigtriangledown: '',\n  bigtriangleup: '',\n  biguplus: '',\n  bigvee: '',\n  bigwedge: '',\n  bkarow: '',\n  blacklozenge: '',\n  blacksquare: '',\n  blacktriangle: '',\n  blacktriangledown: '',\n  blacktriangleleft: '',\n  blacktriangleright: '',\n  blank: '',\n  blk12: '',\n  blk14: '',\n  blk34: '',\n  block: '',\n  bne: '=',\n  bnequiv: '',\n  bnot: '',\n  bopf: '',\n  bot: '',\n  bottom: '',\n  bowtie: '',\n  boxDL: '',\n  boxDR: '',\n  boxDl: '',\n  boxDr: '',\n  boxH: '',\n  boxHD: '',\n  boxHU: '',\n  boxHd: '',\n  boxHu: '',\n  boxUL: '',\n  boxUR: '',\n  boxUl: '',\n  boxUr: '',\n  boxV: '',\n  boxVH: '',\n  boxVL: '',\n  boxVR: '',\n  boxVh: '',\n  boxVl: '',\n  boxVr: '',\n  boxbox: '',\n  boxdL: '',\n  boxdR: '',\n  boxdl: '',\n  boxdr: '',\n  boxh: '',\n  boxhD: '',\n  boxhU: '',\n  boxhd: '',\n  boxhu: '',\n  boxminus: '',\n  boxplus: '',\n  boxtimes: '',\n  boxuL: '',\n  boxuR: '',\n  boxul: '',\n  boxur: '',\n  boxv: '',\n  boxvH: '',\n  boxvL: '',\n  boxvR: '',\n  boxvh: '',\n  boxvl: '',\n  boxvr: '',\n  bprime: '',\n  breve: '',\n  brvbar: '',\n  bscr: '',\n  bsemi: '',\n  bsim: '',\n  bsime: '',\n  bsol: '\\\\',\n  bsolb: '',\n  bsolhsub: '',\n  bull: '',\n  bullet: '',\n  bump: '',\n  bumpE: '',\n  bumpe: '',\n  bumpeq: '',\n  cacute: '',\n  cap: '',\n  capand: '',\n  capbrcup: '',\n  capcap: '',\n  capcup: '',\n  capdot: '',\n  caps: '',\n  caret: '',\n  caron: '',\n  ccaps: '',\n  ccaron: '',\n  ccedil: '',\n  ccirc: '',\n  ccups: '',\n  ccupssm: '',\n  cdot: '',\n  cedil: '',\n  cemptyv: '',\n  cent: '',\n  centerdot: '',\n  cfr: '',\n  chcy: '',\n  check: '',\n  checkmark: '',\n  chi: '',\n  cir: '',\n  cirE: '',\n  circ: '',\n  circeq: '',\n  circlearrowleft: '',\n  circlearrowright: '',\n  circledR: '',\n  circledS: '',\n  circledast: '',\n  circledcirc: '',\n  circleddash: '',\n  cire: '',\n  cirfnint: '',\n  cirmid: '',\n  cirscir: '',\n  clubs: '',\n  clubsuit: '',\n  colon: ':',\n  colone: '',\n  coloneq: '',\n  comma: ',',\n  commat: '@',\n  comp: '',\n  compfn: '',\n  complement: '',\n  complexes: '',\n  cong: '',\n  congdot: '',\n  conint: '',\n  copf: '',\n  coprod: '',\n  copy: '',\n  copysr: '',\n  crarr: '',\n  cross: '',\n  cscr: '',\n  csub: '',\n  csube: '',\n  csup: '',\n  csupe: '',\n  ctdot: '',\n  cudarrl: '',\n  cudarrr: '',\n  cuepr: '',\n  cuesc: '',\n  cularr: '',\n  cularrp: '',\n  cup: '',\n  cupbrcap: '',\n  cupcap: '',\n  cupcup: '',\n  cupdot: '',\n  cupor: '',\n  cups: '',\n  curarr: '',\n  curarrm: '',\n  curlyeqprec: '',\n  curlyeqsucc: '',\n  curlyvee: '',\n  curlywedge: '',\n  curren: '',\n  curvearrowleft: '',\n  curvearrowright: '',\n  cuvee: '',\n  cuwed: '',\n  cwconint: '',\n  cwint: '',\n  cylcty: '',\n  dArr: '',\n  dHar: '',\n  dagger: '',\n  daleth: '',\n  darr: '',\n  dash: '',\n  dashv: '',\n  dbkarow: '',\n  dblac: '',\n  dcaron: '',\n  dcy: '',\n  dd: '',\n  ddagger: '',\n  ddarr: '',\n  ddotseq: '',\n  deg: '',\n  delta: '',\n  demptyv: '',\n  dfisht: '',\n  dfr: '',\n  dharl: '',\n  dharr: '',\n  diam: '',\n  diamond: '',\n  diamondsuit: '',\n  diams: '',\n  die: '',\n  digamma: '',\n  disin: '',\n  div: '',\n  divide: '',\n  divideontimes: '',\n  divonx: '',\n  djcy: '',\n  dlcorn: '',\n  dlcrop: '',\n  dollar: '$',\n  dopf: '',\n  dot: '',\n  doteq: '',\n  doteqdot: '',\n  dotminus: '',\n  dotplus: '',\n  dotsquare: '',\n  doublebarwedge: '',\n  downarrow: '',\n  downdownarrows: '',\n  downharpoonleft: '',\n  downharpoonright: '',\n  drbkarow: '',\n  drcorn: '',\n  drcrop: '',\n  dscr: '',\n  dscy: '',\n  dsol: '',\n  dstrok: '',\n  dtdot: '',\n  dtri: '',\n  dtrif: '',\n  duarr: '',\n  duhar: '',\n  dwangle: '',\n  dzcy: '',\n  dzigrarr: '',\n  eDDot: '',\n  eDot: '',\n  eacute: '',\n  easter: '',\n  ecaron: '',\n  ecir: '',\n  ecirc: '',\n  ecolon: '',\n  ecy: '',\n  edot: '',\n  ee: '',\n  efDot: '',\n  efr: '',\n  eg: '',\n  egrave: '',\n  egs: '',\n  egsdot: '',\n  el: '',\n  elinters: '',\n  ell: '',\n  els: '',\n  elsdot: '',\n  emacr: '',\n  empty: '',\n  emptyset: '',\n  emptyv: '',\n  emsp13: '',\n  emsp14: '',\n  emsp: '',\n  eng: '',\n  ensp: '',\n  eogon: '',\n  eopf: '',\n  epar: '',\n  eparsl: '',\n  eplus: '',\n  epsi: '',\n  epsilon: '',\n  epsiv: '',\n  eqcirc: '',\n  eqcolon: '',\n  eqsim: '',\n  eqslantgtr: '',\n  eqslantless: '',\n  equals: '=',\n  equest: '',\n  equiv: '',\n  equivDD: '',\n  eqvparsl: '',\n  erDot: '',\n  erarr: '',\n  escr: '',\n  esdot: '',\n  esim: '',\n  eta: '',\n  eth: '',\n  euml: '',\n  euro: '',\n  excl: '!',\n  exist: '',\n  expectation: '',\n  exponentiale: '',\n  fallingdotseq: '',\n  fcy: '',\n  female: '',\n  ffilig: '',\n  fflig: '',\n  ffllig: '',\n  ffr: '',\n  filig: '',\n  fjlig: 'fj',\n  flat: '',\n  fllig: '',\n  fltns: '',\n  fnof: '',\n  fopf: '',\n  forall: '',\n  fork: '',\n  forkv: '',\n  fpartint: '',\n  frac12: '',\n  frac13: '',\n  frac14: '',\n  frac15: '',\n  frac16: '',\n  frac18: '',\n  frac23: '',\n  frac25: '',\n  frac34: '',\n  frac35: '',\n  frac38: '',\n  frac45: '',\n  frac56: '',\n  frac58: '',\n  frac78: '',\n  frasl: '',\n  frown: '',\n  fscr: '',\n  gE: '',\n  gEl: '',\n  gacute: '',\n  gamma: '',\n  gammad: '',\n  gap: '',\n  gbreve: '',\n  gcirc: '',\n  gcy: '',\n  gdot: '',\n  ge: '',\n  gel: '',\n  geq: '',\n  geqq: '',\n  geqslant: '',\n  ges: '',\n  gescc: '',\n  gesdot: '',\n  gesdoto: '',\n  gesdotol: '',\n  gesl: '',\n  gesles: '',\n  gfr: '',\n  gg: '',\n  ggg: '',\n  gimel: '',\n  gjcy: '',\n  gl: '',\n  glE: '',\n  gla: '',\n  glj: '',\n  gnE: '',\n  gnap: '',\n  gnapprox: '',\n  gne: '',\n  gneq: '',\n  gneqq: '',\n  gnsim: '',\n  gopf: '',\n  grave: '`',\n  gscr: '',\n  gsim: '',\n  gsime: '',\n  gsiml: '',\n  gt: '>',\n  gtcc: '',\n  gtcir: '',\n  gtdot: '',\n  gtlPar: '',\n  gtquest: '',\n  gtrapprox: '',\n  gtrarr: '',\n  gtrdot: '',\n  gtreqless: '',\n  gtreqqless: '',\n  gtrless: '',\n  gtrsim: '',\n  gvertneqq: '',\n  gvnE: '',\n  hArr: '',\n  hairsp: '',\n  half: '',\n  hamilt: '',\n  hardcy: '',\n  harr: '',\n  harrcir: '',\n  harrw: '',\n  hbar: '',\n  hcirc: '',\n  hearts: '',\n  heartsuit: '',\n  hellip: '',\n  hercon: '',\n  hfr: '',\n  hksearow: '',\n  hkswarow: '',\n  hoarr: '',\n  homtht: '',\n  hookleftarrow: '',\n  hookrightarrow: '',\n  hopf: '',\n  horbar: '',\n  hscr: '',\n  hslash: '',\n  hstrok: '',\n  hybull: '',\n  hyphen: '',\n  iacute: '',\n  ic: '',\n  icirc: '',\n  icy: '',\n  iecy: '',\n  iexcl: '',\n  iff: '',\n  ifr: '',\n  igrave: '',\n  ii: '',\n  iiiint: '',\n  iiint: '',\n  iinfin: '',\n  iiota: '',\n  ijlig: '',\n  imacr: '',\n  image: '',\n  imagline: '',\n  imagpart: '',\n  imath: '',\n  imof: '',\n  imped: '',\n  in: '',\n  incare: '',\n  infin: '',\n  infintie: '',\n  inodot: '',\n  int: '',\n  intcal: '',\n  integers: '',\n  intercal: '',\n  intlarhk: '',\n  intprod: '',\n  iocy: '',\n  iogon: '',\n  iopf: '',\n  iota: '',\n  iprod: '',\n  iquest: '',\n  iscr: '',\n  isin: '',\n  isinE: '',\n  isindot: '',\n  isins: '',\n  isinsv: '',\n  isinv: '',\n  it: '',\n  itilde: '',\n  iukcy: '',\n  iuml: '',\n  jcirc: '',\n  jcy: '',\n  jfr: '',\n  jmath: '',\n  jopf: '',\n  jscr: '',\n  jsercy: '',\n  jukcy: '',\n  kappa: '',\n  kappav: '',\n  kcedil: '',\n  kcy: '',\n  kfr: '',\n  kgreen: '',\n  khcy: '',\n  kjcy: '',\n  kopf: '',\n  kscr: '',\n  lAarr: '',\n  lArr: '',\n  lAtail: '',\n  lBarr: '',\n  lE: '',\n  lEg: '',\n  lHar: '',\n  lacute: '',\n  laemptyv: '',\n  lagran: '',\n  lambda: '',\n  lang: '',\n  langd: '',\n  langle: '',\n  lap: '',\n  laquo: '',\n  larr: '',\n  larrb: '',\n  larrbfs: '',\n  larrfs: '',\n  larrhk: '',\n  larrlp: '',\n  larrpl: '',\n  larrsim: '',\n  larrtl: '',\n  lat: '',\n  latail: '',\n  late: '',\n  lates: '',\n  lbarr: '',\n  lbbrk: '',\n  lbrace: '{',\n  lbrack: '[',\n  lbrke: '',\n  lbrksld: '',\n  lbrkslu: '',\n  lcaron: '',\n  lcedil: '',\n  lceil: '',\n  lcub: '{',\n  lcy: '',\n  ldca: '',\n  ldquo: '',\n  ldquor: '',\n  ldrdhar: '',\n  ldrushar: '',\n  ldsh: '',\n  le: '',\n  leftarrow: '',\n  leftarrowtail: '',\n  leftharpoondown: '',\n  leftharpoonup: '',\n  leftleftarrows: '',\n  leftrightarrow: '',\n  leftrightarrows: '',\n  leftrightharpoons: '',\n  leftrightsquigarrow: '',\n  leftthreetimes: '',\n  leg: '',\n  leq: '',\n  leqq: '',\n  leqslant: '',\n  les: '',\n  lescc: '',\n  lesdot: '',\n  lesdoto: '',\n  lesdotor: '',\n  lesg: '',\n  lesges: '',\n  lessapprox: '',\n  lessdot: '',\n  lesseqgtr: '',\n  lesseqqgtr: '',\n  lessgtr: '',\n  lesssim: '',\n  lfisht: '',\n  lfloor: '',\n  lfr: '',\n  lg: '',\n  lgE: '',\n  lhard: '',\n  lharu: '',\n  lharul: '',\n  lhblk: '',\n  ljcy: '',\n  ll: '',\n  llarr: '',\n  llcorner: '',\n  llhard: '',\n  lltri: '',\n  lmidot: '',\n  lmoust: '',\n  lmoustache: '',\n  lnE: '',\n  lnap: '',\n  lnapprox: '',\n  lne: '',\n  lneq: '',\n  lneqq: '',\n  lnsim: '',\n  loang: '',\n  loarr: '',\n  lobrk: '',\n  longleftarrow: '',\n  longleftrightarrow: '',\n  longmapsto: '',\n  longrightarrow: '',\n  looparrowleft: '',\n  looparrowright: '',\n  lopar: '',\n  lopf: '',\n  loplus: '',\n  lotimes: '',\n  lowast: '',\n  lowbar: '_',\n  loz: '',\n  lozenge: '',\n  lozf: '',\n  lpar: '(',\n  lparlt: '',\n  lrarr: '',\n  lrcorner: '',\n  lrhar: '',\n  lrhard: '',\n  lrm: '',\n  lrtri: '',\n  lsaquo: '',\n  lscr: '',\n  lsh: '',\n  lsim: '',\n  lsime: '',\n  lsimg: '',\n  lsqb: '[',\n  lsquo: '',\n  lsquor: '',\n  lstrok: '',\n  lt: '<',\n  ltcc: '',\n  ltcir: '',\n  ltdot: '',\n  lthree: '',\n  ltimes: '',\n  ltlarr: '',\n  ltquest: '',\n  ltrPar: '',\n  ltri: '',\n  ltrie: '',\n  ltrif: '',\n  lurdshar: '',\n  luruhar: '',\n  lvertneqq: '',\n  lvnE: '',\n  mDDot: '',\n  macr: '',\n  male: '',\n  malt: '',\n  maltese: '',\n  map: '',\n  mapsto: '',\n  mapstodown: '',\n  mapstoleft: '',\n  mapstoup: '',\n  marker: '',\n  mcomma: '',\n  mcy: '',\n  mdash: '',\n  measuredangle: '',\n  mfr: '',\n  mho: '',\n  micro: '',\n  mid: '',\n  midast: '*',\n  midcir: '',\n  middot: '',\n  minus: '',\n  minusb: '',\n  minusd: '',\n  minusdu: '',\n  mlcp: '',\n  mldr: '',\n  mnplus: '',\n  models: '',\n  mopf: '',\n  mp: '',\n  mscr: '',\n  mstpos: '',\n  mu: '',\n  multimap: '',\n  mumap: '',\n  nGg: '',\n  nGt: '',\n  nGtv: '',\n  nLeftarrow: '',\n  nLeftrightarrow: '',\n  nLl: '',\n  nLt: '',\n  nLtv: '',\n  nRightarrow: '',\n  nVDash: '',\n  nVdash: '',\n  nabla: '',\n  nacute: '',\n  nang: '',\n  nap: '',\n  napE: '',\n  napid: '',\n  napos: '',\n  napprox: '',\n  natur: '',\n  natural: '',\n  naturals: '',\n  nbsp: '',\n  nbump: '',\n  nbumpe: '',\n  ncap: '',\n  ncaron: '',\n  ncedil: '',\n  ncong: '',\n  ncongdot: '',\n  ncup: '',\n  ncy: '',\n  ndash: '',\n  ne: '',\n  neArr: '',\n  nearhk: '',\n  nearr: '',\n  nearrow: '',\n  nedot: '',\n  nequiv: '',\n  nesear: '',\n  nesim: '',\n  nexist: '',\n  nexists: '',\n  nfr: '',\n  ngE: '',\n  nge: '',\n  ngeq: '',\n  ngeqq: '',\n  ngeqslant: '',\n  nges: '',\n  ngsim: '',\n  ngt: '',\n  ngtr: '',\n  nhArr: '',\n  nharr: '',\n  nhpar: '',\n  ni: '',\n  nis: '',\n  nisd: '',\n  niv: '',\n  njcy: '',\n  nlArr: '',\n  nlE: '',\n  nlarr: '',\n  nldr: '',\n  nle: '',\n  nleftarrow: '',\n  nleftrightarrow: '',\n  nleq: '',\n  nleqq: '',\n  nleqslant: '',\n  nles: '',\n  nless: '',\n  nlsim: '',\n  nlt: '',\n  nltri: '',\n  nltrie: '',\n  nmid: '',\n  nopf: '',\n  not: '',\n  notin: '',\n  notinE: '',\n  notindot: '',\n  notinva: '',\n  notinvb: '',\n  notinvc: '',\n  notni: '',\n  notniva: '',\n  notnivb: '',\n  notnivc: '',\n  npar: '',\n  nparallel: '',\n  nparsl: '',\n  npart: '',\n  npolint: '',\n  npr: '',\n  nprcue: '',\n  npre: '',\n  nprec: '',\n  npreceq: '',\n  nrArr: '',\n  nrarr: '',\n  nrarrc: '',\n  nrarrw: '',\n  nrightarrow: '',\n  nrtri: '',\n  nrtrie: '',\n  nsc: '',\n  nsccue: '',\n  nsce: '',\n  nscr: '',\n  nshortmid: '',\n  nshortparallel: '',\n  nsim: '',\n  nsime: '',\n  nsimeq: '',\n  nsmid: '',\n  nspar: '',\n  nsqsube: '',\n  nsqsupe: '',\n  nsub: '',\n  nsubE: '',\n  nsube: '',\n  nsubset: '',\n  nsubseteq: '',\n  nsubseteqq: '',\n  nsucc: '',\n  nsucceq: '',\n  nsup: '',\n  nsupE: '',\n  nsupe: '',\n  nsupset: '',\n  nsupseteq: '',\n  nsupseteqq: '',\n  ntgl: '',\n  ntilde: '',\n  ntlg: '',\n  ntriangleleft: '',\n  ntrianglelefteq: '',\n  ntriangleright: '',\n  ntrianglerighteq: '',\n  nu: '',\n  num: '#',\n  numero: '',\n  numsp: '',\n  nvDash: '',\n  nvHarr: '',\n  nvap: '',\n  nvdash: '',\n  nvge: '',\n  nvgt: '>',\n  nvinfin: '',\n  nvlArr: '',\n  nvle: '',\n  nvlt: '<',\n  nvltrie: '',\n  nvrArr: '',\n  nvrtrie: '',\n  nvsim: '',\n  nwArr: '',\n  nwarhk: '',\n  nwarr: '',\n  nwarrow: '',\n  nwnear: '',\n  oS: '',\n  oacute: '',\n  oast: '',\n  ocir: '',\n  ocirc: '',\n  ocy: '',\n  odash: '',\n  odblac: '',\n  odiv: '',\n  odot: '',\n  odsold: '',\n  oelig: '',\n  ofcir: '',\n  ofr: '',\n  ogon: '',\n  ograve: '',\n  ogt: '',\n  ohbar: '',\n  ohm: '',\n  oint: '',\n  olarr: '',\n  olcir: '',\n  olcross: '',\n  oline: '',\n  olt: '',\n  omacr: '',\n  omega: '',\n  omicron: '',\n  omid: '',\n  ominus: '',\n  oopf: '',\n  opar: '',\n  operp: '',\n  oplus: '',\n  or: '',\n  orarr: '',\n  ord: '',\n  order: '',\n  orderof: '',\n  ordf: '',\n  ordm: '',\n  origof: '',\n  oror: '',\n  orslope: '',\n  orv: '',\n  oscr: '',\n  oslash: '',\n  osol: '',\n  otilde: '',\n  otimes: '',\n  otimesas: '',\n  ouml: '',\n  ovbar: '',\n  par: '',\n  para: '',\n  parallel: '',\n  parsim: '',\n  parsl: '',\n  part: '',\n  pcy: '',\n  percnt: '%',\n  period: '.',\n  permil: '',\n  perp: '',\n  pertenk: '',\n  pfr: '',\n  phi: '',\n  phiv: '',\n  phmmat: '',\n  phone: '',\n  pi: '',\n  pitchfork: '',\n  piv: '',\n  planck: '',\n  planckh: '',\n  plankv: '',\n  plus: '+',\n  plusacir: '',\n  plusb: '',\n  pluscir: '',\n  plusdo: '',\n  plusdu: '',\n  pluse: '',\n  plusmn: '',\n  plussim: '',\n  plustwo: '',\n  pm: '',\n  pointint: '',\n  popf: '',\n  pound: '',\n  pr: '',\n  prE: '',\n  prap: '',\n  prcue: '',\n  pre: '',\n  prec: '',\n  precapprox: '',\n  preccurlyeq: '',\n  preceq: '',\n  precnapprox: '',\n  precneqq: '',\n  precnsim: '',\n  precsim: '',\n  prime: '',\n  primes: '',\n  prnE: '',\n  prnap: '',\n  prnsim: '',\n  prod: '',\n  profalar: '',\n  profline: '',\n  profsurf: '',\n  prop: '',\n  propto: '',\n  prsim: '',\n  prurel: '',\n  pscr: '',\n  psi: '',\n  puncsp: '',\n  qfr: '',\n  qint: '',\n  qopf: '',\n  qprime: '',\n  qscr: '',\n  quaternions: '',\n  quatint: '',\n  quest: '?',\n  questeq: '',\n  quot: '\"',\n  rAarr: '',\n  rArr: '',\n  rAtail: '',\n  rBarr: '',\n  rHar: '',\n  race: '',\n  racute: '',\n  radic: '',\n  raemptyv: '',\n  rang: '',\n  rangd: '',\n  range: '',\n  rangle: '',\n  raquo: '',\n  rarr: '',\n  rarrap: '',\n  rarrb: '',\n  rarrbfs: '',\n  rarrc: '',\n  rarrfs: '',\n  rarrhk: '',\n  rarrlp: '',\n  rarrpl: '',\n  rarrsim: '',\n  rarrtl: '',\n  rarrw: '',\n  ratail: '',\n  ratio: '',\n  rationals: '',\n  rbarr: '',\n  rbbrk: '',\n  rbrace: '}',\n  rbrack: ']',\n  rbrke: '',\n  rbrksld: '',\n  rbrkslu: '',\n  rcaron: '',\n  rcedil: '',\n  rceil: '',\n  rcub: '}',\n  rcy: '',\n  rdca: '',\n  rdldhar: '',\n  rdquo: '',\n  rdquor: '',\n  rdsh: '',\n  real: '',\n  realine: '',\n  realpart: '',\n  reals: '',\n  rect: '',\n  reg: '',\n  rfisht: '',\n  rfloor: '',\n  rfr: '',\n  rhard: '',\n  rharu: '',\n  rharul: '',\n  rho: '',\n  rhov: '',\n  rightarrow: '',\n  rightarrowtail: '',\n  rightharpoondown: '',\n  rightharpoonup: '',\n  rightleftarrows: '',\n  rightleftharpoons: '',\n  rightrightarrows: '',\n  rightsquigarrow: '',\n  rightthreetimes: '',\n  ring: '',\n  risingdotseq: '',\n  rlarr: '',\n  rlhar: '',\n  rlm: '',\n  rmoust: '',\n  rmoustache: '',\n  rnmid: '',\n  roang: '',\n  roarr: '',\n  robrk: '',\n  ropar: '',\n  ropf: '',\n  roplus: '',\n  rotimes: '',\n  rpar: ')',\n  rpargt: '',\n  rppolint: '',\n  rrarr: '',\n  rsaquo: '',\n  rscr: '',\n  rsh: '',\n  rsqb: ']',\n  rsquo: '',\n  rsquor: '',\n  rthree: '',\n  rtimes: '',\n  rtri: '',\n  rtrie: '',\n  rtrif: '',\n  rtriltri: '',\n  ruluhar: '',\n  rx: '',\n  sacute: '',\n  sbquo: '',\n  sc: '',\n  scE: '',\n  scap: '',\n  scaron: '',\n  sccue: '',\n  sce: '',\n  scedil: '',\n  scirc: '',\n  scnE: '',\n  scnap: '',\n  scnsim: '',\n  scpolint: '',\n  scsim: '',\n  scy: '',\n  sdot: '',\n  sdotb: '',\n  sdote: '',\n  seArr: '',\n  searhk: '',\n  searr: '',\n  searrow: '',\n  sect: '',\n  semi: ';',\n  seswar: '',\n  setminus: '',\n  setmn: '',\n  sext: '',\n  sfr: '',\n  sfrown: '',\n  sharp: '',\n  shchcy: '',\n  shcy: '',\n  shortmid: '',\n  shortparallel: '',\n  shy: '',\n  sigma: '',\n  sigmaf: '',\n  sigmav: '',\n  sim: '',\n  simdot: '',\n  sime: '',\n  simeq: '',\n  simg: '',\n  simgE: '',\n  siml: '',\n  simlE: '',\n  simne: '',\n  simplus: '',\n  simrarr: '',\n  slarr: '',\n  smallsetminus: '',\n  smashp: '',\n  smeparsl: '',\n  smid: '',\n  smile: '',\n  smt: '',\n  smte: '',\n  smtes: '',\n  softcy: '',\n  sol: '/',\n  solb: '',\n  solbar: '',\n  sopf: '',\n  spades: '',\n  spadesuit: '',\n  spar: '',\n  sqcap: '',\n  sqcaps: '',\n  sqcup: '',\n  sqcups: '',\n  sqsub: '',\n  sqsube: '',\n  sqsubset: '',\n  sqsubseteq: '',\n  sqsup: '',\n  sqsupe: '',\n  sqsupset: '',\n  sqsupseteq: '',\n  squ: '',\n  square: '',\n  squarf: '',\n  squf: '',\n  srarr: '',\n  sscr: '',\n  ssetmn: '',\n  ssmile: '',\n  sstarf: '',\n  star: '',\n  starf: '',\n  straightepsilon: '',\n  straightphi: '',\n  strns: '',\n  sub: '',\n  subE: '',\n  subdot: '',\n  sube: '',\n  subedot: '',\n  submult: '',\n  subnE: '',\n  subne: '',\n  subplus: '',\n  subrarr: '',\n  subset: '',\n  subseteq: '',\n  subseteqq: '',\n  subsetneq: '',\n  subsetneqq: '',\n  subsim: '',\n  subsub: '',\n  subsup: '',\n  succ: '',\n  succapprox: '',\n  succcurlyeq: '',\n  succeq: '',\n  succnapprox: '',\n  succneqq: '',\n  succnsim: '',\n  succsim: '',\n  sum: '',\n  sung: '',\n  sup1: '',\n  sup2: '',\n  sup3: '',\n  sup: '',\n  supE: '',\n  supdot: '',\n  supdsub: '',\n  supe: '',\n  supedot: '',\n  suphsol: '',\n  suphsub: '',\n  suplarr: '',\n  supmult: '',\n  supnE: '',\n  supne: '',\n  supplus: '',\n  supset: '',\n  supseteq: '',\n  supseteqq: '',\n  supsetneq: '',\n  supsetneqq: '',\n  supsim: '',\n  supsub: '',\n  supsup: '',\n  swArr: '',\n  swarhk: '',\n  swarr: '',\n  swarrow: '',\n  swnwar: '',\n  szlig: '',\n  target: '',\n  tau: '',\n  tbrk: '',\n  tcaron: '',\n  tcedil: '',\n  tcy: '',\n  tdot: '',\n  telrec: '',\n  tfr: '',\n  there4: '',\n  therefore: '',\n  theta: '',\n  thetasym: '',\n  thetav: '',\n  thickapprox: '',\n  thicksim: '',\n  thinsp: '',\n  thkap: '',\n  thksim: '',\n  thorn: '',\n  tilde: '',\n  times: '',\n  timesb: '',\n  timesbar: '',\n  timesd: '',\n  tint: '',\n  toea: '',\n  top: '',\n  topbot: '',\n  topcir: '',\n  topf: '',\n  topfork: '',\n  tosa: '',\n  tprime: '',\n  trade: '',\n  triangle: '',\n  triangledown: '',\n  triangleleft: '',\n  trianglelefteq: '',\n  triangleq: '',\n  triangleright: '',\n  trianglerighteq: '',\n  tridot: '',\n  trie: '',\n  triminus: '',\n  triplus: '',\n  trisb: '',\n  tritime: '',\n  trpezium: '',\n  tscr: '',\n  tscy: '',\n  tshcy: '',\n  tstrok: '',\n  twixt: '',\n  twoheadleftarrow: '',\n  twoheadrightarrow: '',\n  uArr: '',\n  uHar: '',\n  uacute: '',\n  uarr: '',\n  ubrcy: '',\n  ubreve: '',\n  ucirc: '',\n  ucy: '',\n  udarr: '',\n  udblac: '',\n  udhar: '',\n  ufisht: '',\n  ufr: '',\n  ugrave: '',\n  uharl: '',\n  uharr: '',\n  uhblk: '',\n  ulcorn: '',\n  ulcorner: '',\n  ulcrop: '',\n  ultri: '',\n  umacr: '',\n  uml: '',\n  uogon: '',\n  uopf: '',\n  uparrow: '',\n  updownarrow: '',\n  upharpoonleft: '',\n  upharpoonright: '',\n  uplus: '',\n  upsi: '',\n  upsih: '',\n  upsilon: '',\n  upuparrows: '',\n  urcorn: '',\n  urcorner: '',\n  urcrop: '',\n  uring: '',\n  urtri: '',\n  uscr: '',\n  utdot: '',\n  utilde: '',\n  utri: '',\n  utrif: '',\n  uuarr: '',\n  uuml: '',\n  uwangle: '',\n  vArr: '',\n  vBar: '',\n  vBarv: '',\n  vDash: '',\n  vangrt: '',\n  varepsilon: '',\n  varkappa: '',\n  varnothing: '',\n  varphi: '',\n  varpi: '',\n  varpropto: '',\n  varr: '',\n  varrho: '',\n  varsigma: '',\n  varsubsetneq: '',\n  varsubsetneqq: '',\n  varsupsetneq: '',\n  varsupsetneqq: '',\n  vartheta: '',\n  vartriangleleft: '',\n  vartriangleright: '',\n  vcy: '',\n  vdash: '',\n  vee: '',\n  veebar: '',\n  veeeq: '',\n  vellip: '',\n  verbar: '|',\n  vert: '|',\n  vfr: '',\n  vltri: '',\n  vnsub: '',\n  vnsup: '',\n  vopf: '',\n  vprop: '',\n  vrtri: '',\n  vscr: '',\n  vsubnE: '',\n  vsubne: '',\n  vsupnE: '',\n  vsupne: '',\n  vzigzag: '',\n  wcirc: '',\n  wedbar: '',\n  wedge: '',\n  wedgeq: '',\n  weierp: '',\n  wfr: '',\n  wopf: '',\n  wp: '',\n  wr: '',\n  wreath: '',\n  wscr: '',\n  xcap: '',\n  xcirc: '',\n  xcup: '',\n  xdtri: '',\n  xfr: '',\n  xhArr: '',\n  xharr: '',\n  xi: '',\n  xlArr: '',\n  xlarr: '',\n  xmap: '',\n  xnis: '',\n  xodot: '',\n  xopf: '',\n  xoplus: '',\n  xotime: '',\n  xrArr: '',\n  xrarr: '',\n  xscr: '',\n  xsqcup: '',\n  xuplus: '',\n  xutri: '',\n  xvee: '',\n  xwedge: '',\n  yacute: '',\n  yacy: '',\n  ycirc: '',\n  ycy: '',\n  yen: '',\n  yfr: '',\n  yicy: '',\n  yopf: '',\n  yscr: '',\n  yucy: '',\n  yuml: '',\n  zacute: '',\n  zcaron: '',\n  zcy: '',\n  zdot: '',\n  zeetrf: '',\n  zeta: '',\n  zfr: '',\n  zhcy: '',\n  zigrarr: '',\n  zopf: '',\n  zscr: '',\n  zwj: '',\n  zwnj: ''\n};","import { characterEntities } from 'character-entities';\nconst own = {}.hasOwnProperty;\n\n/**\n * Decode a single character reference (without the `&` or `;`).\n * You probably only need this when youre building parsers yourself that follow\n * different rules compared to HTML.\n * This is optimized to be tiny in browsers.\n *\n * @param {string} value\n *   `notin` (named), `#123` (deci), `#x123` (hexa).\n * @returns {string|false}\n *   Decoded reference.\n */\nexport function decodeNamedCharacterReference(value) {\n  return own.call(characterEntities, value) ? characterEntities[value] : false;\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { decodeNamedCharacterReference } from 'decode-named-character-reference';\nimport { asciiAlphanumeric, asciiDigit, asciiHexDigit } from 'micromark-util-character';\n/** @type {Construct} */\nexport const characterReference = {\n  name: 'characterReference',\n  tokenize: tokenizeCharacterReference\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCharacterReference(effects, ok, nok) {\n  const self = this;\n  let size = 0;\n  /** @type {number} */\n  let max;\n  /** @type {(code: Code) => boolean} */\n  let test;\n  return start;\n\n  /**\n   * Start of character reference.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *      ^\n   * > | a&#123;b\n   *      ^\n   * > | a&#x9;b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('characterReference');\n    effects.enter('characterReferenceMarker');\n    effects.consume(code);\n    effects.exit('characterReferenceMarker');\n    return open;\n  }\n\n  /**\n   * After `&`, at `#` for numeric references or alphanumeric for named\n   * references.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *       ^\n   * > | a&#123;b\n   *       ^\n   * > | a&#x9;b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (code === 35) {\n      effects.enter('characterReferenceMarkerNumeric');\n      effects.consume(code);\n      effects.exit('characterReferenceMarkerNumeric');\n      return numeric;\n    }\n    effects.enter('characterReferenceValue');\n    max = 31;\n    test = asciiAlphanumeric;\n    return value(code);\n  }\n\n  /**\n   * After `#`, at `x` for hexadecimals or digit for decimals.\n   *\n   * ```markdown\n   * > | a&#123;b\n   *        ^\n   * > | a&#x9;b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function numeric(code) {\n    if (code === 88 || code === 120) {\n      effects.enter('characterReferenceMarkerHexadecimal');\n      effects.consume(code);\n      effects.exit('characterReferenceMarkerHexadecimal');\n      effects.enter('characterReferenceValue');\n      max = 6;\n      test = asciiHexDigit;\n      return value;\n    }\n    effects.enter('characterReferenceValue');\n    max = 7;\n    test = asciiDigit;\n    return value(code);\n  }\n\n  /**\n   * After markers (`&#x`, `&#`, or `&`), in value, before `;`.\n   *\n   * The character reference kind defines what and how many characters are\n   * allowed.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *       ^^^\n   * > | a&#123;b\n   *        ^^^\n   * > | a&#x9;b\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function value(code) {\n    if (code === 59 && size) {\n      const token = effects.exit('characterReferenceValue');\n      if (test === asciiAlphanumeric && !decodeNamedCharacterReference(self.sliceSerialize(token))) {\n        return nok(code);\n      }\n\n      // To do: `markdown-rs` uses a different name:\n      // `CharacterReferenceMarkerSemi`.\n      effects.enter('characterReferenceMarker');\n      effects.consume(code);\n      effects.exit('characterReferenceMarker');\n      effects.exit('characterReference');\n      return ok;\n    }\n    if (test(code) && size++ < max) {\n      effects.consume(code);\n      return value;\n    }\n    return nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { asciiPunctuation } from 'micromark-util-character';\n/** @type {Construct} */\nexport const characterEscape = {\n  name: 'characterEscape',\n  tokenize: tokenizeCharacterEscape\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCharacterEscape(effects, ok, nok) {\n  return start;\n\n  /**\n   * Start of character escape.\n   *\n   * ```markdown\n   * > | a\\*b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('characterEscape');\n    effects.enter('escapeMarker');\n    effects.consume(code);\n    effects.exit('escapeMarker');\n    return inside;\n  }\n\n  /**\n   * After `\\`, at punctuation.\n   *\n   * ```markdown\n   * > | a\\*b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    // ASCII punctuation.\n    if (asciiPunctuation(code)) {\n      effects.enter('characterEscapeValue');\n      effects.consume(code);\n      effects.exit('characterEscapeValue');\n      effects.exit('characterEscape');\n      return ok;\n    }\n    return nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {Construct} */\nexport const lineEnding = {\n  name: 'lineEnding',\n  tokenize: tokenizeLineEnding\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeLineEnding(effects, ok) {\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return factorySpace(effects, ok, 'linePrefix');\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factoryDestination } from 'micromark-factory-destination';\nimport { factoryLabel } from 'micromark-factory-label';\nimport { factoryTitle } from 'micromark-factory-title';\nimport { factoryWhitespace } from 'micromark-factory-whitespace';\nimport { markdownLineEndingOrSpace } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { normalizeIdentifier } from 'micromark-util-normalize-identifier';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/** @type {Construct} */\nexport const labelEnd = {\n  name: 'labelEnd',\n  tokenize: tokenizeLabelEnd,\n  resolveTo: resolveToLabelEnd,\n  resolveAll: resolveAllLabelEnd\n};\n\n/** @type {Construct} */\nconst resourceConstruct = {\n  tokenize: tokenizeResource\n};\n/** @type {Construct} */\nconst referenceFullConstruct = {\n  tokenize: tokenizeReferenceFull\n};\n/** @type {Construct} */\nconst referenceCollapsedConstruct = {\n  tokenize: tokenizeReferenceCollapsed\n};\n\n/** @type {Resolver} */\nfunction resolveAllLabelEnd(events) {\n  let index = -1;\n  while (++index < events.length) {\n    const token = events[index][1];\n    if (token.type === 'labelImage' || token.type === 'labelLink' || token.type === 'labelEnd') {\n      // Remove the marker.\n      events.splice(index + 1, token.type === 'labelImage' ? 4 : 2);\n      token.type = 'data';\n      index++;\n    }\n  }\n  return events;\n}\n\n/** @type {Resolver} */\nfunction resolveToLabelEnd(events, context) {\n  let index = events.length;\n  let offset = 0;\n  /** @type {Token} */\n  let token;\n  /** @type {number | undefined} */\n  let open;\n  /** @type {number | undefined} */\n  let close;\n  /** @type {Array<Event>} */\n  let media;\n\n  // Find an opening.\n  while (index--) {\n    token = events[index][1];\n    if (open) {\n      // If we see another link, or inactive link label, weve been here before.\n      if (token.type === 'link' || token.type === 'labelLink' && token._inactive) {\n        break;\n      }\n\n      // Mark other link openings as inactive, as we cant have links in\n      // links.\n      if (events[index][0] === 'enter' && token.type === 'labelLink') {\n        token._inactive = true;\n      }\n    } else if (close) {\n      if (events[index][0] === 'enter' && (token.type === 'labelImage' || token.type === 'labelLink') && !token._balanced) {\n        open = index;\n        if (token.type !== 'labelLink') {\n          offset = 2;\n          break;\n        }\n      }\n    } else if (token.type === 'labelEnd') {\n      close = index;\n    }\n  }\n  const group = {\n    type: events[open][1].type === 'labelLink' ? 'link' : 'image',\n    start: Object.assign({}, events[open][1].start),\n    end: Object.assign({}, events[events.length - 1][1].end)\n  };\n  const label = {\n    type: 'label',\n    start: Object.assign({}, events[open][1].start),\n    end: Object.assign({}, events[close][1].end)\n  };\n  const text = {\n    type: 'labelText',\n    start: Object.assign({}, events[open + offset + 2][1].end),\n    end: Object.assign({}, events[close - 2][1].start)\n  };\n  media = [['enter', group, context], ['enter', label, context]];\n\n  // Opening marker.\n  media = push(media, events.slice(open + 1, open + offset + 3));\n\n  // Text open.\n  media = push(media, [['enter', text, context]]);\n\n  // Always populated by defaults.\n\n  // Between.\n  media = push(media, resolveAll(context.parser.constructs.insideSpan.null, events.slice(open + offset + 4, close - 3), context));\n\n  // Text close, marker close, label close.\n  media = push(media, [['exit', text, context], events[close - 2], events[close - 1], ['exit', label, context]]);\n\n  // Reference, resource, or so.\n  media = push(media, events.slice(close + 1));\n\n  // Media close.\n  media = push(media, [['exit', group, context]]);\n  splice(events, open, events.length, media);\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeLabelEnd(effects, ok, nok) {\n  const self = this;\n  let index = self.events.length;\n  /** @type {Token} */\n  let labelStart;\n  /** @type {boolean} */\n  let defined;\n\n  // Find an opening.\n  while (index--) {\n    if ((self.events[index][1].type === 'labelImage' || self.events[index][1].type === 'labelLink') && !self.events[index][1]._balanced) {\n      labelStart = self.events[index][1];\n      break;\n    }\n  }\n  return start;\n\n  /**\n   * Start of label end.\n   *\n   * ```markdown\n   * > | [a](b) c\n   *       ^\n   * > | [a][b] c\n   *       ^\n   * > | [a][] b\n   *       ^\n   * > | [a] b\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // If there is not an okay opening.\n    if (!labelStart) {\n      return nok(code);\n    }\n\n    // If the corresponding label (link) start is marked as inactive,\n    // it means wed be wrapping a link, like this:\n    //\n    // ```markdown\n    // > | a [b [c](d) e](f) g.\n    //                  ^\n    // ```\n    //\n    // We cant have that, so its just balanced brackets.\n    if (labelStart._inactive) {\n      return labelEndNok(code);\n    }\n    defined = self.parser.defined.includes(normalizeIdentifier(self.sliceSerialize({\n      start: labelStart.end,\n      end: self.now()\n    })));\n    effects.enter('labelEnd');\n    effects.enter('labelMarker');\n    effects.consume(code);\n    effects.exit('labelMarker');\n    effects.exit('labelEnd');\n    return after;\n  }\n\n  /**\n   * After `]`.\n   *\n   * ```markdown\n   * > | [a](b) c\n   *       ^\n   * > | [a][b] c\n   *       ^\n   * > | [a][] b\n   *       ^\n   * > | [a] b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    // Note: `markdown-rs` also parses GFM footnotes here, which for us is in\n    // an extension.\n\n    // Resource (`[asd](fgh)`)?\n    if (code === 40) {\n      return effects.attempt(resourceConstruct, labelEndOk, defined ? labelEndOk : labelEndNok)(code);\n    }\n\n    // Full (`[asd][fgh]`) or collapsed (`[asd][]`) reference?\n    if (code === 91) {\n      return effects.attempt(referenceFullConstruct, labelEndOk, defined ? referenceNotFull : labelEndNok)(code);\n    }\n\n    // Shortcut (`[asd]`) reference?\n    return defined ? labelEndOk(code) : labelEndNok(code);\n  }\n\n  /**\n   * After `]`, at `[`, but not at a full reference.\n   *\n   * >  **Note**: we only get here if the label is defined.\n   *\n   * ```markdown\n   * > | [a][] b\n   *        ^\n   * > | [a] b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function referenceNotFull(code) {\n    return effects.attempt(referenceCollapsedConstruct, labelEndOk, labelEndNok)(code);\n  }\n\n  /**\n   * Done, we found something.\n   *\n   * ```markdown\n   * > | [a](b) c\n   *           ^\n   * > | [a][b] c\n   *           ^\n   * > | [a][] b\n   *          ^\n   * > | [a] b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelEndOk(code) {\n    // Note: `markdown-rs` does a bunch of stuff here.\n    return ok(code);\n  }\n\n  /**\n   * Done, its nothing.\n   *\n   * There was an okay opening, but we didnt match anything.\n   *\n   * ```markdown\n   * > | [a](b c\n   *        ^\n   * > | [a][b c\n   *        ^\n   * > | [a] b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelEndNok(code) {\n    labelStart._balanced = true;\n    return nok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeResource(effects, ok, nok) {\n  return resourceStart;\n\n  /**\n   * At a resource.\n   *\n   * ```markdown\n   * > | [a](b) c\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function resourceStart(code) {\n    effects.enter('resource');\n    effects.enter('resourceMarker');\n    effects.consume(code);\n    effects.exit('resourceMarker');\n    return resourceBefore;\n  }\n\n  /**\n   * In resource, after `(`, at optional whitespace.\n   *\n   * ```markdown\n   * > | [a](b) c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function resourceBefore(code) {\n    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceOpen)(code) : resourceOpen(code);\n  }\n\n  /**\n   * In resource, after optional whitespace, at `)` or a destination.\n   *\n   * ```markdown\n   * > | [a](b) c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function resourceOpen(code) {\n    if (code === 41) {\n      return resourceEnd(code);\n    }\n    return factoryDestination(effects, resourceDestinationAfter, resourceDestinationMissing, 'resourceDestination', 'resourceDestinationLiteral', 'resourceDestinationLiteralMarker', 'resourceDestinationRaw', 'resourceDestinationString', 32)(code);\n  }\n\n  /**\n   * In resource, after destination, at optional whitespace.\n   *\n   * ```markdown\n   * > | [a](b) c\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function resourceDestinationAfter(code) {\n    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceBetween)(code) : resourceEnd(code);\n  }\n\n  /**\n   * At invalid destination.\n   *\n   * ```markdown\n   * > | [a](<<) b\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function resourceDestinationMissing(code) {\n    return nok(code);\n  }\n\n  /**\n   * In resource, after destination and whitespace, at `(` or title.\n   *\n   * ```markdown\n   * > | [a](b ) c\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function resourceBetween(code) {\n    if (code === 34 || code === 39 || code === 40) {\n      return factoryTitle(effects, resourceTitleAfter, nok, 'resourceTitle', 'resourceTitleMarker', 'resourceTitleString')(code);\n    }\n    return resourceEnd(code);\n  }\n\n  /**\n   * In resource, after title, at optional whitespace.\n   *\n   * ```markdown\n   * > | [a](b \"c\") d\n   *              ^\n   * ```\n   *\n   * @type {State}\n   */\n  function resourceTitleAfter(code) {\n    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceEnd)(code) : resourceEnd(code);\n  }\n\n  /**\n   * In resource, at `)`.\n   *\n   * ```markdown\n   * > | [a](b) d\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function resourceEnd(code) {\n    if (code === 41) {\n      effects.enter('resourceMarker');\n      effects.consume(code);\n      effects.exit('resourceMarker');\n      effects.exit('resource');\n      return ok;\n    }\n    return nok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeReferenceFull(effects, ok, nok) {\n  const self = this;\n  return referenceFull;\n\n  /**\n   * In a reference (full), at the `[`.\n   *\n   * ```markdown\n   * > | [a][b] d\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function referenceFull(code) {\n    return factoryLabel.call(self, effects, referenceFullAfter, referenceFullMissing, 'reference', 'referenceMarker', 'referenceString')(code);\n  }\n\n  /**\n   * In a reference (full), after `]`.\n   *\n   * ```markdown\n   * > | [a][b] d\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function referenceFullAfter(code) {\n    return self.parser.defined.includes(normalizeIdentifier(self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1))) ? ok(code) : nok(code);\n  }\n\n  /**\n   * In reference (full) that was missing.\n   *\n   * ```markdown\n   * > | [a][b d\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function referenceFullMissing(code) {\n    return nok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeReferenceCollapsed(effects, ok, nok) {\n  return referenceCollapsedStart;\n\n  /**\n   * In reference (collapsed), at `[`.\n   *\n   * >  **Note**: we only get here if the label is defined.\n   *\n   * ```markdown\n   * > | [a][] d\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function referenceCollapsedStart(code) {\n    // We only attempt a collapsed label if theres a `[`.\n\n    effects.enter('reference');\n    effects.enter('referenceMarker');\n    effects.consume(code);\n    effects.exit('referenceMarker');\n    return referenceCollapsedOpen;\n  }\n\n  /**\n   * In reference (collapsed), at `]`.\n   *\n   * >  **Note**: we only get here if the label is defined.\n   *\n   * ```markdown\n   * > | [a][] d\n   *         ^\n   * ```\n   *\n   *  @type {State}\n   */\n  function referenceCollapsedOpen(code) {\n    if (code === 93) {\n      effects.enter('referenceMarker');\n      effects.consume(code);\n      effects.exit('referenceMarker');\n      effects.exit('reference');\n      return ok;\n    }\n    return nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport { markdownLineEndingOrSpace, unicodePunctuation, unicodeWhitespace } from 'micromark-util-character';\n/**\n * Classify whether a code represents whitespace, punctuation, or something\n * else.\n *\n * Used for attention (emphasis, strong), whose sequences can open or close\n * based on the class of surrounding characters.\n *\n * >  **Note**: eof (`null`) is seen as whitespace.\n *\n * @param {Code} code\n *   Code.\n * @returns {typeof constants.characterGroupWhitespace | typeof constants.characterGroupPunctuation | undefined}\n *   Group.\n */\nexport function classifyCharacter(code) {\n  if (code === null || markdownLineEndingOrSpace(code) || unicodeWhitespace(code)) {\n    return 1;\n  }\n  if (unicodePunctuation(code)) {\n    return 2;\n  }\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { push, splice } from 'micromark-util-chunked';\nimport { classifyCharacter } from 'micromark-util-classify-character';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/** @type {Construct} */\nexport const attention = {\n  name: 'attention',\n  tokenize: tokenizeAttention,\n  resolveAll: resolveAllAttention\n};\n\n/**\n * Take all events and resolve attention to emphasis or strong.\n *\n * @type {Resolver}\n */\nfunction resolveAllAttention(events, context) {\n  let index = -1;\n  /** @type {number} */\n  let open;\n  /** @type {Token} */\n  let group;\n  /** @type {Token} */\n  let text;\n  /** @type {Token} */\n  let openingSequence;\n  /** @type {Token} */\n  let closingSequence;\n  /** @type {number} */\n  let use;\n  /** @type {Array<Event>} */\n  let nextEvents;\n  /** @type {number} */\n  let offset;\n\n  // Walk through all events.\n  //\n  // Note: performance of this is fine on an mb of normal markdown, but its\n  // a bottleneck for malicious stuff.\n  while (++index < events.length) {\n    // Find a token that can close.\n    if (events[index][0] === 'enter' && events[index][1].type === 'attentionSequence' && events[index][1]._close) {\n      open = index;\n\n      // Now walk back to find an opener.\n      while (open--) {\n        // Find a token that can open the closer.\n        if (events[open][0] === 'exit' && events[open][1].type === 'attentionSequence' && events[open][1]._open &&\n        // If the markers are the same:\n        context.sliceSerialize(events[open][1]).charCodeAt(0) === context.sliceSerialize(events[index][1]).charCodeAt(0)) {\n          // If the opening can close or the closing can open,\n          // and the close size *is not* a multiple of three,\n          // but the sum of the opening and closing size *is* multiple of three,\n          // then dont match.\n          if ((events[open][1]._close || events[index][1]._open) && (events[index][1].end.offset - events[index][1].start.offset) % 3 && !((events[open][1].end.offset - events[open][1].start.offset + events[index][1].end.offset - events[index][1].start.offset) % 3)) {\n            continue;\n          }\n\n          // Number of markers to use from the sequence.\n          use = events[open][1].end.offset - events[open][1].start.offset > 1 && events[index][1].end.offset - events[index][1].start.offset > 1 ? 2 : 1;\n          const start = Object.assign({}, events[open][1].end);\n          const end = Object.assign({}, events[index][1].start);\n          movePoint(start, -use);\n          movePoint(end, use);\n          openingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start,\n            end: Object.assign({}, events[open][1].end)\n          };\n          closingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start: Object.assign({}, events[index][1].start),\n            end\n          };\n          text = {\n            type: use > 1 ? 'strongText' : 'emphasisText',\n            start: Object.assign({}, events[open][1].end),\n            end: Object.assign({}, events[index][1].start)\n          };\n          group = {\n            type: use > 1 ? 'strong' : 'emphasis',\n            start: Object.assign({}, openingSequence.start),\n            end: Object.assign({}, closingSequence.end)\n          };\n          events[open][1].end = Object.assign({}, openingSequence.start);\n          events[index][1].start = Object.assign({}, closingSequence.end);\n          nextEvents = [];\n\n          // If there are more markers in the opening, add them before.\n          if (events[open][1].end.offset - events[open][1].start.offset) {\n            nextEvents = push(nextEvents, [['enter', events[open][1], context], ['exit', events[open][1], context]]);\n          }\n\n          // Opening.\n          nextEvents = push(nextEvents, [['enter', group, context], ['enter', openingSequence, context], ['exit', openingSequence, context], ['enter', text, context]]);\n\n          // Always populated by defaults.\n\n          // Between.\n          nextEvents = push(nextEvents, resolveAll(context.parser.constructs.insideSpan.null, events.slice(open + 1, index), context));\n\n          // Closing.\n          nextEvents = push(nextEvents, [['exit', text, context], ['enter', closingSequence, context], ['exit', closingSequence, context], ['exit', group, context]]);\n\n          // If there are more markers in the closing, add them after.\n          if (events[index][1].end.offset - events[index][1].start.offset) {\n            offset = 2;\n            nextEvents = push(nextEvents, [['enter', events[index][1], context], ['exit', events[index][1], context]]);\n          } else {\n            offset = 0;\n          }\n          splice(events, open - 1, index - open + 3, nextEvents);\n          index = open + nextEvents.length - offset - 2;\n          break;\n        }\n      }\n    }\n  }\n\n  // Remove remaining sequences.\n  index = -1;\n  while (++index < events.length) {\n    if (events[index][1].type === 'attentionSequence') {\n      events[index][1].type = 'data';\n    }\n  }\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeAttention(effects, ok) {\n  const attentionMarkers = this.parser.constructs.attentionMarkers.null;\n  const previous = this.previous;\n  const before = classifyCharacter(previous);\n\n  /** @type {NonNullable<Code>} */\n  let marker;\n  return start;\n\n  /**\n   * Before a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    marker = code;\n    effects.enter('attentionSequence');\n    return inside(code);\n  }\n\n  /**\n   * In a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === marker) {\n      effects.consume(code);\n      return inside;\n    }\n    const token = effects.exit('attentionSequence');\n\n    // To do: next major: move this to resolver, just like `markdown-rs`.\n    const after = classifyCharacter(code);\n\n    // Always populated by defaults.\n\n    const open = !after || after === 2 && before || attentionMarkers.includes(code);\n    const close = !before || before === 2 && after || attentionMarkers.includes(previous);\n    token._open = Boolean(marker === 42 ? open : open && (before || !close));\n    token._close = Boolean(marker === 42 ? close : close && (after || !open));\n    return ok(code);\n  }\n}\n\n/**\n * Move a point a bit.\n *\n * Note: `move` only works inside lines! Its not possible to move past other\n * chunks (replacement characters, tabs, or line endings).\n *\n * @param {Point} point\n * @param {number} offset\n * @returns {void}\n */\nfunction movePoint(point, offset) {\n  point.column += offset;\n  point.offset += offset;\n  point._bufferIndex += offset;\n}","/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\n\nimport { attention, autolink, blockQuote, characterEscape, characterReference, codeFenced, codeIndented, codeText, definition, hardBreakEscape, headingAtx, htmlFlow, htmlText, labelEnd, labelStartImage, labelStartLink, lineEnding, list, setextUnderline, thematicBreak } from 'micromark-core-commonmark';\nimport { resolver as resolveText } from './initialize/text.js';\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n};\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n};\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n};\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n};\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n};\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n};\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n};\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n};\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n};","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownLineEndingOrSpace, markdownSpace } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {Construct} */\nexport const headingAtx = {\n  name: 'headingAtx',\n  tokenize: tokenizeHeadingAtx,\n  resolve: resolveHeadingAtx\n};\n\n/** @type {Resolver} */\nfunction resolveHeadingAtx(events, context) {\n  let contentEnd = events.length - 2;\n  let contentStart = 3;\n  /** @type {Token} */\n  let content;\n  /** @type {Token} */\n  let text;\n\n  // Prefix whitespace, part of the opening.\n  if (events[contentStart][1].type === 'whitespace') {\n    contentStart += 2;\n  }\n\n  // Suffix whitespace, part of the closing.\n  if (contentEnd - 2 > contentStart && events[contentEnd][1].type === 'whitespace') {\n    contentEnd -= 2;\n  }\n  if (events[contentEnd][1].type === 'atxHeadingSequence' && (contentStart === contentEnd - 1 || contentEnd - 4 > contentStart && events[contentEnd - 2][1].type === 'whitespace')) {\n    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4;\n  }\n  if (contentEnd > contentStart) {\n    content = {\n      type: 'atxHeadingText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end\n    };\n    text = {\n      type: 'chunkText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end,\n      contentType: 'text'\n    };\n    splice(events, contentStart, contentEnd - contentStart + 1, [['enter', content, context], ['enter', text, context], ['exit', text, context], ['exit', content, context]]);\n  }\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeHeadingAtx(effects, ok, nok) {\n  let size = 0;\n  return start;\n\n  /**\n   * Start of a heading (atx).\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse indent like `markdown-rs`.\n    effects.enter('atxHeading');\n    return before(code);\n  }\n\n  /**\n   * After optional whitespace, at `#`.\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    effects.enter('atxHeadingSequence');\n    return sequenceOpen(code);\n  }\n\n  /**\n   * In opening sequence.\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === 35 && size++ < 6) {\n      effects.consume(code);\n      return sequenceOpen;\n    }\n\n    // Always at least one `#`.\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingSequence');\n      return atBreak(code);\n    }\n    return nok(code);\n  }\n\n  /**\n   * After something, before something else.\n   *\n   * ```markdown\n   * > | ## aa\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === 35) {\n      effects.enter('atxHeadingSequence');\n      return sequenceFurther(code);\n    }\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('atxHeading');\n      // To do: interrupt like `markdown-rs`.\n      // // Feel free to interrupt.\n      // tokenizer.interrupt = false\n      return ok(code);\n    }\n    if (markdownSpace(code)) {\n      return factorySpace(effects, atBreak, 'whitespace')(code);\n    }\n\n    // To do: generate `data` tokens, add the `text` token later.\n    // Needs edit map, see: `markdown.rs`.\n    effects.enter('atxHeadingText');\n    return data(code);\n  }\n\n  /**\n   * In further sequence (after whitespace).\n   *\n   * Could be normal visible hashes in the heading or a final sequence.\n   *\n   * ```markdown\n   * > | ## aa ##\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceFurther(code) {\n    if (code === 35) {\n      effects.consume(code);\n      return sequenceFurther;\n    }\n    effects.exit('atxHeadingSequence');\n    return atBreak(code);\n  }\n\n  /**\n   * In text.\n   *\n   * ```markdown\n   * > | ## aa\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function data(code) {\n    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingText');\n      return atBreak(code);\n    }\n    effects.consume(code);\n    return data;\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { labelEnd } from './label-end.js';\n\n/** @type {Construct} */\nexport const labelStartImage = {\n  name: 'labelStartImage',\n  tokenize: tokenizeLabelStartImage,\n  resolveAll: labelEnd.resolveAll\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeLabelStartImage(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   * Start of label (image) start.\n   *\n   * ```markdown\n   * > | a ![b] c\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('labelImage');\n    effects.enter('labelImageMarker');\n    effects.consume(code);\n    effects.exit('labelImageMarker');\n    return open;\n  }\n\n  /**\n   * After `!`, at `[`.\n   *\n   * ```markdown\n   * > | a ![b] c\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (code === 91) {\n      effects.enter('labelMarker');\n      effects.consume(code);\n      effects.exit('labelMarker');\n      effects.exit('labelImage');\n      return after;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `![`.\n   *\n   * ```markdown\n   * > | a ![b] c\n   *         ^\n   * ```\n   *\n   * This is needed in because, when GFM footnotes are enabled, images never\n   * form when started with a `^`.\n   * Instead, links form:\n   *\n   * ```markdown\n   * ![^a](b)\n   *\n   * ![^a][b]\n   *\n   * [b]: c\n   * ```\n   *\n   * ```html\n   * <p>!<a href=\\\"b\\\">^a</a></p>\n   * <p>!<a href=\\\"c\\\">^a</a></p>\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    // To do: use a new field to do this, this is still needed for\n    // `micromark-extension-gfm-footnote`, but the `label-start-link`\n    // behavior isnt.\n    // Hidden footnotes hook.\n    /* c8 ignore next 3 */\n    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs ? nok(code) : ok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { asciiAlpha, asciiAlphanumeric, asciiAtext, asciiControl } from 'micromark-util-character';\n/** @type {Construct} */\nexport const autolink = {\n  name: 'autolink',\n  tokenize: tokenizeAutolink\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeAutolink(effects, ok, nok) {\n  let size = 0;\n  return start;\n\n  /**\n   * Start of an autolink.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *      ^\n   * > | a<user@example.com>b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('autolink');\n    effects.enter('autolinkMarker');\n    effects.consume(code);\n    effects.exit('autolinkMarker');\n    effects.enter('autolinkProtocol');\n    return open;\n  }\n\n  /**\n   * After `<`, at protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *       ^\n   * > | a<user@example.com>b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      return schemeOrEmailAtext;\n    }\n    return emailAtext(code);\n  }\n\n  /**\n   * At second byte of protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *        ^\n   * > | a<user@example.com>b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function schemeOrEmailAtext(code) {\n    // ASCII alphanumeric and `+`, `-`, and `.`.\n    if (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) {\n      // Count the previous alphabetical from `open` too.\n      size = 1;\n      return schemeInsideOrEmailAtext(code);\n    }\n    return emailAtext(code);\n  }\n\n  /**\n   * In ambiguous protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *        ^\n   * > | a<user@example.com>b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function schemeInsideOrEmailAtext(code) {\n    if (code === 58) {\n      effects.consume(code);\n      size = 0;\n      return urlInside;\n    }\n\n    // ASCII alphanumeric and `+`, `-`, and `.`.\n    if ((code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) && size++ < 32) {\n      effects.consume(code);\n      return schemeInsideOrEmailAtext;\n    }\n    size = 0;\n    return emailAtext(code);\n  }\n\n  /**\n   * After protocol, in URL.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function urlInside(code) {\n    if (code === 62) {\n      effects.exit('autolinkProtocol');\n      effects.enter('autolinkMarker');\n      effects.consume(code);\n      effects.exit('autolinkMarker');\n      effects.exit('autolink');\n      return ok;\n    }\n\n    // ASCII control, space, or `<`.\n    if (code === null || code === 32 || code === 60 || asciiControl(code)) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return urlInside;\n  }\n\n  /**\n   * In email atext.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *              ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailAtext(code) {\n    if (code === 64) {\n      effects.consume(code);\n      return emailAtSignOrDot;\n    }\n    if (asciiAtext(code)) {\n      effects.consume(code);\n      return emailAtext;\n    }\n    return nok(code);\n  }\n\n  /**\n   * In label, after at-sign or dot.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *                 ^       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailAtSignOrDot(code) {\n    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code);\n  }\n\n  /**\n   * In label, where `.` and `>` are allowed.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *                   ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailLabel(code) {\n    if (code === 46) {\n      effects.consume(code);\n      size = 0;\n      return emailAtSignOrDot;\n    }\n    if (code === 62) {\n      // Exit, then change the token type.\n      effects.exit('autolinkProtocol').type = 'autolinkEmail';\n      effects.enter('autolinkMarker');\n      effects.consume(code);\n      effects.exit('autolinkMarker');\n      effects.exit('autolink');\n      return ok;\n    }\n    return emailValue(code);\n  }\n\n  /**\n   * In label, where `.` and `>` are *not* allowed.\n   *\n   * Though, this is also used in `emailLabel` to parse other values.\n   *\n   * ```markdown\n   * > | a<user.name@ex-ample.com>b\n   *                    ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailValue(code) {\n    // ASCII alphanumeric or `-`.\n    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {\n      const next = code === 45 ? emailValue : emailLabel;\n      effects.consume(code);\n      return next;\n    }\n    return nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { asciiAlpha, asciiAlphanumeric, markdownLineEnding, markdownLineEndingOrSpace, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const htmlText = {\n  name: 'htmlText',\n  tokenize: tokenizeHtmlText\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeHtmlText(effects, ok, nok) {\n  const self = this;\n  /** @type {NonNullable<Code> | undefined} */\n  let marker;\n  /** @type {number} */\n  let index;\n  /** @type {State} */\n  let returnState;\n  return start;\n\n  /**\n   * Start of HTML (text).\n   *\n   * ```markdown\n   * > | a <b> c\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('htmlText');\n    effects.enter('htmlTextData');\n    effects.consume(code);\n    return open;\n  }\n\n  /**\n   * After `<`, at tag name or other stuff.\n   *\n   * ```markdown\n   * > | a <b> c\n   *        ^\n   * > | a <!doctype> c\n   *        ^\n   * > | a <!--b--> c\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (code === 33) {\n      effects.consume(code);\n      return declarationOpen;\n    }\n    if (code === 47) {\n      effects.consume(code);\n      return tagCloseStart;\n    }\n    if (code === 63) {\n      effects.consume(code);\n      return instruction;\n    }\n\n    // ASCII alphabetical.\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      return tagOpen;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `<!`, at declaration, comment, or CDATA.\n   *\n   * ```markdown\n   * > | a <!doctype> c\n   *         ^\n   * > | a <!--b--> c\n   *         ^\n   * > | a <![CDATA[>&<]]> c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function declarationOpen(code) {\n    if (code === 45) {\n      effects.consume(code);\n      return commentOpenInside;\n    }\n    if (code === 91) {\n      effects.consume(code);\n      index = 0;\n      return cdataOpenInside;\n    }\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      return declaration;\n    }\n    return nok(code);\n  }\n\n  /**\n   * In a comment, after `<!-`, at another `-`.\n   *\n   * ```markdown\n   * > | a <!--b--> c\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function commentOpenInside(code) {\n    if (code === 45) {\n      effects.consume(code);\n      return commentEnd;\n    }\n    return nok(code);\n  }\n\n  /**\n   * In comment.\n   *\n   * ```markdown\n   * > | a <!--b--> c\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function comment(code) {\n    if (code === null) {\n      return nok(code);\n    }\n    if (code === 45) {\n      effects.consume(code);\n      return commentClose;\n    }\n    if (markdownLineEnding(code)) {\n      returnState = comment;\n      return lineEndingBefore(code);\n    }\n    effects.consume(code);\n    return comment;\n  }\n\n  /**\n   * In comment, after `-`.\n   *\n   * ```markdown\n   * > | a <!--b--> c\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function commentClose(code) {\n    if (code === 45) {\n      effects.consume(code);\n      return commentEnd;\n    }\n    return comment(code);\n  }\n\n  /**\n   * In comment, after `--`.\n   *\n   * ```markdown\n   * > | a <!--b--> c\n   *              ^\n   * ```\n   *\n   * @type {State}\n   */\n  function commentEnd(code) {\n    return code === 62 ? end(code) : code === 45 ? commentClose(code) : comment(code);\n  }\n\n  /**\n   * After `<![`, in CDATA, expecting `CDATA[`.\n   *\n   * ```markdown\n   * > | a <![CDATA[>&<]]> b\n   *          ^^^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function cdataOpenInside(code) {\n    const value = 'CDATA[';\n    if (code === value.charCodeAt(index++)) {\n      effects.consume(code);\n      return index === value.length ? cdata : cdataOpenInside;\n    }\n    return nok(code);\n  }\n\n  /**\n   * In CDATA.\n   *\n   * ```markdown\n   * > | a <![CDATA[>&<]]> b\n   *                ^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function cdata(code) {\n    if (code === null) {\n      return nok(code);\n    }\n    if (code === 93) {\n      effects.consume(code);\n      return cdataClose;\n    }\n    if (markdownLineEnding(code)) {\n      returnState = cdata;\n      return lineEndingBefore(code);\n    }\n    effects.consume(code);\n    return cdata;\n  }\n\n  /**\n   * In CDATA, after `]`, at another `]`.\n   *\n   * ```markdown\n   * > | a <![CDATA[>&<]]> b\n   *                    ^\n   * ```\n   *\n   * @type {State}\n   */\n  function cdataClose(code) {\n    if (code === 93) {\n      effects.consume(code);\n      return cdataEnd;\n    }\n    return cdata(code);\n  }\n\n  /**\n   * In CDATA, after `]]`, at `>`.\n   *\n   * ```markdown\n   * > | a <![CDATA[>&<]]> b\n   *                     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function cdataEnd(code) {\n    if (code === 62) {\n      return end(code);\n    }\n    if (code === 93) {\n      effects.consume(code);\n      return cdataEnd;\n    }\n    return cdata(code);\n  }\n\n  /**\n   * In declaration.\n   *\n   * ```markdown\n   * > | a <!b> c\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function declaration(code) {\n    if (code === null || code === 62) {\n      return end(code);\n    }\n    if (markdownLineEnding(code)) {\n      returnState = declaration;\n      return lineEndingBefore(code);\n    }\n    effects.consume(code);\n    return declaration;\n  }\n\n  /**\n   * In instruction.\n   *\n   * ```markdown\n   * > | a <?b?> c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function instruction(code) {\n    if (code === null) {\n      return nok(code);\n    }\n    if (code === 63) {\n      effects.consume(code);\n      return instructionClose;\n    }\n    if (markdownLineEnding(code)) {\n      returnState = instruction;\n      return lineEndingBefore(code);\n    }\n    effects.consume(code);\n    return instruction;\n  }\n\n  /**\n   * In instruction, after `?`, at `>`.\n   *\n   * ```markdown\n   * > | a <?b?> c\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function instructionClose(code) {\n    return code === 62 ? end(code) : instruction(code);\n  }\n\n  /**\n   * After `</`, in closing tag, at tag name.\n   *\n   * ```markdown\n   * > | a </b> c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagCloseStart(code) {\n    // ASCII alphabetical.\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      return tagClose;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `</x`, in a tag name.\n   *\n   * ```markdown\n   * > | a </b> c\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagClose(code) {\n    // ASCII alphanumerical and `-`.\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code);\n      return tagClose;\n    }\n    return tagCloseBetween(code);\n  }\n\n  /**\n   * In closing tag, after tag name.\n   *\n   * ```markdown\n   * > | a </b> c\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagCloseBetween(code) {\n    if (markdownLineEnding(code)) {\n      returnState = tagCloseBetween;\n      return lineEndingBefore(code);\n    }\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return tagCloseBetween;\n    }\n    return end(code);\n  }\n\n  /**\n   * After `<x`, in opening tag name.\n   *\n   * ```markdown\n   * > | a <b> c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagOpen(code) {\n    // ASCII alphanumerical and `-`.\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code);\n      return tagOpen;\n    }\n    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code);\n    }\n    return nok(code);\n  }\n\n  /**\n   * In opening tag, after tag name.\n   *\n   * ```markdown\n   * > | a <b> c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagOpenBetween(code) {\n    if (code === 47) {\n      effects.consume(code);\n      return end;\n    }\n\n    // ASCII alphabetical and `:` and `_`.\n    if (code === 58 || code === 95 || asciiAlpha(code)) {\n      effects.consume(code);\n      return tagOpenAttributeName;\n    }\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenBetween;\n      return lineEndingBefore(code);\n    }\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return tagOpenBetween;\n    }\n    return end(code);\n  }\n\n  /**\n   * In attribute name.\n   *\n   * ```markdown\n   * > | a <b c> d\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagOpenAttributeName(code) {\n    // ASCII alphabetical and `-`, `.`, `:`, and `_`.\n    if (code === 45 || code === 46 || code === 58 || code === 95 || asciiAlphanumeric(code)) {\n      effects.consume(code);\n      return tagOpenAttributeName;\n    }\n    return tagOpenAttributeNameAfter(code);\n  }\n\n  /**\n   * After attribute name, before initializer, the end of the tag, or\n   * whitespace.\n   *\n   * ```markdown\n   * > | a <b c> d\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagOpenAttributeNameAfter(code) {\n    if (code === 61) {\n      effects.consume(code);\n      return tagOpenAttributeValueBefore;\n    }\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeNameAfter;\n      return lineEndingBefore(code);\n    }\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return tagOpenAttributeNameAfter;\n    }\n    return tagOpenBetween(code);\n  }\n\n  /**\n   * Before unquoted, double quoted, or single quoted attribute value, allowing\n   * whitespace.\n   *\n   * ```markdown\n   * > | a <b c=d> e\n   *            ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagOpenAttributeValueBefore(code) {\n    if (code === null || code === 60 || code === 61 || code === 62 || code === 96) {\n      return nok(code);\n    }\n    if (code === 34 || code === 39) {\n      effects.consume(code);\n      marker = code;\n      return tagOpenAttributeValueQuoted;\n    }\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeValueBefore;\n      return lineEndingBefore(code);\n    }\n    if (markdownSpace(code)) {\n      effects.consume(code);\n      return tagOpenAttributeValueBefore;\n    }\n    effects.consume(code);\n    return tagOpenAttributeValueUnquoted;\n  }\n\n  /**\n   * In double or single quoted attribute value.\n   *\n   * ```markdown\n   * > | a <b c=\"d\"> e\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagOpenAttributeValueQuoted(code) {\n    if (code === marker) {\n      effects.consume(code);\n      marker = undefined;\n      return tagOpenAttributeValueQuotedAfter;\n    }\n    if (code === null) {\n      return nok(code);\n    }\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeValueQuoted;\n      return lineEndingBefore(code);\n    }\n    effects.consume(code);\n    return tagOpenAttributeValueQuoted;\n  }\n\n  /**\n   * In unquoted attribute value.\n   *\n   * ```markdown\n   * > | a <b c=d> e\n   *            ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagOpenAttributeValueUnquoted(code) {\n    if (code === null || code === 34 || code === 39 || code === 60 || code === 61 || code === 96) {\n      return nok(code);\n    }\n    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code);\n    }\n    effects.consume(code);\n    return tagOpenAttributeValueUnquoted;\n  }\n\n  /**\n   * After double or single quoted attribute value, before whitespace or the end\n   * of the tag.\n   *\n   * ```markdown\n   * > | a <b c=\"d\"> e\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function tagOpenAttributeValueQuotedAfter(code) {\n    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code);\n    }\n    return nok(code);\n  }\n\n  /**\n   * In certain circumstances of a tag where only an `>` is allowed.\n   *\n   * ```markdown\n   * > | a <b c=\"d\"> e\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function end(code) {\n    if (code === 62) {\n      effects.consume(code);\n      effects.exit('htmlTextData');\n      effects.exit('htmlText');\n      return ok;\n    }\n    return nok(code);\n  }\n\n  /**\n   * At eol.\n   *\n   * >  **Note**: we cant have blank lines in text, so no need to worry about\n   * > empty tokens.\n   *\n   * ```markdown\n   * > | a <!--a\n   *            ^\n   *   | b-->\n   * ```\n   *\n   * @type {State}\n   */\n  function lineEndingBefore(code) {\n    effects.exit('htmlTextData');\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return lineEndingAfter;\n  }\n\n  /**\n   * After eol, at optional whitespace.\n   *\n   * >  **Note**: we cant have blank lines in text, so no need to worry about\n   * > empty tokens.\n   *\n   * ```markdown\n   *   | a <!--a\n   * > | b-->\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function lineEndingAfter(code) {\n    // Always populated by defaults.\n\n    return markdownSpace(code) ? factorySpace(effects, lineEndingAfterPrefix, 'linePrefix', self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code) : lineEndingAfterPrefix(code);\n  }\n\n  /**\n   * After eol, after optional whitespace.\n   *\n   * >  **Note**: we cant have blank lines in text, so no need to worry about\n   * > empty tokens.\n   *\n   * ```markdown\n   *   | a <!--a\n   * > | b-->\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function lineEndingAfterPrefix(code) {\n    effects.enter('htmlTextData');\n    return returnState(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { labelEnd } from './label-end.js';\n\n/** @type {Construct} */\nexport const labelStartLink = {\n  name: 'labelStartLink',\n  tokenize: tokenizeLabelStartLink,\n  resolveAll: labelEnd.resolveAll\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeLabelStartLink(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   * Start of label (link) start.\n   *\n   * ```markdown\n   * > | a [b] c\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('labelLink');\n    effects.enter('labelMarker');\n    effects.consume(code);\n    effects.exit('labelMarker');\n    effects.exit('labelLink');\n    return after;\n  }\n\n  /** @type {State} */\n  function after(code) {\n    // To do: this isnt needed in `micromark-extension-gfm-footnote`,\n    // remove.\n    // Hidden footnotes hook.\n    /* c8 ignore next 3 */\n    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs ? nok(code) : ok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {Construct} */\nexport const hardBreakEscape = {\n  name: 'hardBreakEscape',\n  tokenize: tokenizeHardBreakEscape\n};\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeHardBreakEscape(effects, ok, nok) {\n  return start;\n\n  /**\n   * Start of a hard break (escape).\n   *\n   * ```markdown\n   * > | a\\\n   *      ^\n   *   | b\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('hardBreakEscape');\n    effects.consume(code);\n    return after;\n  }\n\n  /**\n   * After `\\`, at eol.\n   *\n   * ```markdown\n   * > | a\\\n   *       ^\n   *   | b\n   * ```\n   *\n   *  @type {State}\n   */\n  function after(code) {\n    if (markdownLineEnding(code)) {\n      effects.exit('hardBreakEscape');\n      return ok(code);\n    }\n    return nok(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {Construct} */\nexport const codeText = {\n  name: 'codeText',\n  tokenize: tokenizeCodeText,\n  resolve: resolveCodeText,\n  previous\n};\n\n// To do: next major: dont resolve, like `markdown-rs`.\n/** @type {Resolver} */\nfunction resolveCodeText(events) {\n  let tailExitIndex = events.length - 4;\n  let headEnterIndex = 3;\n  /** @type {number} */\n  let index;\n  /** @type {number | undefined} */\n  let enter;\n\n  // If we start and end with an EOL or a space.\n  if ((events[headEnterIndex][1].type === 'lineEnding' || events[headEnterIndex][1].type === 'space') && (events[tailExitIndex][1].type === 'lineEnding' || events[tailExitIndex][1].type === 'space')) {\n    index = headEnterIndex;\n\n    // And we have data.\n    while (++index < tailExitIndex) {\n      if (events[index][1].type === 'codeTextData') {\n        // Then we have padding.\n        events[headEnterIndex][1].type = 'codeTextPadding';\n        events[tailExitIndex][1].type = 'codeTextPadding';\n        headEnterIndex += 2;\n        tailExitIndex -= 2;\n        break;\n      }\n    }\n  }\n\n  // Merge adjacent spaces and data.\n  index = headEnterIndex - 1;\n  tailExitIndex++;\n  while (++index <= tailExitIndex) {\n    if (enter === undefined) {\n      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {\n        enter = index;\n      }\n    } else if (index === tailExitIndex || events[index][1].type === 'lineEnding') {\n      events[enter][1].type = 'codeTextData';\n      if (index !== enter + 2) {\n        events[enter][1].end = events[index - 1][1].end;\n        events.splice(enter + 2, index - enter - 2);\n        tailExitIndex -= index - enter - 2;\n        index = enter + 2;\n      }\n      enter = undefined;\n    }\n  }\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Previous}\n */\nfunction previous(code) {\n  // If there is a previous code, there will always be a tail.\n  return code !== 96 || this.events[this.events.length - 1][1].type === 'characterEscape';\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeText(effects, ok, nok) {\n  const self = this;\n  let sizeOpen = 0;\n  /** @type {number} */\n  let size;\n  /** @type {Token} */\n  let token;\n  return start;\n\n  /**\n   * Start of code (text).\n   *\n   * ```markdown\n   * > | `a`\n   *     ^\n   * > | \\`a`\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('codeText');\n    effects.enter('codeTextSequence');\n    return sequenceOpen(code);\n  }\n\n  /**\n   * In opening sequence.\n   *\n   * ```markdown\n   * > | `a`\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === 96) {\n      effects.consume(code);\n      sizeOpen++;\n      return sequenceOpen;\n    }\n    effects.exit('codeTextSequence');\n    return between(code);\n  }\n\n  /**\n   * Between something and something else.\n   *\n   * ```markdown\n   * > | `a`\n   *      ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function between(code) {\n    // EOF.\n    if (code === null) {\n      return nok(code);\n    }\n\n    // To do: next major: dont do spaces in resolve, but when compiling,\n    // like `markdown-rs`.\n    // Tabs dont work, and virtual spaces dont make sense.\n    if (code === 32) {\n      effects.enter('space');\n      effects.consume(code);\n      effects.exit('space');\n      return between;\n    }\n\n    // Closing fence? Could also be data.\n    if (code === 96) {\n      token = effects.enter('codeTextSequence');\n      size = 0;\n      return sequenceClose(code);\n    }\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding');\n      effects.consume(code);\n      effects.exit('lineEnding');\n      return between;\n    }\n\n    // Data.\n    effects.enter('codeTextData');\n    return data(code);\n  }\n\n  /**\n   * In data.\n   *\n   * ```markdown\n   * > | `a`\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function data(code) {\n    if (code === null || code === 32 || code === 96 || markdownLineEnding(code)) {\n      effects.exit('codeTextData');\n      return between(code);\n    }\n    effects.consume(code);\n    return data;\n  }\n\n  /**\n   * In closing sequence.\n   *\n   * ```markdown\n   * > | `a`\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceClose(code) {\n    // More.\n    if (code === 96) {\n      effects.consume(code);\n      size++;\n      return sequenceClose;\n    }\n\n    // Done!\n    if (size === sizeOpen) {\n      effects.exit('codeTextSequence');\n      effects.exit('codeText');\n      return ok(code);\n    }\n\n    // More or less accents: mark as data.\n    token.type = 'codeTextData';\n    return data(code);\n  }\n}","/**\n * @typedef {import('micromark-util-types').Create} Create\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n */\n\nimport { combineExtensions } from 'micromark-util-combine-extensions';\nimport { content } from './initialize/content.js';\nimport { document } from './initialize/document.js';\nimport { flow } from './initialize/flow.js';\nimport { text, string } from './initialize/text.js';\nimport { createTokenizer } from './create-tokenizer.js';\nimport * as defaultConstructs from './constructs.js';\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n * @returns {ParseContext}\n */\nexport function parse(options) {\n  const settings = options || {};\n  const constructs = /** @type {FullNormalizedExtension} */\n  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);\n\n  /** @type {ParseContext} */\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  };\n  return parser;\n\n  /**\n   * @param {InitialConstruct} initial\n   */\n  function create(initial) {\n    return creator;\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from);\n    }\n  }\n}","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding | null | undefined} [encoding]\n * @param {boolean | null | undefined} [end=false]\n * @returns {Array<Chunk>}\n */\n\nconst search = /[\\0\\t\\n\\r]/g;\n\n/**\n * @returns {Preprocessor}\n */\nexport function preprocess() {\n  let column = 1;\n  let buffer = '';\n  /** @type {boolean | undefined} */\n  let start = true;\n  /** @type {boolean | undefined} */\n  let atCarriageReturn;\n  return preprocessor;\n\n  /** @type {Preprocessor} */\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = [];\n    /** @type {RegExpMatchArray | null} */\n    let match;\n    /** @type {number} */\n    let next;\n    /** @type {number} */\n    let startPosition;\n    /** @type {number} */\n    let endPosition;\n    /** @type {Code} */\n    let code;\n\n    // @ts-expect-error `Buffer` does allow an encoding.\n    value = buffer + value.toString(encoding);\n    startPosition = 0;\n    buffer = '';\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++;\n      }\n      start = undefined;\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition;\n      match = search.exec(value);\n      endPosition = match && match.index !== undefined ? match.index : value.length;\n      code = value.charCodeAt(endPosition);\n      if (!match) {\n        buffer = value.slice(startPosition);\n        break;\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3);\n        atCarriageReturn = undefined;\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5);\n          atCarriageReturn = undefined;\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition));\n          column += endPosition - startPosition;\n        }\n        switch (code) {\n          case 0:\n            {\n              chunks.push(65533);\n              column++;\n              break;\n            }\n          case 9:\n            {\n              next = Math.ceil(column / 4) * 4;\n              chunks.push(-2);\n              while (column++ < next) chunks.push(-1);\n              break;\n            }\n          case 10:\n            {\n              chunks.push(-4);\n              column = 1;\n              break;\n            }\n          default:\n            {\n              atCarriageReturn = true;\n              column = 1;\n            }\n        }\n      }\n      startPosition = endPosition + 1;\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5);\n      if (buffer) chunks.push(buffer);\n      chunks.push(null);\n    }\n    return chunks;\n  }\n}","/**\n * Turn the number (in string form as either hexa- or plain decimal) coming from\n * a numeric character reference into a character.\n *\n * Sort of like `String.fromCharCode(Number.parseInt(value, base))`, but makes\n * non-characters and control characters safe.\n *\n * @param {string} value\n *   Value to decode.\n * @param {number} base\n *   Numeric base.\n * @returns {string}\n *   Character.\n */\nexport function decodeNumericCharacterReference(value, base) {\n  const code = Number.parseInt(value, base);\n  if (\n  // C0 except for HT, LF, FF, CR, space.\n  code < 9 || code === 11 || code > 13 && code < 32 ||\n  // Control character (DEL) of C0, and C1 controls.\n  code > 126 && code < 160 ||\n  // Lone high surrogates and low surrogates.\n  code > 55295 && code < 57344 ||\n  // Noncharacters.\n  code > 64975 && code < 65008 /* eslint-disable no-bitwise */ || (code & 65535) === 65535 || (code & 65535) === 65534 /* eslint-enable no-bitwise */ ||\n  // Out of range\n  code > 1114111) {\n    return '\\uFFFD';\n  }\n  return String.fromCharCode(code);\n}","import { decodeNamedCharacterReference } from 'decode-named-character-reference';\nimport { decodeNumericCharacterReference } from 'micromark-util-decode-numeric-character-reference';\nconst characterEscapeOrReference = /\\\\([!-/:-@[-`{-~])|&(#(?:\\d{1,7}|x[\\da-f]{1,6})|[\\da-z]{1,31});/gi;\n\n/**\n * Decode markdown strings (which occur in places such as fenced code info\n * strings, destinations, labels, and titles).\n *\n * The string content type allows character escapes and -references.\n * This decodes those.\n *\n * @param {string} value\n *   Value to decode.\n * @returns {string}\n *   Decoded value.\n */\nexport function decodeString(value) {\n  return value.replace(characterEscapeOrReference, decode);\n}\n\n/**\n * @param {string} $0\n * @param {string} $1\n * @param {string} $2\n * @returns {string}\n */\nfunction decode($0, $1, $2) {\n  if ($1) {\n    // Escape.\n    return $1;\n  }\n\n  // Reference.\n  const head = $2.charCodeAt(0);\n  if (head === 35) {\n    const head = $2.charCodeAt(1);\n    const hex = head === 120 || head === 88;\n    return decodeNumericCharacterReference($2.slice(hex ? 2 : 1), hex ? 16 : 10);\n  }\n  return decodeNamedCharacterReference($2) || $0;\n}","/**\n * @typedef {import('unist').Node} Node\n * @typedef {import('unist').Point} Point\n * @typedef {import('unist').Position} Position\n */\n\n/**\n * @typedef NodeLike\n * @property {string} type\n * @property {PositionLike | null | undefined} [position]\n *\n * @typedef PositionLike\n * @property {PointLike | null | undefined} [start]\n * @property {PointLike | null | undefined} [end]\n *\n * @typedef PointLike\n * @property {number | null | undefined} [line]\n * @property {number | null | undefined} [column]\n * @property {number | null | undefined} [offset]\n */\n\n/**\n * Serialize the positional info of a point, position (start and end points),\n * or node.\n *\n * @param {Node | NodeLike | Position | PositionLike | Point | PointLike | null | undefined} [value]\n *   Node, position, or point.\n * @returns {string}\n *   Pretty printed positional info of a node (`string`).\n *\n *   In the format of a range `ls:cs-le:ce` (when given `node` or `position`)\n *   or a point `l:c` (when given `point`), where `l` stands for line, `c` for\n *   column, `s` for `start`, and `e` for end.\n *   An empty string (`''`) is returned if the given value is neither `node`,\n *   `position`, nor `point`.\n */\nexport function stringifyPosition(value) {\n  // Nothing.\n  if (!value || typeof value !== 'object') {\n    return '';\n  }\n\n  // Node.\n  if ('position' in value || 'type' in value) {\n    return position(value.position);\n  }\n\n  // Position.\n  if ('start' in value || 'end' in value) {\n    return position(value);\n  }\n\n  // Point.\n  if ('line' in value || 'column' in value) {\n    return point(value);\n  }\n\n  // ?\n  return '';\n}\n\n/**\n * @param {Point | PointLike | null | undefined} point\n * @returns {string}\n */\nfunction point(point) {\n  return index(point && point.line) + ':' + index(point && point.column);\n}\n\n/**\n * @param {Position | PositionLike | null | undefined} pos\n * @returns {string}\n */\nfunction position(pos) {\n  return point(pos && pos.start) + '-' + point(pos && pos.end);\n}\n\n/**\n * @param {number | null | undefined} value\n * @returns {number}\n */\nfunction index(value) {\n  return value && typeof value === 'number' ? value : 1;\n}","/**\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Value} Value\n *\n * @typedef {import('unist').Parent} UnistParent\n * @typedef {import('unist').Point} Point\n *\n * @typedef {import('mdast').PhrasingContent} PhrasingContent\n * @typedef {import('mdast').StaticPhrasingContent} StaticPhrasingContent\n * @typedef {import('mdast').Content} Content\n * @typedef {import('mdast').Break} Break\n * @typedef {import('mdast').Blockquote} Blockquote\n * @typedef {import('mdast').Code} Code\n * @typedef {import('mdast').Definition} Definition\n * @typedef {import('mdast').Emphasis} Emphasis\n * @typedef {import('mdast').Heading} Heading\n * @typedef {import('mdast').HTML} HTML\n * @typedef {import('mdast').Image} Image\n * @typedef {import('mdast').ImageReference} ImageReference\n * @typedef {import('mdast').InlineCode} InlineCode\n * @typedef {import('mdast').Link} Link\n * @typedef {import('mdast').LinkReference} LinkReference\n * @typedef {import('mdast').List} List\n * @typedef {import('mdast').ListItem} ListItem\n * @typedef {import('mdast').Paragraph} Paragraph\n * @typedef {import('mdast').Root} Root\n * @typedef {import('mdast').Strong} Strong\n * @typedef {import('mdast').Text} Text\n * @typedef {import('mdast').ThematicBreak} ThematicBreak\n * @typedef {import('mdast').ReferenceType} ReferenceType\n * @typedef {import('../index.js').CompileData} CompileData\n */\n\n/**\n * @typedef {Root | Content} Node\n * @typedef {Extract<Node, UnistParent>} Parent\n *\n * @typedef {Omit<UnistParent, 'type' | 'children'> & {type: 'fragment', children: Array<PhrasingContent>}} Fragment\n */\n\n/**\n * @callback Transform\n *   Extra transform, to change the AST afterwards.\n * @param {Root} tree\n *   Tree to transform.\n * @returns {Root | undefined | null | void}\n *   New tree or nothing (in which case the current tree is used).\n *\n * @callback Handle\n *   Handle a token.\n * @param {CompileContext} this\n *   Context.\n * @param {Token} token\n *   Current token.\n * @returns {void}\n *   Nothing.\n *\n * @typedef {Record<string, Handle>} Handles\n *   Token types mapping to handles\n *\n * @callback OnEnterError\n *   Handle the case where the `right` token is open, but it is closed (by the\n *   `left` token) or because we reached the end of the document.\n * @param {Omit<CompileContext, 'sliceSerialize'>} this\n *   Context.\n * @param {Token | undefined} left\n *   Left token.\n * @param {Token} right\n *   Right token.\n * @returns {void}\n *   Nothing.\n *\n * @callback OnExitError\n *   Handle the case where the `right` token is open but it is closed by\n *   exiting the `left` token.\n * @param {Omit<CompileContext, 'sliceSerialize'>} this\n *   Context.\n * @param {Token} left\n *   Left token.\n * @param {Token} right\n *   Right token.\n * @returns {void}\n *   Nothing.\n *\n * @typedef {[Token, OnEnterError | undefined]} TokenTuple\n *   Open token on the stack, with an optional error handler for when\n *   that token isnt closed properly.\n */\n\n/**\n * @typedef Config\n *   Configuration.\n *\n *   We have our defaults, but extensions will add more.\n * @property {Array<string>} canContainEols\n *   Token types where line endings are used.\n * @property {Handles} enter\n *   Opening handles.\n * @property {Handles} exit\n *   Closing handles.\n * @property {Array<Transform>} transforms\n *   Tree transforms.\n *\n * @typedef {Partial<Config>} Extension\n *   Change how markdown tokens from micromark are turned into mdast.\n *\n * @typedef CompileContext\n *   mdast compiler context.\n * @property {Array<Node | Fragment>} stack\n *   Stack of nodes.\n * @property {Array<TokenTuple>} tokenStack\n *   Stack of tokens.\n * @property {<Key extends keyof CompileData>(key: Key) => CompileData[Key]} getData\n *   Get data from the key/value store.\n * @property {<Key extends keyof CompileData>(key: Key, value?: CompileData[Key]) => void} setData\n *   Set data into the key/value store.\n * @property {(this: CompileContext) => void} buffer\n *   Capture some of the output data.\n * @property {(this: CompileContext) => string} resume\n *   Stop capturing and access the output data.\n * @property {<Kind extends Node>(this: CompileContext, node: Kind, token: Token, onError?: OnEnterError) => Kind} enter\n *   Enter a token.\n * @property {(this: CompileContext, token: Token, onError?: OnExitError) => Node} exit\n *   Exit a token.\n * @property {TokenizeContext['sliceSerialize']} sliceSerialize\n *   Get the string value of a token.\n * @property {Config} config\n *   Configuration.\n *\n * @typedef FromMarkdownOptions\n *   Configuration for how to build mdast.\n * @property {Array<Extension | Array<Extension>> | null | undefined} [mdastExtensions]\n *   Extensions for this utility to change how tokens are turned into a tree.\n *\n * @typedef {ParseOptions & FromMarkdownOptions} Options\n *   Configuration.\n */\n\n// To do: micromark: create a registry of tokens?\n// To do: next major: dont return given `Node` from `enter`.\n// To do: next major: remove setter/getter.\n\nimport { toString } from 'mdast-util-to-string';\nimport { parse } from 'micromark/lib/parse.js';\nimport { preprocess } from 'micromark/lib/preprocess.js';\nimport { postprocess } from 'micromark/lib/postprocess.js';\nimport { decodeNumericCharacterReference } from 'micromark-util-decode-numeric-character-reference';\nimport { decodeString } from 'micromark-util-decode-string';\nimport { normalizeIdentifier } from 'micromark-util-normalize-identifier';\nimport { decodeNamedCharacterReference } from 'decode-named-character-reference';\nimport { stringifyPosition } from 'unist-util-stringify-position';\nconst own = {}.hasOwnProperty;\n\n/**\n * @param value\n *   Markdown to parse.\n * @param encoding\n *   Character encoding for when `value` is `Buffer`.\n * @param options\n *   Configuration.\n * @returns\n *   mdast tree.\n */\nexport const fromMarkdown =\n/**\n * @type {(\n *   ((value: Value, encoding: Encoding, options?: Options | null | undefined) => Root) &\n *   ((value: Value, options?: Options | null | undefined) => Root)\n * )}\n */\n\n/**\n * @param {Value} value\n * @param {Encoding | Options | null | undefined} [encoding]\n * @param {Options | null | undefined} [options]\n * @returns {Root}\n */\nfunction (value, encoding, options) {\n  if (typeof encoding !== 'string') {\n    options = encoding;\n    encoding = undefined;\n  }\n  return compiler(options)(postprocess(parse(options).document().write(preprocess()(value, encoding, true))));\n};\n\n/**\n * Note this compiler only understand complete buffering, not streaming.\n *\n * @param {Options | null | undefined} [options]\n */\nfunction compiler(options) {\n  /** @type {Config} */\n  const config = {\n    transforms: [],\n    canContainEols: ['emphasis', 'fragment', 'heading', 'paragraph', 'strong'],\n    enter: {\n      autolink: opener(link),\n      autolinkProtocol: onenterdata,\n      autolinkEmail: onenterdata,\n      atxHeading: opener(heading),\n      blockQuote: opener(blockQuote),\n      characterEscape: onenterdata,\n      characterReference: onenterdata,\n      codeFenced: opener(codeFlow),\n      codeFencedFenceInfo: buffer,\n      codeFencedFenceMeta: buffer,\n      codeIndented: opener(codeFlow, buffer),\n      codeText: opener(codeText, buffer),\n      codeTextData: onenterdata,\n      data: onenterdata,\n      codeFlowValue: onenterdata,\n      definition: opener(definition),\n      definitionDestinationString: buffer,\n      definitionLabelString: buffer,\n      definitionTitleString: buffer,\n      emphasis: opener(emphasis),\n      hardBreakEscape: opener(hardBreak),\n      hardBreakTrailing: opener(hardBreak),\n      htmlFlow: opener(html, buffer),\n      htmlFlowData: onenterdata,\n      htmlText: opener(html, buffer),\n      htmlTextData: onenterdata,\n      image: opener(image),\n      label: buffer,\n      link: opener(link),\n      listItem: opener(listItem),\n      listItemValue: onenterlistitemvalue,\n      listOrdered: opener(list, onenterlistordered),\n      listUnordered: opener(list),\n      paragraph: opener(paragraph),\n      reference: onenterreference,\n      referenceString: buffer,\n      resourceDestinationString: buffer,\n      resourceTitleString: buffer,\n      setextHeading: opener(heading),\n      strong: opener(strong),\n      thematicBreak: opener(thematicBreak)\n    },\n    exit: {\n      atxHeading: closer(),\n      atxHeadingSequence: onexitatxheadingsequence,\n      autolink: closer(),\n      autolinkEmail: onexitautolinkemail,\n      autolinkProtocol: onexitautolinkprotocol,\n      blockQuote: closer(),\n      characterEscapeValue: onexitdata,\n      characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,\n      characterReferenceMarkerNumeric: onexitcharacterreferencemarker,\n      characterReferenceValue: onexitcharacterreferencevalue,\n      codeFenced: closer(onexitcodefenced),\n      codeFencedFence: onexitcodefencedfence,\n      codeFencedFenceInfo: onexitcodefencedfenceinfo,\n      codeFencedFenceMeta: onexitcodefencedfencemeta,\n      codeFlowValue: onexitdata,\n      codeIndented: closer(onexitcodeindented),\n      codeText: closer(onexitcodetext),\n      codeTextData: onexitdata,\n      data: onexitdata,\n      definition: closer(),\n      definitionDestinationString: onexitdefinitiondestinationstring,\n      definitionLabelString: onexitdefinitionlabelstring,\n      definitionTitleString: onexitdefinitiontitlestring,\n      emphasis: closer(),\n      hardBreakEscape: closer(onexithardbreak),\n      hardBreakTrailing: closer(onexithardbreak),\n      htmlFlow: closer(onexithtmlflow),\n      htmlFlowData: onexitdata,\n      htmlText: closer(onexithtmltext),\n      htmlTextData: onexitdata,\n      image: closer(onexitimage),\n      label: onexitlabel,\n      labelText: onexitlabeltext,\n      lineEnding: onexitlineending,\n      link: closer(onexitlink),\n      listItem: closer(),\n      listOrdered: closer(),\n      listUnordered: closer(),\n      paragraph: closer(),\n      referenceString: onexitreferencestring,\n      resourceDestinationString: onexitresourcedestinationstring,\n      resourceTitleString: onexitresourcetitlestring,\n      resource: onexitresource,\n      setextHeading: closer(onexitsetextheading),\n      setextHeadingLineSequence: onexitsetextheadinglinesequence,\n      setextHeadingText: onexitsetextheadingtext,\n      strong: closer(),\n      thematicBreak: closer()\n    }\n  };\n  configure(config, (options || {}).mdastExtensions || []);\n\n  /** @type {CompileData} */\n  const data = {};\n  return compile;\n\n  /**\n   * Turn micromark events into an mdast tree.\n   *\n   * @param {Array<Event>} events\n   *   Events.\n   * @returns {Root}\n   *   mdast tree.\n   */\n  function compile(events) {\n    /** @type {Root} */\n    let tree = {\n      type: 'root',\n      children: []\n    };\n    /** @type {Omit<CompileContext, 'sliceSerialize'>} */\n    const context = {\n      stack: [tree],\n      tokenStack: [],\n      config,\n      enter,\n      exit,\n      buffer,\n      resume,\n      setData,\n      getData\n    };\n    /** @type {Array<number>} */\n    const listStack = [];\n    let index = -1;\n    while (++index < events.length) {\n      // We preprocess lists to add `listItem` tokens, and to infer whether\n      // items the list itself are spread out.\n      if (events[index][1].type === 'listOrdered' || events[index][1].type === 'listUnordered') {\n        if (events[index][0] === 'enter') {\n          listStack.push(index);\n        } else {\n          const tail = listStack.pop();\n          index = prepareList(events, tail, index);\n        }\n      }\n    }\n    index = -1;\n    while (++index < events.length) {\n      const handler = config[events[index][0]];\n      if (own.call(handler, events[index][1].type)) {\n        handler[events[index][1].type].call(Object.assign({\n          sliceSerialize: events[index][2].sliceSerialize\n        }, context), events[index][1]);\n      }\n    }\n\n    // Handle tokens still being open.\n    if (context.tokenStack.length > 0) {\n      const tail = context.tokenStack[context.tokenStack.length - 1];\n      const handler = tail[1] || defaultOnError;\n      handler.call(context, undefined, tail[0]);\n    }\n\n    // Figure out `root` position.\n    tree.position = {\n      start: point(events.length > 0 ? events[0][1].start : {\n        line: 1,\n        column: 1,\n        offset: 0\n      }),\n      end: point(events.length > 0 ? events[events.length - 2][1].end : {\n        line: 1,\n        column: 1,\n        offset: 0\n      })\n    };\n\n    // Call transforms.\n    index = -1;\n    while (++index < config.transforms.length) {\n      tree = config.transforms[index](tree) || tree;\n    }\n    return tree;\n  }\n\n  /**\n   * @param {Array<Event>} events\n   * @param {number} start\n   * @param {number} length\n   * @returns {number}\n   */\n  function prepareList(events, start, length) {\n    let index = start - 1;\n    let containerBalance = -1;\n    let listSpread = false;\n    /** @type {Token | undefined} */\n    let listItem;\n    /** @type {number | undefined} */\n    let lineIndex;\n    /** @type {number | undefined} */\n    let firstBlankLineIndex;\n    /** @type {boolean | undefined} */\n    let atMarker;\n    while (++index <= length) {\n      const event = events[index];\n      if (event[1].type === 'listUnordered' || event[1].type === 'listOrdered' || event[1].type === 'blockQuote') {\n        if (event[0] === 'enter') {\n          containerBalance++;\n        } else {\n          containerBalance--;\n        }\n        atMarker = undefined;\n      } else if (event[1].type === 'lineEndingBlank') {\n        if (event[0] === 'enter') {\n          if (listItem && !atMarker && !containerBalance && !firstBlankLineIndex) {\n            firstBlankLineIndex = index;\n          }\n          atMarker = undefined;\n        }\n      } else if (event[1].type === 'linePrefix' || event[1].type === 'listItemValue' || event[1].type === 'listItemMarker' || event[1].type === 'listItemPrefix' || event[1].type === 'listItemPrefixWhitespace') {\n        // Empty.\n      } else {\n        atMarker = undefined;\n      }\n      if (!containerBalance && event[0] === 'enter' && event[1].type === 'listItemPrefix' || containerBalance === -1 && event[0] === 'exit' && (event[1].type === 'listUnordered' || event[1].type === 'listOrdered')) {\n        if (listItem) {\n          let tailIndex = index;\n          lineIndex = undefined;\n          while (tailIndex--) {\n            const tailEvent = events[tailIndex];\n            if (tailEvent[1].type === 'lineEnding' || tailEvent[1].type === 'lineEndingBlank') {\n              if (tailEvent[0] === 'exit') continue;\n              if (lineIndex) {\n                events[lineIndex][1].type = 'lineEndingBlank';\n                listSpread = true;\n              }\n              tailEvent[1].type = 'lineEnding';\n              lineIndex = tailIndex;\n            } else if (tailEvent[1].type === 'linePrefix' || tailEvent[1].type === 'blockQuotePrefix' || tailEvent[1].type === 'blockQuotePrefixWhitespace' || tailEvent[1].type === 'blockQuoteMarker' || tailEvent[1].type === 'listItemIndent') {\n              // Empty\n            } else {\n              break;\n            }\n          }\n          if (firstBlankLineIndex && (!lineIndex || firstBlankLineIndex < lineIndex)) {\n            listItem._spread = true;\n          }\n\n          // Fix position.\n          listItem.end = Object.assign({}, lineIndex ? events[lineIndex][1].start : event[1].end);\n          events.splice(lineIndex || index, 0, ['exit', listItem, event[2]]);\n          index++;\n          length++;\n        }\n\n        // Create a new list item.\n        if (event[1].type === 'listItemPrefix') {\n          listItem = {\n            type: 'listItem',\n            _spread: false,\n            start: Object.assign({}, event[1].start),\n            // @ts-expect-error: well add `end` in a second.\n            end: undefined\n          };\n          // @ts-expect-error: `listItem` is most definitely defined, TS...\n          events.splice(index, 0, ['enter', listItem, event[2]]);\n          index++;\n          length++;\n          firstBlankLineIndex = undefined;\n          atMarker = true;\n        }\n      }\n    }\n    events[start][1]._spread = listSpread;\n    return length;\n  }\n\n  /**\n   * Set data.\n   *\n   * @template {keyof CompileData} Key\n   *   Field type.\n   * @param {Key} key\n   *   Key of field.\n   * @param {CompileData[Key]} [value]\n   *   New value.\n   * @returns {void}\n   *   Nothing.\n   */\n  function setData(key, value) {\n    data[key] = value;\n  }\n\n  /**\n   * Get data.\n   *\n   * @template {keyof CompileData} Key\n   *   Field type.\n   * @param {Key} key\n   *   Key of field.\n   * @returns {CompileData[Key]}\n   *   Value.\n   */\n  function getData(key) {\n    return data[key];\n  }\n\n  /**\n   * Create an opener handle.\n   *\n   * @param {(token: Token) => Node} create\n   *   Create a node.\n   * @param {Handle} [and]\n   *   Optional function to also run.\n   * @returns {Handle}\n   *   Handle.\n   */\n  function opener(create, and) {\n    return open;\n\n    /**\n     * @this {CompileContext}\n     * @param {Token} token\n     * @returns {void}\n     */\n    function open(token) {\n      enter.call(this, create(token), token);\n      if (and) and.call(this, token);\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @returns {void}\n   */\n  function buffer() {\n    this.stack.push({\n      type: 'fragment',\n      children: []\n    });\n  }\n\n  /**\n   * @template {Node} Kind\n   *   Node type.\n   * @this {CompileContext}\n   *   Context.\n   * @param {Kind} node\n   *   Node to enter.\n   * @param {Token} token\n   *   Corresponding token.\n   * @param {OnEnterError | undefined} [errorHandler]\n   *   Handle the case where this token is open, but it is closed by something else.\n   * @returns {Kind}\n   *   The given node.\n   */\n  function enter(node, token, errorHandler) {\n    const parent = this.stack[this.stack.length - 1];\n    // @ts-expect-error: Assume `Node` can exist as a child of `parent`.\n    parent.children.push(node);\n    this.stack.push(node);\n    this.tokenStack.push([token, errorHandler]);\n    // @ts-expect-error: `end` will be patched later.\n    node.position = {\n      start: point(token.start)\n    };\n    return node;\n  }\n\n  /**\n   * Create a closer handle.\n   *\n   * @param {Handle} [and]\n   *   Optional function to also run.\n   * @returns {Handle}\n   *   Handle.\n   */\n  function closer(and) {\n    return close;\n\n    /**\n     * @this {CompileContext}\n     * @param {Token} token\n     * @returns {void}\n     */\n    function close(token) {\n      if (and) and.call(this, token);\n      exit.call(this, token);\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   *   Context.\n   * @param {Token} token\n   *   Corresponding token.\n   * @param {OnExitError | undefined} [onExitError]\n   *   Handle the case where another token is open.\n   * @returns {Node}\n   *   The closed node.\n   */\n  function exit(token, onExitError) {\n    const node = this.stack.pop();\n    const open = this.tokenStack.pop();\n    if (!open) {\n      throw new Error('Cannot close `' + token.type + '` (' + stringifyPosition({\n        start: token.start,\n        end: token.end\n      }) + '): its not open');\n    } else if (open[0].type !== token.type) {\n      if (onExitError) {\n        onExitError.call(this, token, open[0]);\n      } else {\n        const handler = open[1] || defaultOnError;\n        handler.call(this, token, open[0]);\n      }\n    }\n    node.position.end = point(token.end);\n    return node;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @returns {string}\n   */\n  function resume() {\n    return toString(this.stack.pop());\n  }\n\n  //\n  // Handlers.\n  //\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistordered() {\n    setData('expectingFirstListItemValue', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistitemvalue(token) {\n    if (getData('expectingFirstListItemValue')) {\n      const ancestor = this.stack[this.stack.length - 2];\n      ancestor.start = Number.parseInt(this.sliceSerialize(token), 10);\n      setData('expectingFirstListItemValue');\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfenceinfo() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.lang = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfencemeta() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.meta = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfence() {\n    // Exit if this is the closing fence.\n    if (getData('flowCodeInside')) return;\n    this.buffer();\n    setData('flowCodeInside', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefenced() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.value = data.replace(/^(\\r?\\n|\\r)|(\\r?\\n|\\r)$/g, '');\n    setData('flowCodeInside');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodeindented() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.value = data.replace(/(\\r?\\n|\\r)$/g, '');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitionlabelstring(token) {\n    const label = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.label = label;\n    node.identifier = normalizeIdentifier(this.sliceSerialize(token)).toLowerCase();\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiontitlestring() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.title = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiondestinationstring() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.url = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitatxheadingsequence(token) {\n    const node = this.stack[this.stack.length - 1];\n    if (!node.depth) {\n      const depth = this.sliceSerialize(token).length;\n      node.depth = depth;\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadingtext() {\n    setData('setextHeadingSlurpLineEnding', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadinglinesequence(token) {\n    const node = this.stack[this.stack.length - 1];\n    node.depth = this.sliceSerialize(token).charCodeAt(0) === 61 ? 1 : 2;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheading() {\n    setData('setextHeadingSlurpLineEnding');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onenterdata(token) {\n    const node = this.stack[this.stack.length - 1];\n    let tail = node.children[node.children.length - 1];\n    if (!tail || tail.type !== 'text') {\n      // Add a new text node.\n      tail = text();\n      // @ts-expect-error: well add `end` later.\n      tail.position = {\n        start: point(token.start)\n      };\n      // @ts-expect-error: Assume `parent` accepts `text`.\n      node.children.push(tail);\n    }\n    this.stack.push(tail);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitdata(token) {\n    const tail = this.stack.pop();\n    tail.value += this.sliceSerialize(token);\n    tail.position.end = point(token.end);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitlineending(token) {\n    const context = this.stack[this.stack.length - 1];\n    // If were at a hard break, include the line ending in there.\n    if (getData('atHardBreak')) {\n      const tail = context.children[context.children.length - 1];\n      tail.position.end = point(token.end);\n      setData('atHardBreak');\n      return;\n    }\n    if (!getData('setextHeadingSlurpLineEnding') && config.canContainEols.includes(context.type)) {\n      onenterdata.call(this, token);\n      onexitdata.call(this, token);\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexithardbreak() {\n    setData('atHardBreak', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexithtmlflow() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.value = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexithtmltext() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.value = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitcodetext() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.value = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitlink() {\n    const node = this.stack[this.stack.length - 1];\n    // Note: there are also `identifier` and `label` fields on this link node!\n    // These are used / cleaned here.\n    // To do: clean.\n    if (getData('inReference')) {\n      /** @type {ReferenceType} */\n      const referenceType = getData('referenceType') || 'shortcut';\n      node.type += 'Reference';\n      // @ts-expect-error: mutate.\n      node.referenceType = referenceType;\n      // @ts-expect-error: mutate.\n      delete node.url;\n      delete node.title;\n    } else {\n      // @ts-expect-error: mutate.\n      delete node.identifier;\n      // @ts-expect-error: mutate.\n      delete node.label;\n    }\n    setData('referenceType');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitimage() {\n    const node = this.stack[this.stack.length - 1];\n    // Note: there are also `identifier` and `label` fields on this link node!\n    // These are used / cleaned here.\n    // To do: clean.\n    if (getData('inReference')) {\n      /** @type {ReferenceType} */\n      const referenceType = getData('referenceType') || 'shortcut';\n      node.type += 'Reference';\n      // @ts-expect-error: mutate.\n      node.referenceType = referenceType;\n      // @ts-expect-error: mutate.\n      delete node.url;\n      delete node.title;\n    } else {\n      // @ts-expect-error: mutate.\n      delete node.identifier;\n      // @ts-expect-error: mutate.\n      delete node.label;\n    }\n    setData('referenceType');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitlabeltext(token) {\n    const string = this.sliceSerialize(token);\n    const ancestor = this.stack[this.stack.length - 2];\n    // @ts-expect-error: stash this on the node, as it might become a reference\n    // later.\n    ancestor.label = decodeString(string);\n    // @ts-expect-error: same as above.\n    ancestor.identifier = normalizeIdentifier(string).toLowerCase();\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitlabel() {\n    const fragment = this.stack[this.stack.length - 1];\n    const value = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    // Assume a reference.\n    setData('inReference', true);\n    if (node.type === 'link') {\n      /** @type {Array<StaticPhrasingContent>} */\n      // @ts-expect-error: Assume static phrasing content.\n      const children = fragment.children;\n      node.children = children;\n    } else {\n      node.alt = value;\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitresourcedestinationstring() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.url = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitresourcetitlestring() {\n    const data = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    node.title = data;\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitresource() {\n    setData('inReference');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onenterreference() {\n    setData('referenceType', 'collapsed');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitreferencestring(token) {\n    const label = this.resume();\n    const node = this.stack[this.stack.length - 1];\n    // @ts-expect-error: stash this on the node, as it might become a reference\n    // later.\n    node.label = label;\n    // @ts-expect-error: same as above.\n    node.identifier = normalizeIdentifier(this.sliceSerialize(token)).toLowerCase();\n    setData('referenceType', 'full');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitcharacterreferencemarker(token) {\n    setData('characterReferenceType', token.type);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcharacterreferencevalue(token) {\n    const data = this.sliceSerialize(token);\n    const type = getData('characterReferenceType');\n    /** @type {string} */\n    let value;\n    if (type) {\n      value = decodeNumericCharacterReference(data, type === 'characterReferenceMarkerNumeric' ? 10 : 16);\n      setData('characterReferenceType');\n    } else {\n      const result = decodeNamedCharacterReference(data);\n      value = result;\n    }\n    const tail = this.stack.pop();\n    tail.value += value;\n    tail.position.end = point(token.end);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkprotocol(token) {\n    onexitdata.call(this, token);\n    const node = this.stack[this.stack.length - 1];\n    node.url = this.sliceSerialize(token);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkemail(token) {\n    onexitdata.call(this, token);\n    const node = this.stack[this.stack.length - 1];\n    node.url = 'mailto:' + this.sliceSerialize(token);\n  }\n\n  //\n  // Creaters.\n  //\n\n  /** @returns {Blockquote} */\n  function blockQuote() {\n    return {\n      type: 'blockquote',\n      children: []\n    };\n  }\n\n  /** @returns {Code} */\n  function codeFlow() {\n    return {\n      type: 'code',\n      lang: null,\n      meta: null,\n      value: ''\n    };\n  }\n\n  /** @returns {InlineCode} */\n  function codeText() {\n    return {\n      type: 'inlineCode',\n      value: ''\n    };\n  }\n\n  /** @returns {Definition} */\n  function definition() {\n    return {\n      type: 'definition',\n      identifier: '',\n      label: null,\n      title: null,\n      url: ''\n    };\n  }\n\n  /** @returns {Emphasis} */\n  function emphasis() {\n    return {\n      type: 'emphasis',\n      children: []\n    };\n  }\n\n  /** @returns {Heading} */\n  function heading() {\n    // @ts-expect-error `depth` will be set later.\n    return {\n      type: 'heading',\n      depth: undefined,\n      children: []\n    };\n  }\n\n  /** @returns {Break} */\n  function hardBreak() {\n    return {\n      type: 'break'\n    };\n  }\n\n  /** @returns {HTML} */\n  function html() {\n    return {\n      type: 'html',\n      value: ''\n    };\n  }\n\n  /** @returns {Image} */\n  function image() {\n    return {\n      type: 'image',\n      title: null,\n      url: '',\n      alt: null\n    };\n  }\n\n  /** @returns {Link} */\n  function link() {\n    return {\n      type: 'link',\n      title: null,\n      url: '',\n      children: []\n    };\n  }\n\n  /**\n   * @param {Token} token\n   * @returns {List}\n   */\n  function list(token) {\n    return {\n      type: 'list',\n      ordered: token.type === 'listOrdered',\n      start: null,\n      spread: token._spread,\n      children: []\n    };\n  }\n\n  /**\n   * @param {Token} token\n   * @returns {ListItem}\n   */\n  function listItem(token) {\n    return {\n      type: 'listItem',\n      spread: token._spread,\n      checked: null,\n      children: []\n    };\n  }\n\n  /** @returns {Paragraph} */\n  function paragraph() {\n    return {\n      type: 'paragraph',\n      children: []\n    };\n  }\n\n  /** @returns {Strong} */\n  function strong() {\n    return {\n      type: 'strong',\n      children: []\n    };\n  }\n\n  /** @returns {Text} */\n  function text() {\n    return {\n      type: 'text',\n      value: ''\n    };\n  }\n\n  /** @returns {ThematicBreak} */\n  function thematicBreak() {\n    return {\n      type: 'thematicBreak'\n    };\n  }\n}\n\n/**\n * Copy a point-like value.\n *\n * @param {Point} d\n *   Point-like value.\n * @returns {Point}\n *   unist point.\n */\nfunction point(d) {\n  return {\n    line: d.line,\n    column: d.column,\n    offset: d.offset\n  };\n}\n\n/**\n * @param {Config} combined\n * @param {Array<Extension | Array<Extension>>} extensions\n * @returns {void}\n */\nfunction configure(combined, extensions) {\n  let index = -1;\n  while (++index < extensions.length) {\n    const value = extensions[index];\n    if (Array.isArray(value)) {\n      configure(combined, value);\n    } else {\n      extension(combined, value);\n    }\n  }\n}\n\n/**\n * @param {Config} combined\n * @param {Extension} extension\n * @returns {void}\n */\nfunction extension(combined, extension) {\n  /** @type {keyof Extension} */\n  let key;\n  for (key in extension) {\n    if (own.call(extension, key)) {\n      if (key === 'canContainEols') {\n        const right = extension[key];\n        if (right) {\n          combined[key].push(...right);\n        }\n      } else if (key === 'transforms') {\n        const right = extension[key];\n        if (right) {\n          combined[key].push(...right);\n        }\n      } else if (key === 'enter' || key === 'exit') {\n        const right = extension[key];\n        if (right) {\n          Object.assign(combined[key], right);\n        }\n      }\n    }\n  }\n}\n\n/** @type {OnEnterError} */\nfunction defaultOnError(left, right) {\n  if (left) {\n    throw new Error('Cannot close `' + left.type + '` (' + stringifyPosition({\n      start: left.start,\n      end: left.end\n    }) + '): a different token (`' + right.type + '`, ' + stringifyPosition({\n      start: right.start,\n      end: right.end\n    }) + ') is open');\n  } else {\n    throw new Error('Cannot close document, a token (`' + right.type + '`, ' + stringifyPosition({\n      start: right.start,\n      end: right.end\n    }) + ') is still open');\n  }\n}","/**\n * @typedef {import('micromark-util-types').Event} Event\n */\n\nimport { subtokenize } from 'micromark-util-subtokenize';\n\n/**\n * @param {Array<Event>} events\n * @returns {Array<Event>}\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events;\n}","import { l as log, J as decodeEntities } from \"./mermaid-8af3addd.js\";\nimport { fromMarkdown } from \"mdast-util-from-markdown\";\nimport { dedent } from \"ts-dedent\";\nfunction preprocessMarkdown(markdown) {\n  const withoutMultipleNewlines = markdown.replace(/\\n{2,}/g, \"\\n\");\n  const withoutExtraSpaces = dedent(withoutMultipleNewlines);\n  return withoutExtraSpaces;\n}\nfunction markdownToLines(markdown) {\n  const preprocessedMarkdown = preprocessMarkdown(markdown);\n  const {\n    children\n  } = fromMarkdown(preprocessedMarkdown);\n  const lines = [[]];\n  let currentLine = 0;\n  function processNode(node) {\n    let parentType = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"normal\";\n    if (node.type === \"text\") {\n      const textLines = node.value.split(\"\\n\");\n      textLines.forEach((textLine, index) => {\n        if (index !== 0) {\n          currentLine++;\n          lines.push([]);\n        }\n        textLine.split(\" \").forEach(word => {\n          if (word) {\n            lines[currentLine].push({\n              content: word,\n              type: parentType\n            });\n          }\n        });\n      });\n    } else if (node.type === \"strong\" || node.type === \"emphasis\") {\n      node.children.forEach(contentNode => {\n        processNode(contentNode, node.type);\n      });\n    }\n  }\n  children.forEach(treeNode => {\n    if (treeNode.type === \"paragraph\") {\n      treeNode.children.forEach(contentNode => {\n        processNode(contentNode);\n      });\n    }\n  });\n  return lines;\n}\nfunction markdownToHTML(markdown) {\n  const {\n    children\n  } = fromMarkdown(markdown);\n  function output(node) {\n    if (node.type === \"text\") {\n      return node.value.replace(/\\n/g, \"<br/>\");\n    } else if (node.type === \"strong\") {\n      return \"<strong>\".concat(node.children.map(output).join(\"\"), \"</strong>\");\n    } else if (node.type === \"emphasis\") {\n      return \"<em>\".concat(node.children.map(output).join(\"\"), \"</em>\");\n    } else if (node.type === \"paragraph\") {\n      return \"<p>\".concat(node.children.map(output).join(\"\"), \"</p>\");\n    }\n    return \"Unsupported markdown: \".concat(node.type);\n  }\n  return children.map(output).join(\"\");\n}\nfunction splitTextToChars(text) {\n  if (Intl.Segmenter) {\n    return [...new Intl.Segmenter().segment(text)].map(s => s.segment);\n  }\n  return [...text];\n}\nfunction splitWordToFitWidth(checkFit, word) {\n  const characters = splitTextToChars(word.content);\n  return splitWordToFitWidthRecursion(checkFit, [], characters, word.type);\n}\nfunction splitWordToFitWidthRecursion(checkFit, usedChars, remainingChars, type) {\n  if (remainingChars.length === 0) {\n    return [{\n      content: usedChars.join(\"\"),\n      type\n    }, {\n      content: \"\",\n      type\n    }];\n  }\n  const [nextChar, ...rest] = remainingChars;\n  const newWord = [...usedChars, nextChar];\n  if (checkFit([{\n    content: newWord.join(\"\"),\n    type\n  }])) {\n    return splitWordToFitWidthRecursion(checkFit, newWord, rest, type);\n  }\n  if (usedChars.length === 0 && nextChar) {\n    usedChars.push(nextChar);\n    remainingChars.shift();\n  }\n  return [{\n    content: usedChars.join(\"\"),\n    type\n  }, {\n    content: remainingChars.join(\"\"),\n    type\n  }];\n}\nfunction splitLineToFitWidth(line, checkFit) {\n  if (line.some(_ref => {\n    let {\n      content\n    } = _ref;\n    return content.includes(\"\\n\");\n  })) {\n    throw new Error(\"splitLineToFitWidth does not support newlines in the line\");\n  }\n  return splitLineToFitWidthRecursion(line, checkFit);\n}\nfunction splitLineToFitWidthRecursion(words, checkFit) {\n  var _words$shift;\n  let lines = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [];\n  let newLine = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [];\n  if (words.length === 0) {\n    if (newLine.length > 0) {\n      lines.push(newLine);\n    }\n    return lines.length > 0 ? lines : [];\n  }\n  let joiner = \"\";\n  if (words[0].content === \" \") {\n    joiner = \" \";\n    words.shift();\n  }\n  const nextWord = (_words$shift = words.shift()) !== null && _words$shift !== void 0 ? _words$shift : {\n    content: \" \",\n    type: \"normal\"\n  };\n  const lineWithNextWord = [...newLine];\n  if (joiner !== \"\") {\n    lineWithNextWord.push({\n      content: joiner,\n      type: \"normal\"\n    });\n  }\n  lineWithNextWord.push(nextWord);\n  if (checkFit(lineWithNextWord)) {\n    return splitLineToFitWidthRecursion(words, checkFit, lines, lineWithNextWord);\n  }\n  if (newLine.length > 0) {\n    lines.push(newLine);\n    words.unshift(nextWord);\n  } else if (nextWord.content) {\n    const [line, rest] = splitWordToFitWidth(checkFit, nextWord);\n    lines.push([line]);\n    if (rest.content) {\n      words.unshift(rest);\n    }\n  }\n  return splitLineToFitWidthRecursion(words, checkFit, lines);\n}\nfunction applyStyle(dom, styleFn) {\n  if (styleFn) {\n    dom.attr(\"style\", styleFn);\n  }\n}\nfunction addHtmlSpan(element, node, width, classes) {\n  let addBackground = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n  const fo = element.append(\"foreignObject\");\n  const div = fo.append(\"xhtml:div\");\n  const label = node.label;\n  const labelClass = node.isNode ? \"nodeLabel\" : \"edgeLabel\";\n  div.html(\"\\n    <span class=\\\"\".concat(labelClass, \" \").concat(classes, \"\\\" \") + (node.labelStyle ? 'style=\"' + node.labelStyle + '\"' : \"\") + \">\" + label + \"</span>\");\n  applyStyle(div, node.labelStyle);\n  div.style(\"display\", \"table-cell\");\n  div.style(\"white-space\", \"nowrap\");\n  div.style(\"max-width\", width + \"px\");\n  div.attr(\"xmlns\", \"http://www.w3.org/1999/xhtml\");\n  if (addBackground) {\n    div.attr(\"class\", \"labelBkg\");\n  }\n  let bbox = div.node().getBoundingClientRect();\n  if (bbox.width === width) {\n    div.style(\"display\", \"table\");\n    div.style(\"white-space\", \"break-spaces\");\n    div.style(\"width\", width + \"px\");\n    bbox = div.node().getBoundingClientRect();\n  }\n  fo.style(\"width\", bbox.width);\n  fo.style(\"height\", bbox.height);\n  return fo.node();\n}\nfunction createTspan(textElement, lineIndex, lineHeight) {\n  return textElement.append(\"tspan\").attr(\"class\", \"text-outer-tspan\").attr(\"x\", 0).attr(\"y\", lineIndex * lineHeight - 0.1 + \"em\").attr(\"dy\", lineHeight + \"em\");\n}\nfunction computeWidthOfText(parentNode, lineHeight, line) {\n  const testElement = parentNode.append(\"text\");\n  const testSpan = createTspan(testElement, 1, lineHeight);\n  updateTextContentAndStyles(testSpan, line);\n  const textLength = testSpan.node().getComputedTextLength();\n  testElement.remove();\n  return textLength;\n}\nfunction computeDimensionOfText(parentNode, lineHeight, text) {\n  var _a;\n  const testElement = parentNode.append(\"text\");\n  const testSpan = createTspan(testElement, 1, lineHeight);\n  updateTextContentAndStyles(testSpan, [{\n    content: text,\n    type: \"normal\"\n  }]);\n  const textDimension = (_a = testSpan.node()) == null ? void 0 : _a.getBoundingClientRect();\n  if (textDimension) {\n    testElement.remove();\n  }\n  return textDimension;\n}\nfunction createFormattedText(width, g, structuredText) {\n  let addBackground = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  const lineHeight = 1.1;\n  const labelGroup = g.append(\"g\");\n  const bkg = labelGroup.insert(\"rect\").attr(\"class\", \"background\");\n  const textElement = labelGroup.append(\"text\").attr(\"y\", \"-10.1\");\n  let lineIndex = 0;\n  for (const line of structuredText) {\n    const checkWidth = line2 => computeWidthOfText(labelGroup, lineHeight, line2) <= width;\n    const linesUnderWidth = checkWidth(line) ? [line] : splitLineToFitWidth(line, checkWidth);\n    for (const preparedLine of linesUnderWidth) {\n      const tspan = createTspan(textElement, lineIndex, lineHeight);\n      updateTextContentAndStyles(tspan, preparedLine);\n      lineIndex++;\n    }\n  }\n  if (addBackground) {\n    const bbox = textElement.node().getBBox();\n    const padding = 2;\n    bkg.attr(\"x\", -padding).attr(\"y\", -padding).attr(\"width\", bbox.width + 2 * padding).attr(\"height\", bbox.height + 2 * padding);\n    return labelGroup.node();\n  } else {\n    return textElement.node();\n  }\n}\nfunction updateTextContentAndStyles(tspan, wrappedLine) {\n  tspan.text(\"\");\n  wrappedLine.forEach((word, index) => {\n    const innerTspan = tspan.append(\"tspan\").attr(\"font-style\", word.type === \"emphasis\" ? \"italic\" : \"normal\").attr(\"class\", \"text-inner-tspan\").attr(\"font-weight\", word.type === \"strong\" ? \"bold\" : \"normal\");\n    if (index === 0) {\n      innerTspan.text(word.content);\n    } else {\n      innerTspan.text(\" \" + word.content);\n    }\n  });\n}\nconst createText = function (el) {\n  let text = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"\";\n  let {\n    style = \"\",\n    isTitle = false,\n    classes = \"\",\n    useHtmlLabels = true,\n    isNode = true,\n    width = 200,\n    addSvgBackground = false\n  } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  log.info(\"createText\", text, style, isTitle, classes, useHtmlLabels, isNode, addSvgBackground);\n  if (useHtmlLabels) {\n    const htmlText = markdownToHTML(text);\n    const node = {\n      isNode,\n      label: decodeEntities(htmlText).replace(/fa[blrs]?:fa-[\\w-]+/g, s => \"<i class='\".concat(s.replace(\":\", \" \"), \"'></i>\")),\n      labelStyle: style.replace(\"fill:\", \"color:\")\n    };\n    const vertexNode = addHtmlSpan(el, node, width, classes, addSvgBackground);\n    return vertexNode;\n  } else {\n    const structuredText = markdownToLines(text);\n    const svgLabel = createFormattedText(width, el, structuredText, addSvgBackground);\n    return svgLabel;\n  }\n};\nexport { createText as a, computeDimensionOfText as c };"],"sourceRoot":""}